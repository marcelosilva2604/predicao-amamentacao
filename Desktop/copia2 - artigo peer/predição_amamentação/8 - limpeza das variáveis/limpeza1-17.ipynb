{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d6b4c1e",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Estudo Aleitamento Materno\n",
    "\n",
    "## Contexto\n",
    "Prepara√ß√£o de vari√°veis para machine learning em estudo sobre aleitamento materno exclusivo baseado na pesquisa ENANI-2019. Objetivo: corrigir problemas identificados pelos revisores sobre tautologia, data leakage e overfitting.\n",
    "\n",
    "## Problemas Identificados pelos Revisores\n",
    "- **Tautologia**: Vari√°veis como \"dura√ß√£o do aleitamento exclusivo\" predizendo \"status atual de aleitamento exclusivo\"\n",
    "- **Data leakage**: Uso de informa√ß√µes que n√£o estariam dispon√≠veis no momento da predi√ß√£o\n",
    "- **Overfitting**: 139 preditores para ~2000 observa√ß√µes\n",
    "- **Linguagem causal inadequada**: Estudo transversal n√£o permite infer√™ncias causais\n",
    "\n",
    "## Estrat√©gia de Transforma√ß√£o\n",
    "1. **Curadoria conceitual**: Remover vari√°veis tautol√≥gicas antes da regulariza√ß√£o\n",
    "2. **Transforma√ß√µes padronizadas**: Binary encoding, one-hot encoding, manter num√©ricas quando apropriado\n",
    "3. **Aplica√ß√£o posterior**: Lasso/Ridge nas vari√°veis conceitualmente v√°lidas\n",
    "\n",
    "---\n",
    "\n",
    "## Vari√°veis Processadas (Lote 1/17)\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `a00_regiao` | **One-hot encoding** (5 colunas) | Categorias bem distribu√≠das, sem hierarquia natural |\n",
    "| `a11_situacao` | **Binary** (0=Rural, 1=Urbano) | Duas categorias claras, 98.1% urbano |\n",
    "| `b02_sexo` | **Binary** (0=Masculino, 1=Feminino) | Vari√°vel bin√°ria natural |\n",
    "| `b03_relacao` | **Binary** (0=Outros, 1=Filho) | 81.7% filhos vs 18.3% outros - mais eficiente que 4 colunas |\n",
    "| `b05a_idade_em_meses` | **Num√©rica** (0-5 meses) | Vari√°vel cont√≠nua ordinal |\n",
    "| `bb04_idade_da_mae` | **Num√©rica** | Vari√°vel cont√≠nua |\n",
    "| `d01_cor` | **One-hot encoding** (4 colunas) | Branca, Parda, Preta, Outras (agrupando Amarela+Ind√≠gena) |\n",
    "| `f001_esta_usando` | **Binary** (0=N√£o, 1=Sim) | Uso atual de vitaminas/minerais |\n",
    "| `g001_usou` | **Binary** (0=N√£o, 1=Sim) | Uso pr√©vio de vitaminas/minerais |\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | Motivo da Exclus√£o |\n",
    "|----------|-------------------|\n",
    "| `g150_vitaminas` | **Colinearidade** com f001_esta_usando e g001_usou |\n",
    "| `g151_sache` | **Irrelevante** - apenas 0.5% respostas positivas, creche inadequada para beb√™s |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 1\n",
    "- **Vari√°veis originais**: 10\n",
    "- **Features resultantes**: 18\n",
    "- **Vari√°veis exclu√≠das**: 2\n",
    "- **Redu√ß√£o de dimensionalidade**: Eficiente (de potenciais 20+ para 18)\n",
    "\n",
    "---\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "1. Processar lotes 2-17 (restantes 163 vari√°veis)\n",
    "2. Identificar e remover vari√°veis tautol√≥gicas relacionadas ao outcome\n",
    "3. Aplicar transforma√ß√µes padronizadas\n",
    "4. Implementar regulariza√ß√£o (Lasso/Ridge)\n",
    "5. Valida√ß√£o cruzada rigorosa\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **Para one-hot**: Usar drop='first' para evitar multicolinearidade perfeita\n",
    "- **Para binary**: Manter interpretabilidade clara (0/1)\n",
    "- **Para num√©ricas**: Considerar padroniza√ß√£o posterior se necess√°rio\n",
    "- **Valida√ß√£o**: Separar conjunto de teste antes de qualquer transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd02b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: (1960, 173)\n",
      "Colunas originais: ['aleitamento_materno_exclusivo', 'id_anon', 'a00_regiao', 'a11_situacao', 'b02_sexo', 'b03_relacao', 'b05a_idade_em_meses', 'bb04_idade_da_mae', 'd01_cor', 'f001_esta_usando', 'g001_usou', 'g150_vitaminas', 'g151_sache', 'h01_semanas_gravidez', 'h02_peso', 'h03_altura', 'h04_parto', 'h05_chupeta_usou', 'h10_consulta', 'h10b1_sindrome_nao', 'h11_alergia', 'h13_diarreia', 'h14_tosse', 'h15_respiracao', 'h16_canseira', 'h17_nariz', 'h18_ronqueira', 'h19_febre', 'h20_outro_problema', 'h21_internado', 'h211_internado_respiratoria', 'h212_internado_intestinais', 'h213_internado_acidente', 'h214_internado_alergias', 'h215_internado_outras', 'h216_internado_nao', 'h219_internado_nao_sabe', 'i993_faltou_alguma_refeicao', 'j03_cor', 'j04_vive', 'j05_religiao', 'j0501_rel_catolica', 'j0502_rel_evangelica_tradicional', 'j0503_rel_evangelica_pentecostal', 'j0504_rel_espirita_kardecista', 'j0505_rel_afro_brasileira', 'j0506_rel_protestante_historica', 'j0507_rel_budista', 'j0508_rel_sem_religiao', 'j0509_rel_outra_religiao', 'j0510_rel_ns_nqr', 'j06_ocupacao', 'j09_frequenta', 'j10_serie', 'k01_gestacoes', 'k02_filhos_vivos', 'k03_prenatal', 'k04_prenatal_semanas', 'k05_prenatal_consultas', 'k06_peso_engravidar', 'k07_peso_final', 'k08_quilos', 'k12_tempo', 'k13_tempo_medida', 'k15_recebeu', 'k16_liquido', 'k20_doou', 'k21_recebeu', 'k22_amamentou', 'k23_deixou', 'k24_utilizou', 'k241_utilizou_concha', 'k242_utilizou_protetor', 'k243_utilizou_bico', 'k244_utilizou_bomba', 'k245_utilizou_mamadeira', 'k246_utilizou_sondinha', 'k247_utilizou_copo', 'k248_utilizou_nao', 'k249_utilizou_nao_sabe', 'k25_mamadeira', 'k28_aleitamento', 'k29_alimentacao', 'l01_morador_alim_acabassem', 'l02_morador_alim_acabaram', 'l03_morador_saudavel', 'l04_morador_insuficiente', 'l05_adulto_saltou_refeicao', 'l06_adulto_comeu_menos', 'l07_adulto_sentiu_fome', 'l08_adulto_sem_comer', 'l09_menos18_saudavel', 'l10_menos18_insuficiente', 'l11_menos18_diminuiu', 'l12_menos18_saltou_refeicao', 'l13_menos18_sentiu_fome', 'l14_menos18_sem_comer', 'm01_costuma_cozinhar', 'm03_alimentos_basicos', 'm04_confiante', 'm05_organiza', 'm06_facilidade', 'm07_sabe_basico', 'm08_adiantar_etapas', 'm09_atividades_divididas', 'n01_frutas', 'n02_legumes', 'n03_verduras', 'n04_feijao', 'n05_suco', 'n06_refrigerantes', 'n07_biscoitos', 'n08_salgadinhos', 'n09_balas', 'o01_frutas_comprar', 'o02_frutas_qualidade', 'o03_frutas_variedade', 'o04_frutas_baratas', 'o05_refrigerantes_comprar', 'o06_refrigerantes_variedade', 'o07_refrigerantes_baratos', 'p02_tipo_de_domicilio', 'p03_ocupacao', 'p05_comodos', 'p06_cozinha', 'p07_dormitorios', 'p08_banheiros_exclusivo', 'p09_banheiros_chuveiro', 'p10_esgoto', 'p11_agua', 'p12_lixo', 'p13_energia_eletrica', 'q01_recebe_beneficio', 'q06_renda', 'q07_renda_faixa', 'r01_televisao', 'r02_automoveis', 'r03_radio', 'r04_geladeira', 'r05_vcr', 'r06_lavadora', 'r07_micro_ondas', 'r08_telefone_fixo', 'r09_microcomputador', 'r10_ar_condicionado', 'r11_tv_a_cabo', 'r12_internet_domicilio', 'r13_internet_celular', 'r14_celular', 't05_altura_medida1', 't06_altura_medida2', 't06a_altura_padrao', 'total_12p', 'x06_total_pessoas', 'x07_total_criancas', 'x08_total_maes_resp', 'vd_ien_escore', 'vd_ien_quintos', 'vd_ien_decimos', 'vd_dummy_domic_ien', 'vd_ebia_escore', 'vd_ebia_categ', 'vd_dummy_domic_ebia', 'vd_suplemento', 'vd_suplemento_sus', 'vd_suplemento_comercial', 'vd_num_supl', 'vd_zwaz', 'vd_zimc', 'vd_zhaz', 'vd_anthro_zwfl', 'vd_prematura_igb', 'vd_imc_mae']\n",
      "\n",
      "1. Transformando a00_regiao...\n",
      "   Criadas: ['regiao_Centro-Oeste', 'regiao_Nordeste', 'regiao_Norte', 'regiao_Sudeste', 'regiao_Sul']\n",
      "\n",
      "2. Transformando a11_situacao...\n",
      "   Distribui√ß√£o: {1: 1922, 0: 38}\n",
      "\n",
      "3. Transformando b02_sexo...\n",
      "   Distribui√ß√£o: {1: 1005, 0: 955}\n",
      "\n",
      "4. Transformando b03_relacao...\n",
      "   Distribui√ß√£o: {1: 1602, 0: 358}\n",
      "\n",
      "5. Mantendo b05a_idade_em_meses...\n",
      "   Range: nan - nan\n",
      "   Valores ausentes: 1960\n",
      "\n",
      "6. Mantendo bb04_idade_da_mae...\n",
      "   Range: 14.0 - 71.0\n",
      "   Valores ausentes: 0\n",
      "\n",
      "7. Transformando d01_cor...\n",
      "   Criadas: ['cor_Branca', 'cor_Outras', 'cor_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_Preta']\n",
      "\n",
      "8. Transformando f001_esta_usando...\n",
      "   Distribui√ß√£o: {0: 1176, 1: 784}\n",
      "\n",
      "9. Transformando g001_usou...\n",
      "   Distribui√ß√£o: {0: 1709, 1: 251}\n",
      "\n",
      "‚ùå Exclu√≠da: g150_vitaminas\n",
      "\n",
      "‚ùå Exclu√≠da: g151_sache\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO DE TRANSFORMA√á√ÉO - LOTE 1\n",
      "==================================================\n",
      "\n",
      "Dataset final: (1960, 178)\n",
      "Mudan√ßa: 1960 linhas, 173 ‚Üí 178 colunas\n",
      "\n",
      "Transforma√ß√µes realizadas:\n",
      " 1. a00_regiao ‚Üí One-hot encoding (5 colunas)\n",
      " 2. a11_situacao ‚Üí Binary (situacao_urbano: 0=Rural, 1=Urbano)\n",
      " 3. b02_sexo ‚Üí Binary (sexo_feminino: 0=Masculino, 1=Feminino)\n",
      " 4. b03_relacao ‚Üí Binary (relacao_filho: 0=Outros, 1=Filho)\n",
      " 5. b05a_idade_em_meses ‚Üí Mantida num√©rica\n",
      " 6. bb04_idade_da_mae ‚Üí Mantida num√©rica\n",
      " 7. d01_cor ‚Üí One-hot encoding (4 colunas, agrupando Amarela+Ind√≠gena=Outras)\n",
      " 8. f001_esta_usando ‚Üí Binary (esta_usando_vitamina: 0=N√£o, 1=Sim)\n",
      " 9. g001_usou ‚Üí Binary (usou_vitamina: 0=N√£o, 1=Sim)\n",
      "10. Exclu√≠das: g150_vitaminas, g151_sache\n",
      "\n",
      "Valores ausentes nas vari√°veis transformadas:\n",
      "   ‚úÖ Nenhum valor ausente nas novas vari√°veis\n",
      "\n",
      "üíæ Dataset salvo em: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs_transformed_lote1.csv\n",
      "üìã Log salvo em: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/transformation_log_lote1.txt\n",
      "\n",
      "Primeiras 5 linhas das novas vari√°veis:\n",
      "   b05a_idade_em_meses  bb04_idade_da_mae  regiao_Centro-Oeste  \\\n",
      "0                  NaN               19.0                    0   \n",
      "1                  NaN               16.0                    0   \n",
      "2                  NaN               34.0                    0   \n",
      "3                  NaN               21.0                    0   \n",
      "4                  NaN               17.0                    0   \n",
      "\n",
      "   regiao_Nordeste  regiao_Norte  regiao_Sudeste  regiao_Sul  situacao_urbano  \\\n",
      "0                0             1               0           0                1   \n",
      "1                0             1               0           0                1   \n",
      "2                0             1               0           0                1   \n",
      "3                0             1               0           0                1   \n",
      "4                0             1               0           0                1   \n",
      "\n",
      "   sexo_feminino  relacao_filho  cor_Branca  cor_Outras  \\\n",
      "0              0              0           0           0   \n",
      "1              1              1           0           0   \n",
      "2              0              0           0           0   \n",
      "3              0              1           1           0   \n",
      "4              0              1           1           0   \n",
      "\n",
      "   cor_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)  cor_Preta  \\\n",
      "0                                                  1                 0   \n",
      "1                                                  1                 0   \n",
      "2                                                  1                 0   \n",
      "3                                                  0                 0   \n",
      "4                                                  0                 0   \n",
      "\n",
      "   esta_usando_vitamina  usou_vitamina  \n",
      "0                     1              0  \n",
      "1                     1              0  \n",
      "2                     1              1  \n",
      "3                     1              0  \n",
      "4                     0              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "print(f\"Colunas originais: {df.columns.tolist()}\")\n",
    "\n",
    "# Fazer uma c√≥pia para transforma√ß√£o\n",
    "df_transformed = df.copy()\n",
    "\n",
    "# Lista para log das transforma√ß√µes\n",
    "transformation_log = []\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES DO LOTE 1\n",
    "# =============================================================================\n",
    "\n",
    "# 1. a00_regiao - One-hot encoding\n",
    "print(\"\\n1. Transformando a00_regiao...\")\n",
    "if 'a00_regiao' in df_transformed.columns:\n",
    "    regiao_dummies = pd.get_dummies(df_transformed['a00_regiao'], prefix='regiao', drop_first=False)\n",
    "    df_transformed = pd.concat([df_transformed, regiao_dummies], axis=1)\n",
    "    df_transformed.drop('a00_regiao', axis=1, inplace=True)\n",
    "    transformation_log.append(\"a00_regiao ‚Üí One-hot encoding (5 colunas)\")\n",
    "    print(f\"   Criadas: {regiao_dummies.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel a00_regiao n√£o encontrada\")\n",
    "\n",
    "# 2. a11_situacao - Binary encoding\n",
    "print(\"\\n2. Transformando a11_situacao...\")\n",
    "if 'a11_situacao' in df_transformed.columns:\n",
    "    df_transformed['situacao_urbano'] = (df_transformed['a11_situacao'] == 'Urbano').astype(int)\n",
    "    df_transformed.drop('a11_situacao', axis=1, inplace=True)\n",
    "    transformation_log.append(\"a11_situacao ‚Üí Binary (situacao_urbano: 0=Rural, 1=Urbano)\")\n",
    "    print(f\"   Distribui√ß√£o: {df_transformed['situacao_urbano'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel a11_situacao n√£o encontrada\")\n",
    "\n",
    "# 3. b02_sexo - Binary encoding\n",
    "print(\"\\n3. Transformando b02_sexo...\")\n",
    "if 'b02_sexo' in df_transformed.columns:\n",
    "    df_transformed['sexo_feminino'] = (df_transformed['b02_sexo'] == 'Feminino').astype(int)\n",
    "    df_transformed.drop('b02_sexo', axis=1, inplace=True)\n",
    "    transformation_log.append(\"b02_sexo ‚Üí Binary (sexo_feminino: 0=Masculino, 1=Feminino)\")\n",
    "    print(f\"   Distribui√ß√£o: {df_transformed['sexo_feminino'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel b02_sexo n√£o encontrada\")\n",
    "\n",
    "# 4. b03_relacao - Binary encoding (Filho vs Outros)\n",
    "print(\"\\n4. Transformando b03_relacao...\")\n",
    "if 'b03_relacao' in df_transformed.columns:\n",
    "    df_transformed['relacao_filho'] = df_transformed['b03_relacao'].str.contains('Filho', case=False, na=False).astype(int)\n",
    "    df_transformed.drop('b03_relacao', axis=1, inplace=True)\n",
    "    transformation_log.append(\"b03_relacao ‚Üí Binary (relacao_filho: 0=Outros, 1=Filho)\")\n",
    "    print(f\"   Distribui√ß√£o: {df_transformed['relacao_filho'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel b03_relacao n√£o encontrada\")\n",
    "\n",
    "# 5. b05a_idade_em_meses - Manter num√©rica\n",
    "print(\"\\n5. Mantendo b05a_idade_em_meses...\")\n",
    "if 'b05a_idade_em_meses' in df_transformed.columns:\n",
    "    # Verificar se √© num√©rica e converter se necess√°rio\n",
    "    df_transformed['b05a_idade_em_meses'] = pd.to_numeric(df_transformed['b05a_idade_em_meses'], errors='coerce')\n",
    "    transformation_log.append(\"b05a_idade_em_meses ‚Üí Mantida num√©rica\")\n",
    "    print(f\"   Range: {df_transformed['b05a_idade_em_meses'].min()} - {df_transformed['b05a_idade_em_meses'].max()}\")\n",
    "    print(f\"   Valores ausentes: {df_transformed['b05a_idade_em_meses'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel b05a_idade_em_meses n√£o encontrada\")\n",
    "\n",
    "# 6. bb04_idade_da_mae - Manter num√©rica\n",
    "print(\"\\n6. Mantendo bb04_idade_da_mae...\")\n",
    "if 'bb04_idade_da_mae' in df_transformed.columns:\n",
    "    df_transformed['bb04_idade_da_mae'] = pd.to_numeric(df_transformed['bb04_idade_da_mae'], errors='coerce')\n",
    "    transformation_log.append(\"bb04_idade_da_mae ‚Üí Mantida num√©rica\")\n",
    "    print(f\"   Range: {df_transformed['bb04_idade_da_mae'].min()} - {df_transformed['bb04_idade_da_mae'].max()}\")\n",
    "    print(f\"   Valores ausentes: {df_transformed['bb04_idade_da_mae'].isna().sum()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel bb04_idade_da_mae n√£o encontrada\")\n",
    "\n",
    "# 7. d01_cor - One-hot encoding com agrupamento\n",
    "print(\"\\n7. Transformando d01_cor...\")\n",
    "if 'd01_cor' in df_transformed.columns:\n",
    "    # Agrupar categorias pequenas\n",
    "    df_transformed['d01_cor_grouped'] = df_transformed['d01_cor'].copy()\n",
    "    mask_outras = df_transformed['d01_cor_grouped'].isin(['Amarela (origem japonesa, chinesa, coreana etc.)', 'Ind√≠gena'])\n",
    "    df_transformed.loc[mask_outras, 'd01_cor_grouped'] = 'Outras'\n",
    "    \n",
    "    # One-hot encoding\n",
    "    cor_dummies = pd.get_dummies(df_transformed['d01_cor_grouped'], prefix='cor', drop_first=False)\n",
    "    df_transformed = pd.concat([df_transformed, cor_dummies], axis=1)\n",
    "    df_transformed.drop(['d01_cor', 'd01_cor_grouped'], axis=1, inplace=True)\n",
    "    transformation_log.append(\"d01_cor ‚Üí One-hot encoding (4 colunas, agrupando Amarela+Ind√≠gena=Outras)\")\n",
    "    print(f\"   Criadas: {cor_dummies.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel d01_cor n√£o encontrada\")\n",
    "\n",
    "# 8. f001_esta_usando - Binary encoding\n",
    "print(\"\\n8. Transformando f001_esta_usando...\")\n",
    "if 'f001_esta_usando' in df_transformed.columns:\n",
    "    df_transformed['esta_usando_vitamina'] = (df_transformed['f001_esta_usando'] == 'Sim').astype(int)\n",
    "    df_transformed.drop('f001_esta_usando', axis=1, inplace=True)\n",
    "    transformation_log.append(\"f001_esta_usando ‚Üí Binary (esta_usando_vitamina: 0=N√£o, 1=Sim)\")\n",
    "    print(f\"   Distribui√ß√£o: {df_transformed['esta_usando_vitamina'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel f001_esta_usando n√£o encontrada\")\n",
    "\n",
    "# 9. g001_usou - Binary encoding\n",
    "print(\"\\n9. Transformando g001_usou...\")\n",
    "if 'g001_usou' in df_transformed.columns:\n",
    "    df_transformed['usou_vitamina'] = (df_transformed['g001_usou'] == 'Sim').astype(int)\n",
    "    df_transformed.drop('g001_usou', axis=1, inplace=True)\n",
    "    transformation_log.append(\"g001_usou ‚Üí Binary (usou_vitamina: 0=N√£o, 1=Sim)\")\n",
    "    print(f\"   Distribui√ß√£o: {df_transformed['usou_vitamina'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Vari√°vel g001_usou n√£o encontrada\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES\n",
    "# =============================================================================\n",
    "\n",
    "# Excluir vari√°veis problem√°ticas\n",
    "vars_to_exclude = ['g150_vitaminas', 'g151_sache']\n",
    "excluded_vars = []\n",
    "\n",
    "for var in vars_to_exclude:\n",
    "    if var in df_transformed.columns:\n",
    "        df_transformed.drop(var, axis=1, inplace=True)\n",
    "        excluded_vars.append(var)\n",
    "        print(f\"\\n‚ùå Exclu√≠da: {var}\")\n",
    "\n",
    "if excluded_vars:\n",
    "    transformation_log.append(f\"Exclu√≠das: {', '.join(excluded_vars)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# RELAT√ìRIO FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO DE TRANSFORMA√á√ÉO - LOTE 1\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"\\nDataset final: {df_transformed.shape}\")\n",
    "print(f\"Mudan√ßa: {df.shape[0]} linhas, {df.shape[1]} ‚Üí {df_transformed.shape[1]} colunas\")\n",
    "\n",
    "print(\"\\nTransforma√ß√µes realizadas:\")\n",
    "for i, log in enumerate(transformation_log, 1):\n",
    "    print(f\"{i:2d}. {log}\")\n",
    "\n",
    "# Verificar se h√° valores ausentes nas novas vari√°veis\n",
    "print(\"\\nValores ausentes nas vari√°veis transformadas:\")\n",
    "new_cols = [col for col in df_transformed.columns if col not in df.columns]\n",
    "if new_cols:\n",
    "    missing_info = df_transformed[new_cols].isnull().sum()\n",
    "    for col, missing in missing_info.items():\n",
    "        if missing > 0:\n",
    "            print(f\"   {col}: {missing} ({missing/len(df_transformed)*100:.1f}%)\")\n",
    "    if missing_info.sum() == 0:\n",
    "        print(\"   ‚úÖ Nenhum valor ausente nas novas vari√°veis\")\n",
    "\n",
    "# Salvar dataset transformado\n",
    "output_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs_transformed_lote1.csv\"\n",
    "df_transformed.to_csv(output_path, index=False)\n",
    "print(f\"\\nüíæ Dataset salvo em: {output_path}\")\n",
    "\n",
    "# Salvar log de transforma√ß√µes\n",
    "log_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/transformation_log_lote1.txt\"\n",
    "with open(log_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"LOG DE TRANSFORMA√á√ïES - LOTE 1\\n\")\n",
    "    f.write(\"=\"*50 + \"\\n\\n\")\n",
    "    f.write(f\"Dataset original: {df.shape}\\n\")\n",
    "    f.write(f\"Dataset transformado: {df_transformed.shape}\\n\\n\")\n",
    "    f.write(\"Transforma√ß√µes realizadas:\\n\")\n",
    "    for i, log in enumerate(transformation_log, 1):\n",
    "        f.write(f\"{i:2d}. {log}\\n\")\n",
    "\n",
    "print(f\"üìã Log salvo em: {log_path}\")\n",
    "\n",
    "# Mostrar primeiras linhas das novas vari√°veis\n",
    "print(\"\\nPrimeiras 5 linhas das novas vari√°veis:\")\n",
    "new_vars = [col for col in df_transformed.columns if col not in df.columns or \n",
    "           col in ['b05a_idade_em_meses', 'bb04_idade_da_mae']]\n",
    "if new_vars:\n",
    "    print(df_transformed[new_vars].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f8a414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original: (1960, 173)\n",
      "\n",
      "1. Transformando a00_regiao...\n",
      "   Criadas: ['regiao_Centro-Oeste', 'regiao_Nordeste', 'regiao_Norte', 'regiao_Sudeste', 'regiao_Sul']\n",
      "\n",
      "2. Transformando a11_situacao...\n",
      "   Distribui√ß√£o: {1: 1922, 0: 38}\n",
      "\n",
      "3. Transformando b02_sexo...\n",
      "   Distribui√ß√£o: {1: 1005, 0: 955}\n",
      "\n",
      "4. Transformando b03_relacao...\n",
      "   Distribui√ß√£o: {1: 1602, 0: 358}\n",
      "\n",
      "5. Transformando b05a_idade_em_meses...\n",
      "   Range: 0.0 - 5.0\n",
      "   Valores ausentes: 0\n",
      "\n",
      "6. Verificando bb04_idade_da_mae...\n",
      "   Range: 14.0 - 71.0\n",
      "\n",
      "7. Transformando d01_cor...\n",
      "   Criadas: ['cor_Branca', 'cor_Outras', 'cor_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_Preta']\n",
      "\n",
      "8. Transformando f001_esta_usando...\n",
      "   Distribui√ß√£o: {0: 1176, 1: 784}\n",
      "\n",
      "9. Transformando g001_usou...\n",
      "   Distribui√ß√£o: {0: 1709, 1: 251}\n",
      "\n",
      "Exclu√≠da: g150_vitaminas\n",
      "\n",
      "Exclu√≠da: g151_sache\n",
      "\n",
      "Dataset transformado salvo: (1960, 178)\n",
      "Arquivo sobrescrito: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Verifica√ß√£o das transforma√ß√µes:\n",
      "b05a_idade_em_meses (primeiras 10):\n",
      "[5.0, 5.0, 5.0, 5.0, 0.0, 5.0, 0.0, 2.0, 3.0, 1.0]\n",
      "\n",
      "Colunas atuais (primeiras 20):\n",
      "['aleitamento_materno_exclusivo', 'id_anon', 'regiao_Centro-Oeste', 'regiao_Nordeste', 'regiao_Norte', 'regiao_Sudeste', 'regiao_Sul', 'a11_situacao', 'b02_sexo', 'b03_relacao', 'b05a_idade_em_meses', 'bb04_idade_da_mae', 'cor_Branca', 'cor_Outras', 'cor_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_Preta', 'f001_esta_usando', 'g001_usou', 'h01_semanas_gravidez', 'h02_peso']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES IN-PLACE (substituindo as originais)\n",
    "# =============================================================================\n",
    "\n",
    "# 1. a00_regiao - One-hot encoding (substituir a original)\n",
    "if 'a00_regiao' in df.columns:\n",
    "    print(\"\\n1. Transformando a00_regiao...\")\n",
    "    regiao_dummies = pd.get_dummies(df['a00_regiao'], prefix='regiao', drop_first=False)\n",
    "    # Inserir no lugar da original\n",
    "    col_index = df.columns.get_loc('a00_regiao')\n",
    "    df.drop('a00_regiao', axis=1, inplace=True)\n",
    "    for i, col in enumerate(regiao_dummies.columns):\n",
    "        df.insert(col_index + i, col, regiao_dummies[col])\n",
    "    print(f\"   Criadas: {regiao_dummies.columns.tolist()}\")\n",
    "\n",
    "# 2. a11_situacao - Binary encoding\n",
    "if 'a11_situacao' in df.columns:\n",
    "    print(\"\\n2. Transformando a11_situacao...\")\n",
    "    df['a11_situacao'] = (df['a11_situacao'] == 'Urbano').astype(int)\n",
    "    print(f\"   Distribui√ß√£o: {df['a11_situacao'].value_counts().to_dict()}\")\n",
    "\n",
    "# 3. b02_sexo - Binary encoding  \n",
    "if 'b02_sexo' in df.columns:\n",
    "    print(\"\\n3. Transformando b02_sexo...\")\n",
    "    df['b02_sexo'] = (df['b02_sexo'] == 'Feminino').astype(int)\n",
    "    print(f\"   Distribui√ß√£o: {df['b02_sexo'].value_counts().to_dict()}\")\n",
    "\n",
    "# 4. b03_relacao - Binary encoding (Filho vs Outros)\n",
    "if 'b03_relacao' in df.columns:\n",
    "    print(\"\\n4. Transformando b03_relacao...\")\n",
    "    df['b03_relacao'] = df['b03_relacao'].str.contains('Filho', case=False, na=False).astype(int)\n",
    "    print(f\"   Distribui√ß√£o: {df['b03_relacao'].value_counts().to_dict()}\")\n",
    "\n",
    "# 5. b05a_idade_em_meses - Converter texto para n√∫meros\n",
    "if 'b05a_idade_em_meses' in df.columns:\n",
    "    print(\"\\n5. Transformando b05a_idade_em_meses...\")\n",
    "    # Extrair n√∫meros do texto \"X meses\" ou \"X m√™s\"\n",
    "    def extract_months(text):\n",
    "        if pd.isna(text):\n",
    "            return np.nan\n",
    "        # Procurar por n√∫meros no in√≠cio da string\n",
    "        match = re.search(r'^(\\d+)', str(text))\n",
    "        if match:\n",
    "            return float(match.group(1))\n",
    "        return np.nan\n",
    "    \n",
    "    df['b05a_idade_em_meses'] = df['b05a_idade_em_meses'].apply(extract_months)\n",
    "    print(f\"   Range: {df['b05a_idade_em_meses'].min()} - {df['b05a_idade_em_meses'].max()}\")\n",
    "    print(f\"   Valores ausentes: {df['b05a_idade_em_meses'].isna().sum()}\")\n",
    "\n",
    "# 6. bb04_idade_da_mae - Garantir que √© num√©rica\n",
    "if 'bb04_idade_da_mae' in df.columns:\n",
    "    print(\"\\n6. Verificando bb04_idade_da_mae...\")\n",
    "    df['bb04_idade_da_mae'] = pd.to_numeric(df['bb04_idade_da_mae'], errors='coerce')\n",
    "    print(f\"   Range: {df['bb04_idade_da_mae'].min()} - {df['bb04_idade_da_mae'].max()}\")\n",
    "\n",
    "# 7. d01_cor - One-hot encoding com agrupamento (substituir a original)\n",
    "if 'd01_cor' in df.columns:\n",
    "    print(\"\\n7. Transformando d01_cor...\")\n",
    "    # Agrupar categorias pequenas\n",
    "    cor_grouped = df['d01_cor'].copy()\n",
    "    mask_outras = cor_grouped.isin(['Amarela (origem japonesa, chinesa, coreana etc.)', 'Ind√≠gena'])\n",
    "    cor_grouped.loc[mask_outras] = 'Outras'\n",
    "    \n",
    "    # One-hot encoding\n",
    "    cor_dummies = pd.get_dummies(cor_grouped, prefix='cor', drop_first=False)\n",
    "    # Inserir no lugar da original\n",
    "    col_index = df.columns.get_loc('d01_cor')\n",
    "    df.drop('d01_cor', axis=1, inplace=True)\n",
    "    for i, col in enumerate(cor_dummies.columns):\n",
    "        df.insert(col_index + i, col, cor_dummies[col])\n",
    "    print(f\"   Criadas: {cor_dummies.columns.tolist()}\")\n",
    "\n",
    "# 8. f001_esta_usando - Binary encoding\n",
    "if 'f001_esta_usando' in df.columns:\n",
    "    print(\"\\n8. Transformando f001_esta_usando...\")\n",
    "    df['f001_esta_usando'] = (df['f001_esta_usando'] == 'Sim').astype(int)\n",
    "    print(f\"   Distribui√ß√£o: {df['f001_esta_usando'].value_counts().to_dict()}\")\n",
    "\n",
    "# 9. g001_usou - Binary encoding\n",
    "if 'g001_usou' in df.columns:\n",
    "    print(\"\\n9. Transformando g001_usou...\")\n",
    "    df['g001_usou'] = (df['g001_usou'] == 'Sim').astype(int)\n",
    "    print(f\"   Distribui√ß√£o: {df['g001_usou'].value_counts().to_dict()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES\n",
    "# =============================================================================\n",
    "\n",
    "vars_to_exclude = ['g150_vitaminas', 'g151_sache']\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        print(f\"\\nExclu√≠da: {var}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET MODIFICADO (SOBRESCREVER O ORIGINAL)\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo sobrescrito: {file_path}\")\n",
    "\n",
    "# Verificar algumas transforma√ß√µes\n",
    "print(\"\\nVerifica√ß√£o das transforma√ß√µes:\")\n",
    "print(\"b05a_idade_em_meses (primeiras 10):\")\n",
    "print(df['b05a_idade_em_meses'].head(10).tolist())\n",
    "\n",
    "print(\"\\nColunas atuais (primeiras 20):\")\n",
    "print(df.columns[:20].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e966c8f7",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Estudo Aleitamento Materno\n",
    "\n",
    "## Contexto\n",
    "Prepara√ß√£o de vari√°veis para machine learning em estudo sobre aleitamento materno exclusivo baseado na pesquisa ENANI-2019. Objetivo: corrigir problemas identificados pelos revisores sobre tautologia, data leakage e overfitting.\n",
    "\n",
    "## Problemas Identificados pelos Revisores\n",
    "- **Tautologia**: Vari√°veis como \"dura√ß√£o do aleitamento exclusivo\" predizendo \"status atual de aleitamento exclusivo\"\n",
    "- **Data leakage**: Uso de informa√ß√µes que n√£o estariam dispon√≠veis no momento da predi√ß√£o\n",
    "- **Overfitting**: 139 preditores para ~2000 observa√ß√µes\n",
    "- **Linguagem causal inadequada**: Estudo transversal n√£o permite infer√™ncias causais\n",
    "\n",
    "## Estrat√©gia de Transforma√ß√£o\n",
    "1. **Curadoria conceitual**: Remover vari√°veis tautol√≥gicas antes da regulariza√ß√£o\n",
    "2. **Transforma√ß√µes padronizadas**: Binary encoding, one-hot encoding, manter num√©ricas quando apropriado\n",
    "3. **Aplica√ß√£o posterior**: Lasso/Ridge nas vari√°veis conceitualmente v√°lidas\n",
    "\n",
    "---\n",
    "\n",
    "## Vari√°veis Processadas (Lote 1/17)\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `a00_regiao` | **One-hot encoding** (5 colunas) | Categorias bem distribu√≠das, sem hierarquia natural |\n",
    "| `a11_situacao` | **Binary** (0=Rural, 1=Urbano) | Duas categorias claras, 98.1% urbano |\n",
    "| `b02_sexo` | **Binary** (0=Masculino, 1=Feminino) | Vari√°vel bin√°ria natural |\n",
    "| `b03_relacao` | **Binary** (0=Outros, 1=Filho) | 81.7% filhos vs 18.3% outros - mais eficiente que 4 colunas |\n",
    "| `b05a_idade_em_meses` | **Num√©rica** (0-5 meses) | Vari√°vel cont√≠nua ordinal |\n",
    "| `bb04_idade_da_mae` | **Num√©rica** | Vari√°vel cont√≠nua |\n",
    "| `d01_cor` | **One-hot encoding** (4 colunas) | Branca, Parda, Preta, Outras (agrupando Amarela+Ind√≠gena) |\n",
    "| `f001_esta_usando` | **Binary** (0=N√£o, 1=Sim) | Uso atual de vitaminas/minerais |\n",
    "| `g001_usou` | **Binary** (0=N√£o, 1=Sim) | Uso pr√©vio de vitaminas/minerais |\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | Motivo da Exclus√£o |\n",
    "|----------|-------------------|\n",
    "| `g150_vitaminas` | **Colinearidade** com f001_esta_usando e g001_usou |\n",
    "| `g151_sache` | **Irrelevante** - apenas 0.5% respostas positivas, creche inadequada para beb√™s |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 1\n",
    "- **Vari√°veis originais**: 10\n",
    "- **Features resultantes**: 18\n",
    "- **Vari√°veis exclu√≠das**: 2\n",
    "- **Redu√ß√£o de dimensionalidade**: Eficiente (de potenciais 20+ para 18)\n",
    "\n",
    "---\n",
    "\n",
    "## Vari√°veis Processadas (Lote 2/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Excluir vari√°veis com <5% na categoria minorit√°ria para evitar desbalanceamento extremo\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `h01_semanas_gravidez` | **Num√©rica** | Boa distribui√ß√£o, relevante para predi√ß√£o |\n",
    "| `h02_peso` | **Num√©rica** | Peso ao nascer em gramas |\n",
    "| `h03_altura` | **Num√©rica** | Altura ao nascer em cm |\n",
    "| `h04_parto` | **One-hot encoding** (3 colunas) | Normal (52.8%), Cesariana urg√™ncia (27.9%), Cesariana eletiva (19.3%) |\n",
    "| `h05_chupeta_usou` | **Binary** (exposi√ß√£o √† chupeta) | \"Usa\"+\"J√° usou\" = 1 vs \"Recusou\"+\"Nunca oferecido\" = 0 |\n",
    "| `h10_consulta` | **One-hot encoding** (3 colunas) | P√∫blico (76.1%), Privado (17.2%), N√£o leva/Outros (agrupados) |\n",
    "| `h13_diarreia` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (9.4% sim) |\n",
    "| `h14_tosse` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (24.7% sim) |\n",
    "| `h15_respiracao` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (16.4% sim) |\n",
    "| `h16_canseira` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (8.0% sim) |\n",
    "| `h17_nariz` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (32.4% sim) |\n",
    "| `h18_ronqueira` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (20.5% sim) |\n",
    "| `h19_febre` | **Binary** (0=N√£o, 1=Sim) | Sintoma relevante (15.2% sim) |\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | % Categoria Minorit√°ria | Motivo |\n",
    "|----------|------------------------|---------|\n",
    "| `h10b1_sindrome_nao` | 0.8% | Varia√ß√£o insuficiente |\n",
    "| `h11_alergia` | 1.5% | Muito raro em beb√™s 0-5 meses |\n",
    "| `h20_outro_problema` | 3.0% | Abaixo do limiar 5% |\n",
    "| `h21_internado` | V√°rias <1% | C√≥digos confusos, categorias esparsas |\n",
    "| `h211_internado_respiratoria` | 2.1% | Evento raro |\n",
    "| `h212_internado_intestinais` | 0.5% | Evento raro |\n",
    "| `h213_internado_acidente` | 0.3% | Evento raro |\n",
    "| `h214_internado_alergias` | 0.2% | Evento raro |\n",
    "| `h215_internado_outras` | 3.3% | Abaixo do limiar 5% |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 2\n",
    "- **Vari√°veis originais**: 22\n",
    "- **Features resultantes**: ~17 \n",
    "- **Vari√°veis exclu√≠das**: 9\n",
    "- **Taxa de exclus√£o**: 40.9% (aplica√ß√£o rigorosa do crit√©rio 5%)\n",
    "\n",
    "---\n",
    "\n",
    "## Pr√≥ximos Passos\n",
    "1. Processar lotes 3-17 (restantes 141 vari√°veis)\n",
    "2. Identificar e remover vari√°veis tautol√≥gicas relacionadas ao outcome\n",
    "3. Aplicar transforma√ß√µes padronizadas\n",
    "4. Implementar regulariza√ß√£o (Lasso/Ridge)\n",
    "5. Valida√ß√£o cruzada rigorosa\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **Para one-hot**: Usar drop='first' para evitar multicolinearidade perfeita\n",
    "- **Para binary**: Manter interpretabilidade clara (0/1)\n",
    "- **Para num√©ricas**: Considerar padroniza√ß√£o posterior se necess√°rio\n",
    "- **Valida√ß√£o**: Separar conjunto de teste antes de qualquer transforma√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d1d77ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 178)\n",
      "\n",
      "1. Verificando h01_semanas_gravidez...\n",
      "   Range: 28 - 42\n",
      "\n",
      "2. Verificando h02_peso...\n",
      "   Range: 255 - 4885\n",
      "\n",
      "3. Verificando h03_altura...\n",
      "   Range: 31.0 - 59.0\n",
      "\n",
      "4. Transformando h04_parto...\n",
      "   Criadas: ['parto_Cesariana agendada (eletiva)', 'parto_Cesariana de urg√™ncia (N√£o agendada)', 'parto_Normal']\n",
      "\n",
      "5. Transformando h05_chupeta_usou...\n",
      "   Exposi√ß√£o √† chupeta: 824 casos (42.0%)\n",
      "\n",
      "6. Transformando h10_consulta...\n",
      "   Criadas: ['consulta_Outros', 'consulta_Privado', 'consulta_P√∫blico']\n",
      "\n",
      "7. Transformando h13_diarreia...\n",
      "   Sim: 184 casos (9.4%)\n",
      "\n",
      "8. Transformando h14_tosse...\n",
      "   Sim: 484 casos (24.7%)\n",
      "\n",
      "9. Transformando h15_respiracao...\n",
      "   Sim: 322 casos (16.4%)\n",
      "\n",
      "10. Transformando h16_canseira...\n",
      "   Sim: 157 casos (8.0%)\n",
      "\n",
      "11. Transformando h17_nariz...\n",
      "   Sim: 636 casos (32.4%)\n",
      "\n",
      "12. Transformando h18_ronqueira...\n",
      "   Sim: 402 casos (20.5%)\n",
      "\n",
      "13. Transformando h19_febre...\n",
      "   Sim: 297 casos (15.2%)\n",
      "\n",
      "Exclu√≠da: h10b1_sindrome_nao\n",
      "\n",
      "Exclu√≠da: h11_alergia\n",
      "\n",
      "Exclu√≠da: h20_outro_problema\n",
      "\n",
      "Exclu√≠da: h21_internado\n",
      "\n",
      "Exclu√≠da: h211_internado_respiratoria\n",
      "\n",
      "Exclu√≠da: h212_internado_intestinais\n",
      "\n",
      "Exclu√≠da: h213_internado_acidente\n",
      "\n",
      "Exclu√≠da: h214_internado_alergias\n",
      "\n",
      "Exclu√≠da: h215_internado_outras\n",
      "\n",
      "Total de vari√°veis exclu√≠das: 9\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 2\n",
      "==================================================\n",
      "\n",
      "Valores ausentes em vari√°veis num√©ricas:\n",
      "\n",
      "Distribui√ß√µes das vari√°veis bin√°rias:\n",
      "   h05_chupeta_usou: 824 casos sim (42.0%)\n",
      "   h13_diarreia: 184 casos sim (9.4%)\n",
      "   h14_tosse: 484 casos sim (24.7%)\n",
      "   h15_respiracao: 322 casos sim (16.4%)\n",
      "   h16_canseira: 157 casos sim (8.0%)\n",
      "   h17_nariz: 636 casos sim (32.4%)\n",
      "   h18_ronqueira: 402 casos sim (20.5%)\n",
      "   h19_febre: 297 casos sim (15.2%)\n",
      "\n",
      "Resumo do lote:\n",
      "   Features criadas com one-hot: 6\n",
      "   Vari√°veis bin√°rias transformadas: 8\n",
      "   Vari√°veis num√©ricas mantidas: 3\n",
      "   Vari√°veis exclu√≠das: 9\n",
      "\n",
      "Dataset transformado salvo: (1960, 173)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Colunas atuais (primeiras 30):\n",
      "['aleitamento_materno_exclusivo', 'id_anon', 'regiao_Centro-Oeste', 'regiao_Nordeste', 'regiao_Norte', 'regiao_Sudeste', 'regiao_Sul', 'a11_situacao', 'b02_sexo', 'b03_relacao', 'b05a_idade_em_meses', 'bb04_idade_da_mae', 'cor_Branca', 'cor_Outras', 'cor_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_Preta', 'f001_esta_usando', 'g001_usou', 'h01_semanas_gravidez', 'h02_peso', 'h03_altura', 'parto_Cesariana agendada (eletiva)', 'parto_Cesariana de urg√™ncia (N√£o agendada)', 'parto_Normal', 'h05_chupeta_usou', 'consulta_Outros', 'consulta_Privado', 'consulta_P√∫blico', 'h13_diarreia', 'h14_tosse']\n",
      "\n",
      "√öltimas colunas:\n",
      "['vd_suplemento', 'vd_suplemento_sus', 'vd_suplemento_comercial', 'vd_num_supl', 'vd_zwaz', 'vd_zimc', 'vd_zhaz', 'vd_anthro_zwfl', 'vd_prematura_igb', 'vd_imc_mae']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Carregar o dataset j√° transformado do lote 1\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 2 - IN-PLACE\n",
    "# =============================================================================\n",
    "\n",
    "# 1. h01_semanas_gravidez - Manter num√©rica\n",
    "if 'h01_semanas_gravidez' in df.columns:\n",
    "    print(\"\\n1. Verificando h01_semanas_gravidez...\")\n",
    "    df['h01_semanas_gravidez'] = pd.to_numeric(df['h01_semanas_gravidez'], errors='coerce')\n",
    "    print(f\"   Range: {df['h01_semanas_gravidez'].min()} - {df['h01_semanas_gravidez'].max()}\")\n",
    "\n",
    "# 2. h02_peso - Manter num√©rica\n",
    "if 'h02_peso' in df.columns:\n",
    "    print(\"\\n2. Verificando h02_peso...\")\n",
    "    df['h02_peso'] = pd.to_numeric(df['h02_peso'], errors='coerce')\n",
    "    print(f\"   Range: {df['h02_peso'].min()} - {df['h02_peso'].max()}\")\n",
    "\n",
    "# 3. h03_altura - Manter num√©rica\n",
    "if 'h03_altura' in df.columns:\n",
    "    print(\"\\n3. Verificando h03_altura...\")\n",
    "    df['h03_altura'] = pd.to_numeric(df['h03_altura'], errors='coerce')\n",
    "    print(f\"   Range: {df['h03_altura'].min()} - {df['h03_altura'].max()}\")\n",
    "\n",
    "# 4. h04_parto - One-hot encoding\n",
    "if 'h04_parto' in df.columns:\n",
    "    print(\"\\n4. Transformando h04_parto...\")\n",
    "    parto_dummies = pd.get_dummies(df['h04_parto'], prefix='parto', drop_first=False)\n",
    "    # Inserir no lugar da original\n",
    "    col_index = df.columns.get_loc('h04_parto')\n",
    "    df.drop('h04_parto', axis=1, inplace=True)\n",
    "    for i, col in enumerate(parto_dummies.columns):\n",
    "        df.insert(col_index + i, col, parto_dummies[col])\n",
    "    print(f\"   Criadas: {parto_dummies.columns.tolist()}\")\n",
    "\n",
    "# 5. h05_chupeta_usou - Binary (exposi√ß√£o √† chupeta)\n",
    "if 'h05_chupeta_usou' in df.columns:\n",
    "    print(\"\\n5. Transformando h05_chupeta_usou...\")\n",
    "    # Exposi√ß√£o = \"Usa\" ou \"J√° usou\"\n",
    "    exposicao = df['h05_chupeta_usou'].isin(['Usa chupeta', 'J√° usou chupeta, mas n√£o usa mais'])\n",
    "    df['h05_chupeta_usou'] = exposicao.astype(int)\n",
    "    print(f\"   Exposi√ß√£o √† chupeta: {df['h05_chupeta_usou'].sum()} casos ({df['h05_chupeta_usou'].mean()*100:.1f}%)\")\n",
    "\n",
    "# 6. h10_consulta - One-hot encoding simplificado\n",
    "if 'h10_consulta' in df.columns:\n",
    "    print(\"\\n6. Transformando h10_consulta...\")\n",
    "    # Simplificar categorias\n",
    "    consulta_simpl = df['h10_consulta'].copy()\n",
    "    \n",
    "    # P√∫blico: UBS\n",
    "    mask_publico = consulta_simpl.str.contains('Unidade b√°sica|posto|centro de sa√∫de', case=False, na=False)\n",
    "    \n",
    "    # Privado: Particular/cl√≠nica\n",
    "    mask_privado = consulta_simpl.str.contains('particular|cl√≠nica privada', case=False, na=False)\n",
    "    \n",
    "    # Outros: Hospital, n√£o leva, etc.\n",
    "    consulta_simpl.loc[mask_publico] = 'P√∫blico'\n",
    "    consulta_simpl.loc[mask_privado] = 'Privado' \n",
    "    consulta_simpl.loc[~(mask_publico | mask_privado)] = 'Outros'\n",
    "    \n",
    "    # One-hot encoding\n",
    "    consulta_dummies = pd.get_dummies(consulta_simpl, prefix='consulta', drop_first=False)\n",
    "    col_index = df.columns.get_loc('h10_consulta')\n",
    "    df.drop('h10_consulta', axis=1, inplace=True)\n",
    "    for i, col in enumerate(consulta_dummies.columns):\n",
    "        df.insert(col_index + i, col, consulta_dummies[col])\n",
    "    print(f\"   Criadas: {consulta_dummies.columns.tolist()}\")\n",
    "\n",
    "# 7-13. Sintomas - Binary encoding\n",
    "sintomas = ['h13_diarreia', 'h14_tosse', 'h15_respiracao', 'h16_canseira', \n",
    "           'h17_nariz', 'h18_ronqueira', 'h19_febre']\n",
    "\n",
    "for i, sintoma in enumerate(sintomas, 7):\n",
    "    if sintoma in df.columns:\n",
    "        print(f\"\\n{i}. Transformando {sintoma}...\")\n",
    "        df[sintoma] = (df[sintoma] == 'Sim').astype(int)\n",
    "        print(f\"   Sim: {df[sintoma].sum()} casos ({df[sintoma].mean()*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES - CRIT√âRIO <5%\n",
    "# =============================================================================\n",
    "\n",
    "vars_to_exclude = [\n",
    "    'h10b1_sindrome_nao',      # 0.8%\n",
    "    'h11_alergia',             # 1.5%\n",
    "    'h20_outro_problema',      # 3.0%\n",
    "    'h21_internado',           # c√≥digos confusos\n",
    "    'h211_internado_respiratoria',  # 2.1%\n",
    "    'h212_internado_intestinais',   # 0.5%\n",
    "    'h213_internado_acidente',      # 0.3%\n",
    "    'h214_internado_alergias',      # 0.2%\n",
    "    'h215_internado_outras'         # 3.3%\n",
    "]\n",
    "\n",
    "excluded_count = 0\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "        print(f\"\\nExclu√≠da: {var}\")\n",
    "\n",
    "print(f\"\\nTotal de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 2\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar valores missing nas transforma√ß√µes\n",
    "print(\"\\nValores ausentes em vari√°veis num√©ricas:\")\n",
    "numeric_vars = ['h01_semanas_gravidez', 'h02_peso', 'h03_altura']\n",
    "for var in numeric_vars:\n",
    "    if var in df.columns:\n",
    "        missing = df[var].isna().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"   {var}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verificar distribui√ß√µes das transforma√ß√µes bin√°rias\n",
    "print(\"\\nDistribui√ß√µes das vari√°veis bin√°rias:\")\n",
    "binary_vars = ['h05_chupeta_usou'] + sintomas\n",
    "for var in binary_vars:\n",
    "    if var in df.columns:\n",
    "        ones = df[var].sum()\n",
    "        print(f\"   {var}: {ones} casos sim ({ones/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Contar features criadas vs exclu√≠das\n",
    "features_created = 0\n",
    "if 'parto_Cesariana agendada (eletiva)' in df.columns:\n",
    "    features_created += 3  # parto\n",
    "if 'consulta_Outros' in df.columns:\n",
    "    features_created += 3  # consulta\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Features criadas com one-hot: {features_created}\")\n",
    "print(f\"   Vari√°veis bin√°rias transformadas: {len([v for v in binary_vars if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis num√©ricas mantidas: {len([v for v in numeric_vars if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "# Mostrar estrutura atual\n",
    "print(f\"\\nColunas atuais (primeiras 30):\")\n",
    "print(df.columns[:30].tolist())\n",
    "\n",
    "print(f\"\\n√öltimas colunas:\")\n",
    "print(df.columns[-10:].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31aa70c",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 3\n",
    "\n",
    "## Vari√°veis Processadas (Lote 3/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Excluir vari√°veis com <5% na categoria minorit√°ria + eliminar redund√¢ncias\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `j03_cor` | **One-hot encoding** (4 colunas) | Branca (38.2%), Parda (49.8%), Preta (10.7%), Outras (1.3%) |\n",
    "| `j04_vive` | **Binary** (0=N√£o, 1=Sim) | Vive com companheiro: 75.3% vs 24.7% |\n",
    "\n",
    "### TRANSFORMA√á√ÉO ESPECIAL: RELIGI√ÉO\n",
    "\n",
    "**Problema identificado**: Redund√¢ncia total entre `j05_religiao` (c√≥digos A,B,C...) e vari√°veis `j0501` a `j0509` (mesma informa√ß√£o)\n",
    "\n",
    "**Solu√ß√£o**: Criar 4 agrupamentos cientificamente defens√°veis\n",
    "\n",
    "| Novo Agrupamento | Composi√ß√£o | Percentual |\n",
    "|------------------|------------|------------|\n",
    "| `religiao_catolica` | j0501_rel_catolica | 43.8% |\n",
    "| `religiao_evangelica` | j0502_tradicional + j0503_pentecostal + j0506_protestante | ~38.0% |\n",
    "| `religiao_sem_religiao` | j0508_rel_sem_religiao | 11.8% |\n",
    "| `religiao_outras` | j0504_espirita + j0505_afro + j0507_budista + j0509_outra | ~3.0% |\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | % Categoria Minorit√°ria | Motivo |\n",
    "|----------|------------------------|---------|\n",
    "| `h216_internado_nao` | 6.3% | Redundante com outras vari√°veis de interna√ß√£o |\n",
    "| `h219_internado_nao_sabe` | 0.2% | Varia√ß√£o insuficiente |\n",
    "| `i993_faltou_alguma_refeicao` | 2.4% | Abaixo do limiar 5% |\n",
    "| `j05_religiao` | N/A | C√≥digos confusos, redundante com j0501-j0509 |\n",
    "| `j0501_rel_catolica` | N/A | Substitu√≠da por agrupamento |\n",
    "| `j0502_rel_evangelica_tradicional` | N/A | Substitu√≠da por agrupamento |\n",
    "| `j0503_rel_evangelica_pentecostal` | N/A | Substitu√≠da por agrupamento |\n",
    "| `j0504_rel_espirita_kardecista` | 1.1% | Incorporada em \"outras\" |\n",
    "| `j0505_rel_afro_brasileira` | 1.1% | Incorporada em \"outras\" |\n",
    "| `j0506_rel_protestante_historica` | 1.5% | Incorporada em \"evangelica\" |\n",
    "| `j0507_rel_budista` | 0.7% | Incorporada em \"outras\" |\n",
    "| `j0508_rel_sem_religiao` | N/A | Substitu√≠da por agrupamento |\n",
    "| `j0509_rel_outra_religiao` | 0.2% | Incorporada em \"outras\" |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 3\n",
    "- **Vari√°veis originais**: 15\n",
    "- **Features resultantes**: 10 (4 cor + 1 vive companheiro + 4 religi√£o + 1 religi√£o ref)\n",
    "- **Vari√°veis exclu√≠das**: 11\n",
    "- **Taxa de exclus√£o**: 73.3% (alta devido √† redund√¢ncia religiosa)\n",
    "\n",
    "---\n",
    "\n",
    "## Inova√ß√£o Metodol√≥gica\n",
    "- **Elimina√ß√£o de redund√¢ncia**: Solu√ß√£o elegante para vari√°veis que capturam a mesma informa√ß√£o\n",
    "- **Agrupamentos cientificamente v√°lidos**: Religi√£o agrupada por fam√≠lias teol√≥gicas\n",
    "- **Redu√ß√£o dram√°tica de dimensionalidade**: De potenciais 20+ features para 10\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **One-hot religi√£o**: Usar drop='first' para evitar multicolinearidade\n",
    "- **Valida√ß√£o**: Verificar que soma dos agrupamentos religiosos = 100%\n",
    "- **Missing values**: Tratar casos onde m√∫ltiplas religi√µes = \"Sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5b655e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 173)\n",
      "\n",
      "1. Transformando j03_cor...\n",
      "   Criadas: ['cor_mae_Branca', 'cor_mae_Outras', 'cor_mae_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_mae_Preta']\n",
      "\n",
      "2. Transformando j04_vive...\n",
      "   Vive com companheiro: 1476 casos (75.3%)\n",
      "\n",
      "3. Criando agrupamentos de religi√£o...\n",
      "   Vari√°veis de religi√£o encontradas: 9\n",
      "   Cat√≥lica: 858 casos (43.8%)\n",
      "   Evang√©lica: 738 casos (37.7%)\n",
      "   Sem religi√£o: 231 casos (11.8%)\n",
      "   Outras religi√µes: 61 casos (3.1%)\n",
      "\n",
      "Exclu√≠da: h216_internado_nao\n",
      "\n",
      "Exclu√≠da: h219_internado_nao_sabe\n",
      "\n",
      "Exclu√≠da: i993_faltou_alguma_refeicao\n",
      "\n",
      "Exclu√≠da: j05_religiao\n",
      "\n",
      "Exclu√≠da: j0501_rel_catolica\n",
      "\n",
      "Exclu√≠da: j0502_rel_evangelica_tradicional\n",
      "\n",
      "Exclu√≠da: j0503_rel_evangelica_pentecostal\n",
      "\n",
      "Exclu√≠da: j0504_rel_espirita_kardecista\n",
      "\n",
      "Exclu√≠da: j0505_rel_afro_brasileira\n",
      "\n",
      "Exclu√≠da: j0506_rel_protestante_historica\n",
      "\n",
      "Exclu√≠da: j0507_rel_budista\n",
      "\n",
      "Exclu√≠da: j0508_rel_sem_religiao\n",
      "\n",
      "Exclu√≠da: j0509_rel_outra_religiao\n",
      "\n",
      "Total de vari√°veis exclu√≠das: 13\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 3\n",
      "==================================================\n",
      "\n",
      "Verifica√ß√£o agrupamentos religiosos:\n",
      "   Casos com m√∫ltiplas religi√µes: 17\n",
      "   Casos sem religi√£o definida: 89\n",
      "   religiao_catolica: 858 casos (43.8%)\n",
      "   religiao_evangelica: 738 casos (37.7%)\n",
      "   religiao_sem_religiao: 231 casos (11.8%)\n",
      "   religiao_outras: 61 casos (3.1%)\n",
      "\n",
      "Distribui√ß√£o cor da m√£e:\n",
      "   cor_mae_Branca: 748 casos (38.2%)\n",
      "   cor_mae_Outras: 26 casos (1.3%)\n",
      "   cor_mae_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa): 977 casos (49.8%)\n",
      "   cor_mae_Preta: 209 casos (10.7%)\n",
      "\n",
      "Vive com companheiro: 1476 casos (75.3%)\n",
      "\n",
      "Resumo do lote:\n",
      "   Vari√°veis de cor da m√£e: 4\n",
      "   Vari√°veis de religi√£o: 4\n",
      "   Vari√°vel vive companheiro: Sim\n",
      "   Total de vari√°veis exclu√≠das: 13\n",
      "\n",
      "Dataset transformado salvo: (1960, 167)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Novos features criados:\n",
      "['cor_mae_Branca', 'cor_mae_Outras', 'cor_mae_Parda (mulata, cabocla, cafuza, mameluca ou mesti√ßa)', 'cor_mae_Preta', 'j04_vive', 'religiao_catolica', 'religiao_evangelica', 'religiao_sem_religiao', 'religiao_outras']\n",
      "\n",
      "Primeiras 10 colunas atuais:\n",
      "['aleitamento_materno_exclusivo', 'id_anon', 'regiao_Centro-Oeste', 'regiao_Nordeste', 'regiao_Norte', 'regiao_Sudeste', 'regiao_Sul', 'a11_situacao', 'b02_sexo', 'b03_relacao']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 3 - IN-PLACE\n",
    "# =============================================================================\n",
    "\n",
    "# 1. j03_cor - One-hot encoding com agrupamento\n",
    "if 'j03_cor' in df.columns:\n",
    "    print(\"\\n1. Transformando j03_cor...\")\n",
    "    # Agrupar categorias pequenas\n",
    "    cor_mae_grouped = df['j03_cor'].copy()\n",
    "    mask_outras = cor_mae_grouped.isin(['Amarela (origem japonesa, chinesa, coreana etc.)', 'Ind√≠gena'])\n",
    "    cor_mae_grouped.loc[mask_outras] = 'Outras'\n",
    "    \n",
    "    # One-hot encoding\n",
    "    cor_mae_dummies = pd.get_dummies(cor_mae_grouped, prefix='cor_mae', drop_first=False)\n",
    "    # Inserir no lugar da original\n",
    "    col_index = df.columns.get_loc('j03_cor')\n",
    "    df.drop('j03_cor', axis=1, inplace=True)\n",
    "    for i, col in enumerate(cor_mae_dummies.columns):\n",
    "        df.insert(col_index + i, col, cor_mae_dummies[col])\n",
    "    print(f\"   Criadas: {cor_mae_dummies.columns.tolist()}\")\n",
    "\n",
    "# 2. j04_vive - Binary encoding\n",
    "if 'j04_vive' in df.columns:\n",
    "    print(\"\\n2. Transformando j04_vive...\")\n",
    "    df['j04_vive'] = (df['j04_vive'] == 'Sim').astype(int)\n",
    "    print(f\"   Vive com companheiro: {df['j04_vive'].sum()} casos ({df['j04_vive'].mean()*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ÉO ESPECIAL: RELIGI√ÉO - CRIAR AGRUPAMENTOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n3. Criando agrupamentos de religi√£o...\")\n",
    "\n",
    "# Verificar quais vari√°veis de religi√£o existem\n",
    "rel_vars = ['j0501_rel_catolica', 'j0502_rel_evangelica_tradicional', 'j0503_rel_evangelica_pentecostal',\n",
    "           'j0504_rel_espirita_kardecista', 'j0505_rel_afro_brasileira', 'j0506_rel_protestante_historica',\n",
    "           'j0507_rel_budista', 'j0508_rel_sem_religiao', 'j0509_rel_outra_religiao']\n",
    "\n",
    "existing_rel_vars = [var for var in rel_vars if var in df.columns]\n",
    "print(f\"   Vari√°veis de religi√£o encontradas: {len(existing_rel_vars)}\")\n",
    "\n",
    "if existing_rel_vars:\n",
    "    # Posi√ß√£o para inserir as novas vari√°veis (ap√≥s j04_vive)\n",
    "    if 'j04_vive' in df.columns:\n",
    "        insert_pos = df.columns.get_loc('j04_vive') + 1\n",
    "    else:\n",
    "        insert_pos = len(df.columns)\n",
    "    \n",
    "    # 1. Cat√≥lica\n",
    "    if 'j0501_rel_catolica' in df.columns:\n",
    "        religiao_catolica = (df['j0501_rel_catolica'] == 'Sim').astype(int)\n",
    "        df.insert(insert_pos, 'religiao_catolica', religiao_catolica)\n",
    "        insert_pos += 1\n",
    "        print(f\"   Cat√≥lica: {religiao_catolica.sum()} casos ({religiao_catolica.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # 2. Evang√©lica (soma de 3 tipos)\n",
    "    evangelica_vars = ['j0502_rel_evangelica_tradicional', 'j0503_rel_evangelica_pentecostal', \n",
    "                      'j0506_rel_protestante_historica']\n",
    "    evangelica_existing = [var for var in evangelica_vars if var in df.columns]\n",
    "    \n",
    "    if evangelica_existing:\n",
    "        religiao_evangelica = 0\n",
    "        for var in evangelica_existing:\n",
    "            religiao_evangelica += (df[var] == 'Sim').astype(int)\n",
    "        religiao_evangelica = (religiao_evangelica > 0).astype(int)  # Se pelo menos uma = 1\n",
    "        df.insert(insert_pos, 'religiao_evangelica', religiao_evangelica)\n",
    "        insert_pos += 1\n",
    "        print(f\"   Evang√©lica: {religiao_evangelica.sum()} casos ({religiao_evangelica.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # 3. Sem religi√£o\n",
    "    if 'j0508_rel_sem_religiao' in df.columns:\n",
    "        religiao_sem_religiao = (df['j0508_rel_sem_religiao'] == 'Sim').astype(int)\n",
    "        df.insert(insert_pos, 'religiao_sem_religiao', religiao_sem_religiao)\n",
    "        insert_pos += 1\n",
    "        print(f\"   Sem religi√£o: {religiao_sem_religiao.sum()} casos ({religiao_sem_religiao.mean()*100:.1f}%)\")\n",
    "    \n",
    "    # 4. Outras religi√µes (soma de 4 tipos)\n",
    "    outras_vars = ['j0504_rel_espirita_kardecista', 'j0505_rel_afro_brasileira', \n",
    "                  'j0507_rel_budista', 'j0509_rel_outra_religiao']\n",
    "    outras_existing = [var for var in outras_vars if var in df.columns]\n",
    "    \n",
    "    if outras_existing:\n",
    "        religiao_outras = 0\n",
    "        for var in outras_existing:\n",
    "            religiao_outras += (df[var] == 'Sim').astype(int)\n",
    "        religiao_outras = (religiao_outras > 0).astype(int)  # Se pelo menos uma = 1\n",
    "        df.insert(insert_pos, 'religiao_outras', religiao_outras)\n",
    "        print(f\"   Outras religi√µes: {religiao_outras.sum()} casos ({religiao_outras.mean()*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES\n",
    "# =============================================================================\n",
    "\n",
    "# Excluir vari√°veis com <5% ou redundantes\n",
    "vars_to_exclude = [\n",
    "    'h216_internado_nao',          # redundante\n",
    "    'h219_internado_nao_sabe',     # 0.2%\n",
    "    'i993_faltou_alguma_refeicao', # 2.4%\n",
    "    'j05_religiao'                 # c√≥digos confusos, redundante\n",
    "] + existing_rel_vars  # todas as vari√°veis individuais de religi√£o\n",
    "\n",
    "excluded_count = 0\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "        print(f\"\\nExclu√≠da: {var}\")\n",
    "\n",
    "print(f\"\\nTotal de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 3\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar soma das religi√µes\n",
    "rel_cols = [col for col in df.columns if col.startswith('religiao_')]\n",
    "if rel_cols:\n",
    "    print(\"\\nVerifica√ß√£o agrupamentos religiosos:\")\n",
    "    soma_religiao = df[rel_cols].sum(axis=1)\n",
    "    print(f\"   Casos com m√∫ltiplas religi√µes: {(soma_religiao > 1).sum()}\")\n",
    "    print(f\"   Casos sem religi√£o definida: {(soma_religiao == 0).sum()}\")\n",
    "    \n",
    "    for col in rel_cols:\n",
    "        count = df[col].sum()\n",
    "        pct = count/len(df)*100\n",
    "        print(f\"   {col}: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# Verificar cor da m√£e\n",
    "cor_cols = [col for col in df.columns if col.startswith('cor_mae_')]\n",
    "if cor_cols:\n",
    "    print(\"\\nDistribui√ß√£o cor da m√£e:\")\n",
    "    for col in cor_cols:\n",
    "        count = df[col].sum()\n",
    "        pct = count/len(df)*100\n",
    "        print(f\"   {col}: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# Verificar vive com companheiro\n",
    "if 'j04_vive' in df.columns:\n",
    "    count = df['j04_vive'].sum()\n",
    "    pct = count/len(df)*100\n",
    "    print(f\"\\nVive com companheiro: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Vari√°veis de cor da m√£e: {len(cor_cols)}\")\n",
    "print(f\"   Vari√°veis de religi√£o: {len(rel_cols)}\")\n",
    "print(f\"   Vari√°vel vive companheiro: {'Sim' if 'j04_vive' in df.columns else 'N√£o'}\")\n",
    "print(f\"   Total de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "# Mostrar estrutura atual\n",
    "print(f\"\\nNovos features criados:\")\n",
    "new_features = [col for col in df.columns if \n",
    "               col.startswith('cor_mae_') or col.startswith('religiao_') or col == 'j04_vive']\n",
    "print(new_features)\n",
    "\n",
    "print(f\"\\nPrimeiras 10 colunas atuais:\")\n",
    "print(df.columns[:10].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b7b21a",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 4\n",
    "\n",
    "## Vari√°veis Processadas (Lote 4/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Excluir vari√°veis com <5% na categoria minorit√°ria, exceto quando h√° justificativa cient√≠fica\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `j06_ocupacao` | **One-hot encoding** (4 categorias) | Todas >5%: Fora mercado (45.5%), Regular (27.8%), Desempregada (17.6%), Irregular (9.2%) |\n",
    "| `j09_frequenta` | **One-hot encoding** (3 categorias) | Frequenta escola afeta rotina materna: J√° frequentou (90.3%), Frequenta (9.3%), Nunca (0.4%) |\n",
    "| `j10_serie` | **One-hot agrupado** (3 n√≠veis) | Fundamental, M√©dio, Superior - educa√ß√£o materna √© preditor forte |\n",
    "| `k01_gestacoes` | **Num√©rica** | Multiparidade afeta padr√µes de aleitamento |\n",
    "| `k02_filhos_vivos` | **Num√©rica** | Diferente de gesta√ß√µes (abortos, natimortos) |\n",
    "| `k04_prenatal_semanas` | **Num√©rica** | In√≠cio precoce indica engajamento materno |\n",
    "| `k05_prenatal_consultas` | **Num√©rica** | Qualidade do acompanhamento pr√©-natal |\n",
    "| `k06_peso_engravidar` | **Num√©rica** | Estado nutricional pr√©-gestacional |\n",
    "| `k07_peso_final` | **Num√©rica** | Ganho de peso gestacional |\n",
    "| `k08_quilos` | **Num√©rica** (tratar 99.9) | Ganho de peso, valor 99.9 = missing code |\n",
    "| `k12_tempo + k13_tempo_medida` | **Combinada em horas** | Tempo para primeira mamada (preditor v√°lido) |\n",
    "| `k15_recebeu` | **Binary** (0=N√£o, 1=Sim) | Hist√≥rico maternidade n√£o afeta status atual exclusivo |\n",
    "| `k16_liquido` | **Binary** (0=N√£o, 1=Sim) | L√≠quidos pr√©-descida do leite, hist√≥rico v√°lido |\n",
    "| `k20_doou` | **Binary** (0=N√£o, 1=Sim) | Doa√ß√£o indica produ√ß√£o abundante |\n",
    "| `k21_recebeu` | **Binary** (0=N√£o, 1=Sim) | Recebeu banco leite indica necessidade (4.2% mantido) |\n",
    "| `k22_amamentou` | **Binary** (0=N√£o, 1=Sim) | Ama de leite indica confian√ßa/capacidade |\n",
    "| `k23_deixou` | **Binary** (0=N√£o, 1=Sim) | Rede de apoio ao aleitamento |\n",
    "\n",
    "### TRANSFORMA√á√ÉO ESPECIAL: EDUCA√á√ÉO MATERNA\n",
    "\n",
    "**Agrupamento j10_serie**:\n",
    "- **Fundamental**: At√© 8¬™ s√©rie/9¬∫ ano\n",
    "- **M√©dio**: 1¬∫ ao 3¬∫ ano ensino m√©dio  \n",
    "- **Superior**: Superior completo/incompleto\n",
    "\n",
    "### TRANSFORMA√á√ÉO ESPECIAL: TEMPO PRIMEIRA MAMADA\n",
    "\n",
    "**Combina√ß√£o k12_tempo + k13_tempo_medida**:\n",
    "- Se k13 = \"Horas\": usar k12 diretamente\n",
    "- Se k13 = \"Dias\": k12 √ó 24\n",
    "- Resultado: `tempo_primeira_mamada_horas`\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | % Categoria Minorit√°ria | Motivo |\n",
    "|----------|------------------------|---------|\n",
    "| `j0510_rel_ns_nqr` | 4.5% | \"N√£o sabe/n√£o responder\" n√£o √© informativo |\n",
    "| `k03_prenatal` | 1.7% | Varia√ß√£o menor que missing t√≠pico |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 4\n",
    "- **Vari√°veis originais**: 20\n",
    "- **Features resultantes**: ~25\n",
    "- **Vari√°veis exclu√≠das**: 2\n",
    "- **Taxa de exclus√£o**: 10% (baixa, vari√°veis bem distribu√≠das)\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes Metodol√≥gicas\n",
    "\n",
    "### Defini√ß√£o de Aleitamento Materno Exclusivo\n",
    "**Crit√©rio OMS**: Apenas leite materno nas √∫ltimas 24 horas. Hist√≥rico de f√≥rmula/l√≠quidos n√£o impede classifica√ß√£o atual como exclusivo.\n",
    "\n",
    "### Tratamento de Missing Values\n",
    "- **k08_quilos**: Valor 99.9 (6.5% dos casos) tratado como c√≥digo de aus√™ncia\n",
    "- **Vari√°veis k**: ~2-7% missing aceit√°vel, n√£o exclui vari√°veis\n",
    "\n",
    "### Justificativas Cient√≠ficas\n",
    "- **k21_recebeu mantida**: Mesmo 4.2%, indica padr√£o de necessidade/dificuldade\n",
    "- **j09_frequenta mantida**: Mesmo 0.4% nunca frequentou, rotina escolar afeta aleitamento\n",
    "- **k02_filhos_vivos ‚â† k01_gestacoes**: Capturam fen√¥menos diferentes (perdas gestacionais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312f0bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 167)\n",
      "\n",
      "1. Transformando j06_ocupacao...\n",
      "   Criadas: ['ocupacao_Desempregado e ativamente procurando por trabalho', 'ocupacao_Fora do mercado de trabalho, n√£o trabalha e n√£o procura ativamente por trabalho', 'ocupacao_Trabalho irregular e sem hor√°rio fixo (bicos)', 'ocupacao_Trabalho regular ou com hor√°rio fixo']\n",
      "\n",
      "2. Transformando j09_frequenta...\n",
      "   Criadas: ['frequenta_Frequenta', 'frequenta_J√° frequentou', 'frequenta_Nunca frequentou']\n",
      "\n",
      "3. Transformando j10_serie...\n",
      "   Criadas: ['educacao_Fundamental', 'educacao_M√©dio', 'educacao_Sem estudo', 'educacao_Superior']\n",
      "\n",
      "4. Verificando k01_gestacoes...\n",
      "   Range: 1.0 - 10.0\n",
      "   Missing: 40 (2.0%)\n",
      "\n",
      "5. Verificando k02_filhos_vivos...\n",
      "   Range: 1.0 - 10.0\n",
      "   Missing: 40 (2.0%)\n",
      "\n",
      "6. Verificando k04_prenatal_semanas...\n",
      "   Range: 1.0 - 40.0\n",
      "   Missing: 119 (6.1%)\n",
      "\n",
      "7. Verificando k05_prenatal_consultas...\n",
      "   Range: 1.0 - 40.0\n",
      "   Missing: 130 (6.6%)\n",
      "\n",
      "8. Verificando k06_peso_engravidar...\n",
      "   Range: 35.0 - 133.0\n",
      "   Missing: 140 (7.1%)\n",
      "\n",
      "9. Verificando k07_peso_final...\n",
      "   Range: 38.0 - 138.0\n",
      "   Missing: 137 (7.0%)\n",
      "\n",
      "10. Transformando k08_quilos...\n",
      "   Valores 99.9 convertidos para missing\n",
      "   Range: 0.0 - 65.0\n",
      "   Missing total: 164 (8.4%)\n",
      "\n",
      "11. Combinando k12_tempo + k13_tempo_medida...\n",
      "   Range: 0.0 - 1440.0 horas\n",
      "   Missing: 83 (4.2%)\n",
      "\n",
      "12. Transformando k15_recebeu...\n",
      "   Sim: 405 casos (20.7%)\n",
      "\n",
      "13. Transformando k16_liquido...\n",
      "   Sim: 286 casos (14.6%)\n",
      "\n",
      "14. Transformando k20_doou...\n",
      "   Sim: 121 casos (6.2%)\n",
      "\n",
      "15. Transformando k21_recebeu...\n",
      "   Sim: 79 casos (4.0%)\n",
      "\n",
      "16. Transformando k22_amamentou...\n",
      "   Sim: 162 casos (8.3%)\n",
      "\n",
      "17. Transformando k23_deixou...\n",
      "   Sim: 125 casos (6.4%)\n",
      "\n",
      "Exclu√≠da: j0510_rel_ns_nqr\n",
      "\n",
      "Exclu√≠da: k03_prenatal\n",
      "\n",
      "Total de vari√°veis exclu√≠das: 2\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 4\n",
      "==================================================\n",
      "\n",
      "Features criadas:\n",
      "   Ocupa√ß√£o: 4 colunas\n",
      "   Frequenta escola: 3 colunas\n",
      "   Educa√ß√£o: 4 colunas\n",
      "\n",
      "Vari√°veis num√©ricas mantidas:\n",
      "   k01_gestacoes: 40 missing (2.0%)\n",
      "   k02_filhos_vivos: 40 missing (2.0%)\n",
      "   k04_prenatal_semanas: 119 missing (6.1%)\n",
      "   k05_prenatal_consultas: 130 missing (6.6%)\n",
      "   k06_peso_engravidar: 140 missing (7.1%)\n",
      "   k07_peso_final: 137 missing (7.0%)\n",
      "   k08_quilos: 164 missing (8.4%)\n",
      "   tempo_primeira_mamada_horas: 83 missing (4.2%)\n",
      "\n",
      "Vari√°veis de aleitamento (% Sim):\n",
      "   k15_recebeu: 20.7%\n",
      "   k16_liquido: 14.6%\n",
      "   k20_doou: 6.2%\n",
      "   k21_recebeu: 4.0%\n",
      "   k22_amamentou: 8.3%\n",
      "   k23_deixou: 6.4%\n",
      "\n",
      "Resumo do lote:\n",
      "   Features one-hot criadas: 11\n",
      "   Vari√°veis num√©ricas: 7\n",
      "   Vari√°veis binary: 6\n",
      "   Vari√°vel tempo combinada: Sim\n",
      "   Total exclu√≠das: 2\n",
      "\n",
      "Dataset transformado salvo: (1960, 172)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Novas features criadas neste lote:\n",
      "   ocupacao_Desempregado e ativamente procurando por trabalho\n",
      "   ocupacao_Fora do mercado de trabalho, n√£o trabalha e n√£o procura ativamente por trabalho\n",
      "   ocupacao_Trabalho irregular e sem hor√°rio fixo (bicos)\n",
      "   ocupacao_Trabalho regular ou com hor√°rio fixo\n",
      "   frequenta_Frequenta\n",
      "   frequenta_J√° frequentou\n",
      "   frequenta_Nunca frequentou\n",
      "   educacao_Fundamental\n",
      "   educacao_M√©dio\n",
      "   educacao_Sem estudo\n",
      "   educacao_Superior\n",
      "   tempo_primeira_mamada_horas\n",
      "\n",
      "Total de colunas atual: 172\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 4 - IN-PLACE\n",
    "# =============================================================================\n",
    "\n",
    "# 1. j06_ocupacao - One-hot encoding\n",
    "if 'j06_ocupacao' in df.columns:\n",
    "    print(\"\\n1. Transformando j06_ocupacao...\")\n",
    "    ocupacao_dummies = pd.get_dummies(df['j06_ocupacao'], prefix='ocupacao', drop_first=False)\n",
    "    # Inserir no lugar da original\n",
    "    col_index = df.columns.get_loc('j06_ocupacao')\n",
    "    df.drop('j06_ocupacao', axis=1, inplace=True)\n",
    "    for i, col in enumerate(ocupacao_dummies.columns):\n",
    "        df.insert(col_index + i, col, ocupacao_dummies[col])\n",
    "    print(f\"   Criadas: {ocupacao_dummies.columns.tolist()}\")\n",
    "\n",
    "# 2. j09_frequenta - One-hot encoding\n",
    "if 'j09_frequenta' in df.columns:\n",
    "    print(\"\\n2. Transformando j09_frequenta...\")\n",
    "    frequenta_dummies = pd.get_dummies(df['j09_frequenta'], prefix='frequenta', drop_first=False)\n",
    "    col_index = df.columns.get_loc('j09_frequenta')\n",
    "    df.drop('j09_frequenta', axis=1, inplace=True)\n",
    "    for i, col in enumerate(frequenta_dummies.columns):\n",
    "        df.insert(col_index + i, col, frequenta_dummies[col])\n",
    "    print(f\"   Criadas: {frequenta_dummies.columns.tolist()}\")\n",
    "\n",
    "# 3. j10_serie - One-hot agrupado por n√≠veis educacionais\n",
    "if 'j10_serie' in df.columns:\n",
    "    print(\"\\n3. Transformando j10_serie...\")\n",
    "    \n",
    "    # Criar agrupamentos educacionais\n",
    "    educacao_agrupada = df['j10_serie'].copy()\n",
    "    \n",
    "    # Fundamental: at√© 8¬™ s√©rie/9¬∫ ano\n",
    "    mask_fundamental = educacao_agrupada.str.contains('fundamental|s√©rie', case=False, na=False)\n",
    "    \n",
    "    # M√©dio: 1¬∫ ao 3¬∫ ano ensino m√©dio\n",
    "    mask_medio = educacao_agrupada.str.contains('m√©dio', case=False, na=False)\n",
    "    \n",
    "    # Superior: completo ou incompleto\n",
    "    mask_superior = educacao_agrupada.str.contains('superior', case=False, na=False)\n",
    "    \n",
    "    # Aplicar agrupamentos\n",
    "    educacao_agrupada.loc[mask_fundamental] = 'Fundamental'\n",
    "    educacao_agrupada.loc[mask_medio] = 'M√©dio'\n",
    "    educacao_agrupada.loc[mask_superior] = 'Superior'\n",
    "    \n",
    "    # One-hot encoding\n",
    "    educacao_dummies = pd.get_dummies(educacao_agrupada, prefix='educacao', drop_first=False)\n",
    "    col_index = df.columns.get_loc('j10_serie')\n",
    "    df.drop('j10_serie', axis=1, inplace=True)\n",
    "    for i, col in enumerate(educacao_dummies.columns):\n",
    "        df.insert(col_index + i, col, educacao_dummies[col])\n",
    "    print(f\"   Criadas: {educacao_dummies.columns.tolist()}\")\n",
    "\n",
    "# 4-9. Vari√°veis num√©ricas - verificar e manter\n",
    "numeric_vars = ['k01_gestacoes', 'k02_filhos_vivos', 'k04_prenatal_semanas', \n",
    "               'k05_prenatal_consultas', 'k06_peso_engravidar', 'k07_peso_final']\n",
    "\n",
    "for i, var in enumerate(numeric_vars, 4):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Verificando {var}...\")\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
    "        print(f\"   Range: {df[var].min()} - {df[var].max()}\")\n",
    "        missing = df[var].isna().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 10. k08_quilos - Tratar valor 99.9 como missing\n",
    "if 'k08_quilos' in df.columns:\n",
    "    print(\"\\n10. Transformando k08_quilos...\")\n",
    "    # Substituir 99.9 por NaN\n",
    "    df['k08_quilos'] = df['k08_quilos'].replace(99.9, np.nan)\n",
    "    df['k08_quilos'] = pd.to_numeric(df['k08_quilos'], errors='coerce')\n",
    "    missing_total = df['k08_quilos'].isna().sum()\n",
    "    print(f\"   Valores 99.9 convertidos para missing\")\n",
    "    print(f\"   Range: {df['k08_quilos'].min()} - {df['k08_quilos'].max()}\")\n",
    "    print(f\"   Missing total: {missing_total} ({missing_total/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 11. k12_tempo + k13_tempo_medida - Combinar em horas\n",
    "if 'k12_tempo' in df.columns and 'k13_tempo_medida' in df.columns:\n",
    "    print(\"\\n11. Combinando k12_tempo + k13_tempo_medida...\")\n",
    "    \n",
    "    # Converter tempo para horas\n",
    "    tempo_horas = df['k12_tempo'].copy()\n",
    "    \n",
    "    # Converter dias para horas\n",
    "    mask_dias = df['k13_tempo_medida'] == 'Dias'\n",
    "    tempo_horas.loc[mask_dias] = tempo_horas.loc[mask_dias] * 24\n",
    "    \n",
    "    # Inserir nova vari√°vel no lugar de k12_tempo\n",
    "    col_index = df.columns.get_loc('k12_tempo')\n",
    "    df.insert(col_index, 'tempo_primeira_mamada_horas', tempo_horas)\n",
    "    \n",
    "    # Remover vari√°veis originais\n",
    "    df.drop(['k12_tempo', 'k13_tempo_medida'], axis=1, inplace=True)\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    print(f\"   Range: {tempo_horas.min()} - {tempo_horas.max()} horas\")\n",
    "    missing = tempo_horas.isna().sum()\n",
    "    print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 12-17. Vari√°veis de aleitamento - Binary encoding\n",
    "aleitamento_vars = ['k15_recebeu', 'k16_liquido', 'k20_doou', 'k21_recebeu', \n",
    "                   'k22_amamentou', 'k23_deixou']\n",
    "\n",
    "for i, var in enumerate(aleitamento_vars, 12):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Transformando {var}...\")\n",
    "        df[var] = (df[var] == 'Sim').astype(int)\n",
    "        count = df[var].sum()\n",
    "        print(f\"   Sim: {count} casos ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES\n",
    "# =============================================================================\n",
    "\n",
    "vars_to_exclude = [\n",
    "    'j0510_rel_ns_nqr',    # 4.5%, n√£o informativo\n",
    "    'k03_prenatal'         # 1.7%, varia√ß√£o insuficiente\n",
    "]\n",
    "\n",
    "excluded_count = 0\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "        print(f\"\\nExclu√≠da: {var}\")\n",
    "\n",
    "print(f\"\\nTotal de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 4\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Contar features criadas\n",
    "ocupacao_cols = [col for col in df.columns if col.startswith('ocupacao_')]\n",
    "frequenta_cols = [col for col in df.columns if col.startswith('frequenta_')]\n",
    "educacao_cols = [col for col in df.columns if col.startswith('educacao_')]\n",
    "\n",
    "print(f\"\\nFeatures criadas:\")\n",
    "print(f\"   Ocupa√ß√£o: {len(ocupacao_cols)} colunas\")\n",
    "print(f\"   Frequenta escola: {len(frequenta_cols)} colunas\")\n",
    "print(f\"   Educa√ß√£o: {len(educacao_cols)} colunas\")\n",
    "\n",
    "# Verificar vari√°veis num√©ricas\n",
    "print(f\"\\nVari√°veis num√©ricas mantidas:\")\n",
    "for var in numeric_vars + ['k08_quilos']:\n",
    "    if var in df.columns:\n",
    "        missing = df[var].isna().sum()\n",
    "        print(f\"   {var}: {missing} missing ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verificar tempo primeira mamada\n",
    "if 'tempo_primeira_mamada_horas' in df.columns:\n",
    "    missing = df['tempo_primeira_mamada_horas'].isna().sum()\n",
    "    print(f\"   tempo_primeira_mamada_horas: {missing} missing ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verificar vari√°veis de aleitamento\n",
    "print(f\"\\nVari√°veis de aleitamento (% Sim):\")\n",
    "for var in aleitamento_vars:\n",
    "    if var in df.columns:\n",
    "        pct = df[var].mean() * 100\n",
    "        print(f\"   {var}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Features one-hot criadas: {len(ocupacao_cols + frequenta_cols + educacao_cols)}\")\n",
    "print(f\"   Vari√°veis num√©ricas: {len([v for v in numeric_vars + ['k08_quilos'] if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis binary: {len([v for v in aleitamento_vars if v in df.columns])}\")\n",
    "print(f\"   Vari√°vel tempo combinada: {'Sim' if 'tempo_primeira_mamada_horas' in df.columns else 'N√£o'}\")\n",
    "print(f\"   Total exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "# Mostrar colunas criadas neste lote\n",
    "new_features = ocupacao_cols + frequenta_cols + educacao_cols\n",
    "if 'tempo_primeira_mamada_horas' in df.columns:\n",
    "    new_features.append('tempo_primeira_mamada_horas')\n",
    "\n",
    "print(f\"\\nNovas features criadas neste lote:\")\n",
    "for feature in new_features:\n",
    "    print(f\"   {feature}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas atual: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d06d95",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 5\n",
    "\n",
    "## Vari√°veis Processadas (Lote 5/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Consolidar vari√°veis redundantes em conceito √∫nico + excluir <5%\n",
    "\n",
    "### TRANSFORMA√á√ÉO PRINCIPAL: APOIO √Ä AMAMENTA√á√ÉO\n",
    "\n",
    "**Problema identificado**: 10 vari√°veis capturam o mesmo conceito (uso de apoios/utens√≠lios para amamenta√ß√£o)\n",
    "\n",
    "**Solu√ß√£o**: Criar vari√°vel bin√°ria √∫nica `utilizou_apoio_amamentacao`\n",
    "\n",
    "| Componentes da Nova Vari√°vel | % Uso Individual | Inclu√≠da |\n",
    "|------------------------------|------------------|----------|\n",
    "| `k241_utilizou_concha` | 4.6% | ‚úÖ Sim |\n",
    "| `k242_utilizou_protetor` | 10.1% | ‚úÖ Sim |\n",
    "| `k243_utilizou_bico` | 7.9% | ‚úÖ Sim |\n",
    "| `k244_utilizou_bomba` | 19.9% | ‚úÖ Sim |\n",
    "| `k245_utilizou_mamadeira` | 11.8% | ‚úÖ Sim |\n",
    "\n",
    "**L√≥gica da Vari√°vel:**\n",
    "- `utilizou_apoio_amamentacao = 1`: Se usou QUALQUER dos apoios acima\n",
    "- `utilizou_apoio_amamentacao = 0`: Se n√£o usou NENHUM apoio\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | % Categoria Minorit√°ria | Motivo |\n",
    "|----------|------------------------|---------|\n",
    "| `k24_utilizou` | N/A | C√≥digos confusos (A,B,C,D,E,H,I...), redundante |\n",
    "| `k246_utilizou_sondinha` | 1.1% | Abaixo do limiar 5% |\n",
    "| `k247_utilizou_copo` | 3.6% | Abaixo do limiar 5% |\n",
    "| `k248_utilizou_nao` | N/A | Redundante com nova vari√°vel bin√°ria |\n",
    "| `k249_utilizou_nao_sabe` | 1.6% | \"N√£o sabe\" n√£o √© informativo |\n",
    "| `k241_utilizou_concha` | N/A | Incorporada na vari√°vel consolidada |\n",
    "| `k242_utilizou_protetor` | N/A | Incorporada na vari√°vel consolidada |\n",
    "| `k243_utilizou_bico` | N/A | Incorporada na vari√°vel consolidada |\n",
    "| `k244_utilizou_bomba` | N/A | Incorporada na vari√°vel consolidada |\n",
    "| `k245_utilizou_mamadeira` | N/A | Incorporada na vari√°vel consolidada |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 5\n",
    "- **Vari√°veis originais**: 10\n",
    "- **Features resultantes**: 1\n",
    "- **Vari√°veis exclu√≠das**: 10 (todas consolidadas ou removidas)\n",
    "- **Taxa de redu√ß√£o**: 90% (redu√ß√£o dram√°tica de dimensionalidade)\n",
    "\n",
    "---\n",
    "\n",
    "## Justificativas Metodol√≥gicas\n",
    "\n",
    "### Inclus√£o da Mamadeira\n",
    "**Decis√£o**: Incluir k245_utilizou_mamadeira na vari√°vel de apoio\n",
    "**Justificativa**: Uso hist√≥rico de mamadeira n√£o impede status atual de aleitamento exclusivo (√∫ltimas 24h)\n",
    "\n",
    "### Conceito Cient√≠fico\n",
    "**\"Utilizou apoio √† amamenta√ß√£o\"** captura:\n",
    "- Necessidade de suporte t√©cnico\n",
    "- Dificuldades ou desafios na amamenta√ß√£o\n",
    "- Acesso a recursos de apoio\n",
    "- Engajamento com pr√°ticas de suporte ao aleitamento\n",
    "\n",
    "### Vantagens da Consolida√ß√£o\n",
    "1. **Redu√ß√£o de dimensionalidade**: 10 ‚Üí 1 vari√°vel\n",
    "2. **Conceito cientificamente coerente**: Apoio vs. sem apoio\n",
    "3. **Elimina redund√¢ncia**: k24_utilizou vs k241-k249\n",
    "4. **Facilita interpreta√ß√£o**: Bin√°ria clara\n",
    "5. **Robusto para regulariza√ß√£o**: Uma vari√°vel bem distribu√≠da vs. m√∫ltiplas esparsas\n",
    "\n",
    "---\n",
    "\n",
    "## Implementa√ß√£o T√©cnica\n",
    "```python\n",
    "# L√≥gica OR: qualquer apoio = 1\n",
    "utilizou_apoio = (\n",
    "    (k241_concha == 'Sim') |\n",
    "    (k242_protetor == 'Sim') |\n",
    "    (k243_bico == 'Sim') |\n",
    "    (k244_bomba == 'Sim') |\n",
    "    (k245_mamadeira == 'Sim')\n",
    ").astype(int)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24920632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 172)\n",
      "\n",
      "Vari√°veis de apoio encontradas: 5\n",
      "\n",
      "1. Criando vari√°vel consolidada 'utilizou_apoio_amamentacao'...\n",
      "   k241_utilizou_concha: 87 casos (4.4%)\n",
      "   k242_utilizou_protetor: 189 casos (9.6%)\n",
      "   k243_utilizou_bico: 149 casos (7.6%)\n",
      "   k244_utilizou_bomba: 374 casos (19.1%)\n",
      "   k245_utilizou_mamadeira: 221 casos (11.3%)\n",
      "\n",
      "Vari√°vel consolidada criada:\n",
      "   utilizou_apoio_amamentacao: 662 casos (33.8%)\n",
      "   Sem apoio: 1298 casos (66.2%)\n",
      "\n",
      "2. Excluindo vari√°veis originais...\n",
      "   Excluindo k24_utilizou: incorporada ou redundante\n",
      "   Excluindo k241_utilizou_concha: incorporada ou redundante\n",
      "   Excluindo k242_utilizou_protetor: incorporada ou redundante\n",
      "   Excluindo k243_utilizou_bico: incorporada ou redundante\n",
      "   Excluindo k244_utilizou_bomba: incorporada ou redundante\n",
      "   Excluindo k245_utilizou_mamadeira: incorporada ou redundante\n",
      "   Excluindo k246_utilizou_sondinha: 20 casos (1.0%) - abaixo do limiar 5%\n",
      "   Excluindo k247_utilizou_copo: 68 casos (3.5%) - abaixo do limiar 5%\n",
      "   Excluindo k248_utilizou_nao: incorporada ou redundante\n",
      "   Excluindo k249_utilizou_nao_sabe: 30 casos (1.5%) - abaixo do limiar 5%\n",
      "\n",
      "Total de vari√°veis exclu√≠das: 10\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 5\n",
      "==================================================\n",
      "\n",
      "Distribui√ß√£o da vari√°vel consolidada:\n",
      "   N√£o utilizou apoio (0): 1298 casos (66.2%)\n",
      "   Utilizou apoio (1): 662 casos (33.8%)\n",
      "   ‚úÖ Sem valores ausentes\n",
      "\n",
      "Redu√ß√£o de dimensionalidade:\n",
      "   Vari√°veis originais processadas: 10\n",
      "   Vari√°vel resultante: 1\n",
      "   Taxa de redu√ß√£o: 90%\n",
      "\n",
      "Resumo do lote:\n",
      "   Conceito capturado: Necessidade de apoio t√©cnico √† amamenta√ß√£o\n",
      "   M√©todo: OR l√≥gico (qualquer apoio = 1)\n",
      "   Vari√°veis consolidadas: 5\n",
      "   Total exclu√≠das: 10\n",
      "   Redu√ß√£o l√≠quida: 9 vari√°veis\n",
      "\n",
      "Dataset transformado salvo: (1960, 163)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Nova vari√°vel criada:\n",
      "   Nome: utilizou_apoio_amamentacao\n",
      "   Tipo: Bin√°ria (0/1)\n",
      "   Posi√ß√£o: Coluna 70\n",
      "\n",
      "Total de colunas atual: 163\n",
      "\n",
      "Verifica√ß√£o final:\n",
      "   Dataset shape: (1960, 163)\n",
      "   Vari√°veis de apoio originais restantes: 0\n",
      "   ‚úÖ Consolida√ß√£o conclu√≠da com sucesso\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ÉO LOTE 5 - CONSOLIDA√á√ÉO DE APOIO √Ä AMAMENTA√á√ÉO\n",
    "# =============================================================================\n",
    "\n",
    "# Verificar quais vari√°veis de apoio existem\n",
    "apoio_vars = ['k241_utilizou_concha', 'k242_utilizou_protetor', 'k243_utilizou_bico', \n",
    "             'k244_utilizou_bomba', 'k245_utilizou_mamadeira']\n",
    "\n",
    "existing_apoio_vars = [var for var in apoio_vars if var in df.columns]\n",
    "print(f\"\\nVari√°veis de apoio encontradas: {len(existing_apoio_vars)}\")\n",
    "\n",
    "if existing_apoio_vars:\n",
    "    print(\"\\n1. Criando vari√°vel consolidada 'utilizou_apoio_amamentacao'...\")\n",
    "    \n",
    "    # Posi√ß√£o para inserir (usar primeira vari√°vel encontrada como refer√™ncia)\n",
    "    insert_pos = df.columns.get_loc(existing_apoio_vars[0])\n",
    "    \n",
    "    # Criar vari√°vel bin√°ria: 1 se usou qualquer apoio, 0 caso contr√°rio\n",
    "    utilizou_apoio = pd.Series(0, index=df.index, dtype=int)\n",
    "    \n",
    "    # Verificar cada tipo de apoio\n",
    "    for var in existing_apoio_vars:\n",
    "        if var in df.columns:\n",
    "            # Contar quantos usaram este apoio espec√≠fico\n",
    "            count_sim = (df[var] == 'Sim').sum()\n",
    "            pct_sim = count_sim / len(df) * 100\n",
    "            print(f\"   {var}: {count_sim} casos ({pct_sim:.1f}%)\")\n",
    "            \n",
    "            # Adicionar √† vari√°vel consolidada (OR l√≥gico)\n",
    "            utilizou_apoio |= (df[var] == 'Sim').astype(int)\n",
    "    \n",
    "    # Inserir a nova vari√°vel\n",
    "    df.insert(insert_pos, 'utilizou_apoio_amamentacao', utilizou_apoio)\n",
    "    \n",
    "    # Estat√≠sticas da vari√°vel consolidada\n",
    "    total_com_apoio = utilizou_apoio.sum()\n",
    "    pct_com_apoio = total_com_apoio / len(df) * 100\n",
    "    print(f\"\\nVari√°vel consolidada criada:\")\n",
    "    print(f\"   utilizou_apoio_amamentacao: {total_com_apoio} casos ({pct_com_apoio:.1f}%)\")\n",
    "    print(f\"   Sem apoio: {len(df) - total_com_apoio} casos ({100 - pct_com_apoio:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES - TODAS AS VARI√ÅVEIS ORIGINAIS\n",
    "# =============================================================================\n",
    "\n",
    "vars_to_exclude = [\n",
    "    'k24_utilizou',            # c√≥digos confusos\n",
    "    'k241_utilizou_concha',    # incorporada na consolidada\n",
    "    'k242_utilizou_protetor',  # incorporada na consolidada\n",
    "    'k243_utilizou_bico',      # incorporada na consolidada\n",
    "    'k244_utilizou_bomba',     # incorporada na consolidada\n",
    "    'k245_utilizou_mamadeira', # incorporada na consolidada\n",
    "    'k246_utilizou_sondinha',  # 1.1%\n",
    "    'k247_utilizou_copo',      # 3.6%\n",
    "    'k248_utilizou_nao',       # redundante\n",
    "    'k249_utilizou_nao_sabe'   # 1.6%\n",
    "]\n",
    "\n",
    "excluded_count = 0\n",
    "print(f\"\\n2. Excluindo vari√°veis originais...\")\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        # Mostrar estat√≠stica antes de excluir (apenas para as <5%)\n",
    "        if var in ['k246_utilizou_sondinha', 'k247_utilizou_copo', 'k249_utilizou_nao_sabe']:\n",
    "            count_sim = (df[var] == 'Sim').sum()\n",
    "            pct_sim = count_sim / len(df) * 100\n",
    "            print(f\"   Excluindo {var}: {count_sim} casos ({pct_sim:.1f}%) - abaixo do limiar 5%\")\n",
    "        else:\n",
    "            print(f\"   Excluindo {var}: incorporada ou redundante\")\n",
    "        \n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "\n",
    "print(f\"\\nTotal de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 5\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar se a consolida√ß√£o foi bem-sucedida\n",
    "if 'utilizou_apoio_amamentacao' in df.columns:\n",
    "    apoio_stats = df['utilizou_apoio_amamentacao'].value_counts()\n",
    "    print(f\"\\nDistribui√ß√£o da vari√°vel consolidada:\")\n",
    "    print(f\"   N√£o utilizou apoio (0): {apoio_stats[0]} casos ({apoio_stats[0]/len(df)*100:.1f}%)\")\n",
    "    print(f\"   Utilizou apoio (1): {apoio_stats[1]} casos ({apoio_stats[1]/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Verificar valores missing\n",
    "    missing = df['utilizou_apoio_amamentacao'].isna().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"   Valores ausentes: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Sem valores ausentes\")\n",
    "\n",
    "# Verificar redu√ß√£o de dimensionalidade\n",
    "print(f\"\\nRedu√ß√£o de dimensionalidade:\")\n",
    "print(f\"   Vari√°veis originais processadas: 10\")\n",
    "print(f\"   Vari√°vel resultante: 1\")\n",
    "print(f\"   Taxa de redu√ß√£o: 90%\")\n",
    "\n",
    "# Verificar se alguma vari√°vel n√£o foi encontrada\n",
    "missing_vars = [var for var in apoio_vars if var not in df.columns and var not in vars_to_exclude]\n",
    "if missing_vars:\n",
    "    print(f\"\\n‚ö†Ô∏è Vari√°veis esperadas mas n√£o encontradas: {missing_vars}\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Conceito capturado: Necessidade de apoio t√©cnico √† amamenta√ß√£o\")\n",
    "print(f\"   M√©todo: OR l√≥gico (qualquer apoio = 1)\")\n",
    "print(f\"   Vari√°veis consolidadas: {len(existing_apoio_vars)}\")\n",
    "print(f\"   Total exclu√≠das: {excluded_count}\")\n",
    "print(f\"   Redu√ß√£o l√≠quida: {excluded_count - 1} vari√°veis\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "# Mostrar informa√ß√µes sobre a nova vari√°vel\n",
    "if 'utilizou_apoio_amamentacao' in df.columns:\n",
    "    print(f\"\\nNova vari√°vel criada:\")\n",
    "    print(f\"   Nome: utilizou_apoio_amamentacao\")\n",
    "    print(f\"   Tipo: Bin√°ria (0/1)\")\n",
    "    print(f\"   Posi√ß√£o: Coluna {df.columns.get_loc('utilizou_apoio_amamentacao') + 1}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas atual: {len(df.columns)}\")\n",
    "\n",
    "# Verifica√ß√£o final - mostrar algumas estat√≠sticas\n",
    "print(f\"\\nVerifica√ß√£o final:\")\n",
    "print(f\"   Dataset shape: {df.shape}\")\n",
    "print(f\"   Vari√°veis de apoio originais restantes: {len([col for col in df.columns if 'k24' in col or 'utilizou_' in col and col != 'utilizou_apoio_amamentacao'])}\")\n",
    "print(f\"   ‚úÖ Consolida√ß√£o conclu√≠da com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d9c539",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 6\n",
    "\n",
    "## Vari√°veis Processadas (Lote 6/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Eliminar redund√¢ncia massiva + transformar vari√°veis relevantes em bin√°rias\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `k25_mamadeira` | **Binary \"exposicao_mamadeira\"** | Usa (41.2%) + J√° usou (5.2%) = 1 vs Nunca (53.4%) + N√£o sabe (0.3%) = 0 |\n",
    "| `k28_aleitamento` | **Binary \"busca_info_aleitamento\"** | Muito (21.5%) + Pouco (12.9%) + Mais ou menos (10.6%) = 1 vs N√£o (54.8%) + N√£o sabe (0.2%) = 0 |\n",
    "| `k29_alimentacao` | **Binary \"busca_info_alimentacao\"** | Muito (18.3%) + Pouco (11.6%) + Mais ou menos (10.6%) = 1 vs N√£o (59.2%) + N√£o sabe (0.3%) = 0 |\n",
    "| `m01_costuma_cozinhar` | **Binary \"cozinha_regularmente\"** | Todos dias (78.7%) + Maioria (9.9%) = 1 vs Outros = 0 |\n",
    "| `m03_alimentos_basicos` | **Binary \"usa_alimentos_basicos\"** | Sempre (86.6%) + Quase sempre (9.8%) = 1 vs Outros = 0 |\n",
    "| `m04_confiante` | **Binary \"confiante_cozinhar\"** | Todos (84.9%) + Maioria (10.8%) = 1 vs Outros = 0 |\n",
    "| `m05_organiza` | **Binary \"organiza_alimentos\"** | Sempre (75.1%) + Quase sempre (14.3%) = 1 vs Outros = 0 |\n",
    "\n",
    "### FEATURE ENGINEERING CR√çTICA: EXPOSI√á√ÉO √Ä MAMADEIRA\n",
    "\n",
    "**Problema metodol√≥gico identificado**: Risco de tautologia entre uso atual de mamadeira e aleitamento exclusivo\n",
    "\n",
    "**Solu√ß√£o**: Transformar em \"exposi√ß√£o hist√≥rica √† mamadeira\"\n",
    "- **Conceito**: Captura hist√≥rico de exposi√ß√£o, independente do status atual\n",
    "- **Separa√ß√£o temporal**: Exposi√ß√£o pr√©via ‚â† uso nas √∫ltimas 24h (crit√©rio WHO)\n",
    "- **Mecanismo biol√≥gico**: Exposi√ß√£o pode influenciar padr√µes de suc√ß√£o/lacta√ß√£o sem determinar status atual\n",
    "\n",
    "### EXCLU√çDAS - BLOCO EBIA COMPLETO\n",
    "\n",
    "| Vari√°veis EBIA (14 total) | Motivo da Exclus√£o |\n",
    "|---------------------------|-------------------|\n",
    "| `l01_morador_alim_acabassem` | Redundante com vd_ebia_categ existente |\n",
    "| `l02_morador_alim_acabaram` | Redundante com vd_ebia_categ existente |\n",
    "| `l03_morador_saudavel` | Redundante com vd_ebia_categ existente |\n",
    "| `l04_morador_insuficiente` | Redundante com vd_ebia_categ existente |\n",
    "| `l05_adulto_saltou_refeicao` | Redundante com vd_ebia_categ existente |\n",
    "| `l06_adulto_comeu_menos` | Redundante com vd_ebia_categ existente |\n",
    "| `l07_adulto_sentiu_fome` | Redundante com vd_ebia_categ existente |\n",
    "| `l08_adulto_sem_comer` | Redundante com vd_ebia_categ existente |\n",
    "| `l09_menos18_saudavel` | Redundante com vd_ebia_categ existente |\n",
    "| `l10_menos18_insuficiente` | Redundante com vd_ebia_categ existente |\n",
    "| `l11_menos18_diminuiu` | Redundante com vd_ebia_categ existente |\n",
    "| `l12_menos18_saltou_refeicao` | Redundante com vd_ebia_categ existente |\n",
    "| `l13_menos18_sentiu_fome` | Redundante com vd_ebia_categ existente |\n",
    "| `l14_menos18_sem_comer` | Redundante com vd_ebia_categ existente |\n",
    "\n",
    "**Justificativa**: Dataset j√° cont√©m `vd_ebia_escore` e `vd_ebia_categ` (escala validada consolidada)\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 6\n",
    "- **Vari√°veis originais**: 21\n",
    "- **Features resultantes**: 7\n",
    "- **Vari√°veis exclu√≠das**: 14\n",
    "- **Taxa de exclus√£o**: 66.7% (elimina√ß√£o de redund√¢ncia EBIA)\n",
    "\n",
    "---\n",
    "\n",
    "## Defesa Metodol√≥gica para Revisores\n",
    "\n",
    "### Exposi√ß√£o √† Mamadeira vs. Tautologia\n",
    "**Argumento principal**: Separa√ß√£o temporal clara entre exposi√ß√£o hist√≥rica e status atual\n",
    "\n",
    "**Exemplos cl√≠nicos**:\n",
    "1. Rec√©m-nascido recebeu complemento na maternidade (exposi√ß√£o = 1)\n",
    "2. Aos 3 meses, restabeleceu aleitamento exclusivo (outcome = EBF)\n",
    "\n",
    "**Mecanismos biol√≥gicos defens√°veis**:\n",
    "- Exposi√ß√£o precoce altera padr√µes oro-motores\n",
    "- Influencia din√¢mica de produ√ß√£o l√°ctea\n",
    "- Afeta confian√ßa materna\n",
    "- **N√£o determina** inevitavelmente status atual (24h)\n",
    "\n",
    "### Consolida√ß√£o EBIA\n",
    "**Justificativa**: Escala validada (vd_ebia_categ) mais robusta que 14 itens individuais\n",
    "**Precedente**: Pr√°tica padr√£o usar scores consolidados vs. itens individuais em ML\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **Temporal separation**: Hist√≥rico vs. status atual (24h WHO)\n",
    "- **Biological plausibility**: Mecanismos conhecidos sem determinismo\n",
    "- **Statistical efficiency**: 7 vari√°veis bin√°rias vs. 21 originais esparsas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbbfd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 163)\n",
      "\n",
      "1. Transformando k25_mamadeira em 'exposicao_mamadeira'...\n",
      "   Exposi√ß√£o √† mamadeira: 870 casos (44.4%)\n",
      "   Sem exposi√ß√£o: 1090 casos (55.6%)\n",
      "\n",
      "2. Transformando k28_aleitamento em 'busca_info_aleitamento'...\n",
      "   Busca info aleitamento: 845 casos (43.1%)\n",
      "\n",
      "3. Transformando k29_alimentacao em 'busca_info_alimentacao'...\n",
      "   Busca info alimenta√ß√£o: 778 casos (39.7%)\n",
      "\n",
      "4. Transformando m01_costuma_cozinhar em 'cozinha_regularmente'...\n",
      "   Cozinha regularmente: 1738 casos (88.7%)\n",
      "\n",
      "5. Transformando m03_alimentos_basicos em 'usa_alimentos_basicos'...\n",
      "   Usa alimentos b√°sicos: 1813 casos (92.5%)\n",
      "\n",
      "6. Transformando m04_confiante em 'confiante_cozinhar'...\n",
      "   Confiante cozinhar: 1799 casos (91.8%)\n",
      "\n",
      "7. Transformando m05_organiza em 'organiza_alimentos'...\n",
      "   Organiza alimentos: 1679 casos (85.7%)\n",
      "\n",
      "8. Excluindo bloco EBIA completo (redundante com vd_ebia_categ)...\n",
      "   l01_morador_alim_acabassem: 701 casos (35.8%) - redundante\n",
      "   l05_adulto_saltou_refeicao: 164 casos (8.4%) - redundante\n",
      "   l12_menos18_saltou_refeicao: 79 casos (4.0%) - redundante\n",
      "\n",
      "Total vari√°veis EBIA exclu√≠das: 14\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 6\n",
      "==================================================\n",
      "\n",
      "Vari√°veis EBIA derivadas mantidas: ['vd_ebia_escore', 'vd_ebia_categ', 'vd_dummy_domic_ebia']\n",
      "\n",
      "Distribui√ß√£o das novas vari√°veis bin√°rias:\n",
      "   exposicao_mamadeira: 870 casos (44.4%)\n",
      "   busca_info_aleitamento: 845 casos (43.1%)\n",
      "   busca_info_alimentacao: 778 casos (39.7%)\n",
      "   cozinha_regularmente: 1738 casos (88.7%)\n",
      "   usa_alimentos_basicos: 1813 casos (92.5%)\n",
      "   confiante_cozinhar: 1799 casos (91.8%)\n",
      "   organiza_alimentos: 1679 casos (85.7%)\n",
      "\n",
      "Valores ausentes nas novas vari√°veis:\n",
      "   ‚úÖ Nenhum valor ausente nas vari√°veis transformadas\n",
      "\n",
      "Resumo do lote:\n",
      "   Vari√°veis originais processadas: 21\n",
      "   Novas vari√°veis bin√°rias criadas: 7\n",
      "   Vari√°veis EBIA exclu√≠das: 14\n",
      "   Redu√ß√£o l√≠quida: 14 vari√°veis\n",
      "\n",
      "üéØ FEATURE ENGINEERING CR√çTICA:\n",
      "   exposicao_mamadeira criada com sucesso\n",
      "   Conceito: Hist√≥rico de exposi√ß√£o (independente de uso atual)\n",
      "   Defesa contra tautologia: Separa√ß√£o temporal clara\n",
      "\n",
      "Dataset transformado salvo: (1960, 149)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Total de colunas atual: 149\n",
      "\n",
      "Verifica√ß√£o final:\n",
      "   Dataset shape: (1960, 149)\n",
      "   Transforma√ß√µes bin√°rias: 7\n",
      "   Exclus√µes EBIA: 14\n",
      "   ‚úÖ Lote 6 processado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 6 - EXPOSI√á√ÉO E COMPET√äNCIAS\n",
    "# =============================================================================\n",
    "\n",
    "# 1. k25_mamadeira - Feature engineering: Exposi√ß√£o √† mamadeira\n",
    "if 'k25_mamadeira' in df.columns:\n",
    "    print(\"\\n1. Transformando k25_mamadeira em 'exposicao_mamadeira'...\")\n",
    "    # Exposi√ß√£o = \"Usa\" ou \"J√° usou\"\n",
    "    # Sem exposi√ß√£o = \"Nunca usou\" ou \"N√£o sabe\"\n",
    "    exposicao = df['k25_mamadeira'].isin(['Sim, ainda usa', 'Sim, j√° usou mas n√£o usa mais'])\n",
    "    col_index = df.columns.get_loc('k25_mamadeira')\n",
    "    df.insert(col_index, 'exposicao_mamadeira', exposicao.astype(int))\n",
    "    df.drop('k25_mamadeira', axis=1, inplace=True)\n",
    "    \n",
    "    count_exposicao = exposicao.sum()\n",
    "    pct_exposicao = count_exposicao / len(df) * 100\n",
    "    print(f\"   Exposi√ß√£o √† mamadeira: {count_exposicao} casos ({pct_exposicao:.1f}%)\")\n",
    "    print(f\"   Sem exposi√ß√£o: {len(df) - count_exposicao} casos ({100 - pct_exposicao:.1f}%)\")\n",
    "\n",
    "# 2. k28_aleitamento - Binary: Busca informa√ß√£o sobre aleitamento\n",
    "if 'k28_aleitamento' in df.columns:\n",
    "    print(\"\\n2. Transformando k28_aleitamento em 'busca_info_aleitamento'...\")\n",
    "    # Busca = \"Muito\", \"Pouco\", \"Mais ou menos\"\n",
    "    # N√£o busca = \"N√£o\", \"N√£o sabe\"\n",
    "    busca_aleit = df['k28_aleitamento'].isin(['Muito', 'Pouco', 'Mais ou menos'])\n",
    "    col_index = df.columns.get_loc('k28_aleitamento')\n",
    "    df.insert(col_index, 'busca_info_aleitamento', busca_aleit.astype(int))\n",
    "    df.drop('k28_aleitamento', axis=1, inplace=True)\n",
    "    \n",
    "    count_busca = busca_aleit.sum()\n",
    "    pct_busca = count_busca / len(df) * 100\n",
    "    print(f\"   Busca info aleitamento: {count_busca} casos ({pct_busca:.1f}%)\")\n",
    "\n",
    "# 3. k29_alimentacao - Binary: Busca informa√ß√£o sobre alimenta√ß√£o\n",
    "if 'k29_alimentacao' in df.columns:\n",
    "    print(\"\\n3. Transformando k29_alimentacao em 'busca_info_alimentacao'...\")\n",
    "    busca_alim = df['k29_alimentacao'].isin(['Muito', 'Pouco', 'Mais ou menos'])\n",
    "    col_index = df.columns.get_loc('k29_alimentacao')\n",
    "    df.insert(col_index, 'busca_info_alimentacao', busca_alim.astype(int))\n",
    "    df.drop('k29_alimentacao', axis=1, inplace=True)\n",
    "    \n",
    "    count_busca_alim = busca_alim.sum()\n",
    "    pct_busca_alim = count_busca_alim / len(df) * 100\n",
    "    print(f\"   Busca info alimenta√ß√£o: {count_busca_alim} casos ({pct_busca_alim:.1f}%)\")\n",
    "\n",
    "# 4. m01_costuma_cozinhar - Binary: Cozinha regularmente\n",
    "if 'm01_costuma_cozinhar' in df.columns:\n",
    "    print(\"\\n4. Transformando m01_costuma_cozinhar em 'cozinha_regularmente'...\")\n",
    "    # Regular = \"Todos os dias\", \"Maioria dos dias\"\n",
    "    cozinha_reg = df['m01_costuma_cozinhar'].isin([\n",
    "        'Sim, todos os dias da semana', \n",
    "        'Sim, a maioria dos dias da semana'\n",
    "    ])\n",
    "    col_index = df.columns.get_loc('m01_costuma_cozinhar')\n",
    "    df.insert(col_index, 'cozinha_regularmente', cozinha_reg.astype(int))\n",
    "    df.drop('m01_costuma_cozinhar', axis=1, inplace=True)\n",
    "    \n",
    "    count_cozinha = cozinha_reg.sum()\n",
    "    pct_cozinha = count_cozinha / len(df) * 100\n",
    "    print(f\"   Cozinha regularmente: {count_cozinha} casos ({pct_cozinha:.1f}%)\")\n",
    "\n",
    "# 5. m03_alimentos_basicos - Binary: Usa alimentos b√°sicos\n",
    "if 'm03_alimentos_basicos' in df.columns:\n",
    "    print(\"\\n5. Transformando m03_alimentos_basicos em 'usa_alimentos_basicos'...\")\n",
    "    usa_basicos = df['m03_alimentos_basicos'].isin(['Sim, sempre', 'Sim, quase sempre'])\n",
    "    col_index = df.columns.get_loc('m03_alimentos_basicos')\n",
    "    df.insert(col_index, 'usa_alimentos_basicos', usa_basicos.astype(int))\n",
    "    df.drop('m03_alimentos_basicos', axis=1, inplace=True)\n",
    "    \n",
    "    count_basicos = usa_basicos.sum()\n",
    "    pct_basicos = count_basicos / len(df) * 100\n",
    "    print(f\"   Usa alimentos b√°sicos: {count_basicos} casos ({pct_basicos:.1f}%)\")\n",
    "\n",
    "# 6. m04_confiante - Binary: Confiante para cozinhar\n",
    "if 'm04_confiante' in df.columns:\n",
    "    print(\"\\n6. Transformando m04_confiante em 'confiante_cozinhar'...\")\n",
    "    confiante = df['m04_confiante'].isin([\n",
    "        'Sim, para todos esses alimentos', \n",
    "        'Sim, para a maioria desses alimentos'\n",
    "    ])\n",
    "    col_index = df.columns.get_loc('m04_confiante')\n",
    "    df.insert(col_index, 'confiante_cozinhar', confiante.astype(int))\n",
    "    df.drop('m04_confiante', axis=1, inplace=True)\n",
    "    \n",
    "    count_conf = confiante.sum()\n",
    "    pct_conf = count_conf / len(df) * 100\n",
    "    print(f\"   Confiante cozinhar: {count_conf} casos ({pct_conf:.1f}%)\")\n",
    "\n",
    "# 7. m05_organiza - Binary: Organiza alimentos\n",
    "if 'm05_organiza' in df.columns:\n",
    "    print(\"\\n7. Transformando m05_organiza em 'organiza_alimentos'...\")\n",
    "    organiza = df['m05_organiza'].isin(['Sim, sempre', 'Sim, quase sempre'])\n",
    "    col_index = df.columns.get_loc('m05_organiza')\n",
    "    df.insert(col_index, 'organiza_alimentos', organiza.astype(int))\n",
    "    df.drop('m05_organiza', axis=1, inplace=True)\n",
    "    \n",
    "    count_org = organiza.sum()\n",
    "    pct_org = count_org / len(df) * 100\n",
    "    print(f\"   Organiza alimentos: {count_org} casos ({pct_org:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ÉO MASSIVA: BLOCO EBIA COMPLETO (14 vari√°veis)\n",
    "# =============================================================================\n",
    "\n",
    "# Definir todas as vari√°veis EBIA para exclus√£o\n",
    "ebia_vars = [\n",
    "    'l01_morador_alim_acabassem',\n",
    "    'l02_morador_alim_acabaram', \n",
    "    'l03_morador_saudavel',\n",
    "    'l04_morador_insuficiente',\n",
    "    'l05_adulto_saltou_refeicao',\n",
    "    'l06_adulto_comeu_menos',\n",
    "    'l07_adulto_sentiu_fome',\n",
    "    'l08_adulto_sem_comer',\n",
    "    'l09_menos18_saudavel',\n",
    "    'l10_menos18_insuficiente',\n",
    "    'l11_menos18_diminuiu',\n",
    "    'l12_menos18_saltou_refeicao',\n",
    "    'l13_menos18_sentiu_fome',\n",
    "    'l14_menos18_sem_comer'\n",
    "]\n",
    "\n",
    "print(f\"\\n8. Excluindo bloco EBIA completo (redundante com vd_ebia_categ)...\")\n",
    "excluded_ebia = 0\n",
    "for var in ebia_vars:\n",
    "    if var in df.columns:\n",
    "        # Mostrar estat√≠stica antes de excluir (apenas algumas para exemplo)\n",
    "        if var in ['l01_morador_alim_acabassem', 'l05_adulto_saltou_refeicao', 'l12_menos18_saltou_refeicao']:\n",
    "            count_sim = (df[var] == 'Sim').sum()\n",
    "            pct_sim = count_sim / len(df) * 100\n",
    "            print(f\"   {var}: {count_sim} casos ({pct_sim:.1f}%) - redundante\")\n",
    "        \n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_ebia += 1\n",
    "\n",
    "print(f\"\\nTotal vari√°veis EBIA exclu√≠das: {excluded_ebia}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 6\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar se vari√°veis derivadas EBIA existem\n",
    "ebia_derivadas = [col for col in df.columns if 'ebia' in col.lower()]\n",
    "if ebia_derivadas:\n",
    "    print(f\"\\nVari√°veis EBIA derivadas mantidas: {ebia_derivadas}\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Vari√°veis EBIA derivadas n√£o encontradas\")\n",
    "\n",
    "# Distribui√ß√£o das novas vari√°veis bin√°rias\n",
    "new_binary_vars = [\n",
    "    'exposicao_mamadeira', 'busca_info_aleitamento', 'busca_info_alimentacao',\n",
    "    'cozinha_regularmente', 'usa_alimentos_basicos', 'confiante_cozinhar', 'organiza_alimentos'\n",
    "]\n",
    "\n",
    "print(f\"\\nDistribui√ß√£o das novas vari√°veis bin√°rias:\")\n",
    "for var in new_binary_vars:\n",
    "    if var in df.columns:\n",
    "        count = df[var].sum()\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   {var}: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# Verificar valores missing\n",
    "print(f\"\\nValores ausentes nas novas vari√°veis:\")\n",
    "missing_found = False\n",
    "for var in new_binary_vars:\n",
    "    if var in df.columns:\n",
    "        missing = df[var].isna().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"   {var}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "            missing_found = True\n",
    "\n",
    "if not missing_found:\n",
    "    print(f\"   ‚úÖ Nenhum valor ausente nas vari√°veis transformadas\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Vari√°veis originais processadas: 21\")\n",
    "print(f\"   Novas vari√°veis bin√°rias criadas: {len([v for v in new_binary_vars if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis EBIA exclu√≠das: {excluded_ebia}\")\n",
    "print(f\"   Redu√ß√£o l√≠quida: {21 - len([v for v in new_binary_vars if v in df.columns])} vari√°veis\")\n",
    "\n",
    "# Verificar vari√°vel cr√≠tica - exposi√ß√£o √† mamadeira\n",
    "if 'exposicao_mamadeira' in df.columns:\n",
    "    print(f\"\\nüéØ FEATURE ENGINEERING CR√çTICA:\")\n",
    "    print(f\"   exposicao_mamadeira criada com sucesso\")\n",
    "    print(f\"   Conceito: Hist√≥rico de exposi√ß√£o (independente de uso atual)\")\n",
    "    print(f\"   Defesa contra tautologia: Separa√ß√£o temporal clara\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas atual: {len(df.columns)}\")\n",
    "\n",
    "# Verifica√ß√£o final\n",
    "print(f\"\\nVerifica√ß√£o final:\")\n",
    "print(f\"   Dataset shape: {df.shape}\")\n",
    "print(f\"   Transforma√ß√µes bin√°rias: {len([v for v in new_binary_vars if v in df.columns])}\")\n",
    "print(f\"   Exclus√µes EBIA: {excluded_ebia}\")\n",
    "print(f\"   ‚úÖ Lote 6 processado com sucesso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a56211",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 7\n",
    "\n",
    "## Vari√°veis Processadas (Lote 7/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Consolidar blocos tem√°ticos + agrupar categorias <5% + excluir varia√ß√£o insuficiente\n",
    "\n",
    "### CONSOLIDA√á√ïES PRINCIPAIS\n",
    "\n",
    "#### 1. AMBIENTE ALIMENTAR DOMICILIAR (9 vari√°veis ‚Üí 2 scores)\n",
    "\n",
    "**Alimentos Saud√°veis (score 0-4):**\n",
    "| Componente | Frequ√™ncia Dominante |\n",
    "|------------|---------------------|\n",
    "| `n01_frutas` | Sempre (52.7%) |\n",
    "| `n02_legumes` | Sempre (50.5%) |\n",
    "| `n03_verduras` | Sempre (47.2%) |\n",
    "| `n04_feijao` | Sempre (79.2%) |\n",
    "\n",
    "**Alimentos Processados (score 0-4):**\n",
    "| Componente | Frequ√™ncia Dominante |\n",
    "|------------|---------------------|\n",
    "| `n05_suco` | Sempre (33.5%) |\n",
    "| `n06_refrigerantes` | √Äs vezes (32.9%) |\n",
    "| `n07_biscoitos` | Sempre (42.7%) |\n",
    "| `n08_salgadinhos` | Raramente (33.4%) |\n",
    "| `n09_balas` | Raramente (32.0%) |\n",
    "\n",
    "#### 2. ACESSO ALIMENTAR NO BAIRRO (7 vari√°veis ‚Üí 2 scores)\n",
    "\n",
    "**Acesso a Saud√°veis (score 0-4):**\n",
    "- `o01_frutas_comprar`, `o02_frutas_qualidade`, `o03_frutas_variedade`, `o04_frutas_baratas`\n",
    "\n",
    "**Acesso a Processados (score 0-4):**\n",
    "- `o05_refrigerantes_comprar`, `o06_refrigerantes_variedade`, `o07_refrigerantes_baratos`\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `m09_atividades_divididas` | **Binary** | Sempre+Quase sempre (46.7%) vs Outros (53.3%) |\n",
    "| `p02_tipo_de_domicilio` | **One-hot agrupado** | Casa, Apartamento, Outros (<5% agrupados) |\n",
    "| `p03_ocupacao` | **One-hot agrupado** | Pr√≥prio, Alugado, Cedido |\n",
    "| `p05_comodos` | **Num√©rica** | Distribui√ß√£o adequada (2-17 c√¥modos) |\n",
    "| `p06_cozinha` | **Binary** | Tem cozinha (96.9%) vs N√£o tem (3.1%) |\n",
    "| `p07_dormitorios` | **Num√©rica** | Distribui√ß√£o adequada (1-7 dormit√≥rios) |\n",
    "| `p08_banheiros_exclusivo` | **One-hot agrupado** | 0-1, 2-3, 4+ banheiros |\n",
    "| `p09_banheiros_chuveiro` | **One-hot agrupado** | 0-1, 2-3, 4+ banheiros |\n",
    "| `p10_esgoto` | **Binary** | Rede geral (71.9%) vs Outros (28.1%) |\n",
    "| `p11_agua` | **One-hot agrupado** | Rede geral, Po√ßo, Outras fontes |\n",
    "\n",
    "### ALGORITMO DE CONSOLIDA√á√ÉO\n",
    "\n",
    "**Codifica√ß√£o de Frequ√™ncia:**\n",
    "- Sempre = 4\n",
    "- Quase sempre = 3\n",
    "- √Äs vezes = 2\n",
    "- Raramente = 1\n",
    "- Nunca = 0\n",
    "\n",
    "**Score Final:** M√©dia aritm√©tica dos componentes (0-4)\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | Motivo |\n",
    "|----------|---------|\n",
    "| `m07_sabe_basico` | 3.1% \"n√£o\" - varia√ß√£o insuficiente |\n",
    "| `m08_adiantar_etapas` | Comportamento espec√≠fico, n√£o preditor forte |\n",
    "| Todas as vari√°veis N individuais | Consolidadas em scores ambiente alimentar |\n",
    "| Todas as vari√°veis O individuais | Consolidadas em scores acesso bairro |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 7\n",
    "- **Vari√°veis originais**: 28\n",
    "- **Features resultantes**: ~18 (4 scores + 14 habitacionais transformadas)\n",
    "- **Vari√°veis exclu√≠das**: 18 (16 consolidadas + 2 exclu√≠das)\n",
    "- **Taxa de consolida√ß√£o**: 57.1%\n",
    "\n",
    "---\n",
    "\n",
    "## Inova√ß√µes Metodol√≥gicas\n",
    "\n",
    "### Scores de Ambiente Alimentar\n",
    "**Conceito**: Capturar padr√£o global de disponibilidade vs. itens individuais\n",
    "**Vantagem**: Reduz dimensionalidade preservando informa√ß√£o nutricional relevante\n",
    "\n",
    "### Agrupamento Inteligente de Categorias\n",
    "**Princ√≠pio**: Preservar informa√ß√£o socioecon√¥mica atrav√©s de categoriza√ß√£o hier√°rquica\n",
    "**Exemplo**: Banheiros 0-1 (baixo), 2-3 (m√©dio), 4+ (alto) vs. excluir categorias <5%\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **Scores cont√≠nuos**: Preservam granularidade (0-4)\n",
    "- **Missing values**: Tratar como categoria separada em agrupamentos\n",
    "- **Interpretabilidade**: Scores mant√™m significado cl√≠nico/social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d9d87c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 149)\n",
      "\n",
      "1. Criando score 'alimentos_saudaveis_disponiveis'...\n",
      "   n01_frutas: Sempre (1033, 52.7%)\n",
      "   n02_legumes: Sempre (990, 50.5%)\n",
      "   n03_verduras: Sempre (925, 47.2%)\n",
      "   n04_feijao: Sempre (1552, 79.2%)\n",
      "   Score criado - Range: 0.00 - 4.00\n",
      "   M√©dia: 3.23\n",
      "\n",
      "2. Criando score 'alimentos_processados_disponiveis'...\n",
      "   n05_suco: Sempre (656, 33.5%)\n",
      "   n06_refrigerantes: √Äs vezes (644, 32.9%)\n",
      "   n07_biscoitos: Sempre (836, 42.7%)\n",
      "   n08_salgadinhos: Raramente (655, 33.4%)\n",
      "   n09_balas: Raramente (628, 32.0%)\n",
      "   Score criado - Range: 0.00 - 4.00\n",
      "   M√©dia: 2.05\n",
      "\n",
      "3. Criando score 'acesso_saudaveis_bairro'...\n",
      "   o01_frutas_comprar: Concordo totalmente (1298, 66.2%)\n",
      "   o02_frutas_qualidade: Concordo totalmente (1126, 57.4%)\n",
      "   o03_frutas_variedade: Concordo totalmente (1086, 55.4%)\n",
      "   o04_frutas_baratas: Concordo totalmente (570, 29.1%)\n",
      "   Score criado - Range: 0.00 - 4.00\n",
      "\n",
      "4. Criando score 'acesso_processados_bairro'...\n",
      "   Score criado - Range: 0.00 - 4.00\n",
      "\n",
      "5. Transformando m09_atividades_divididas...\n",
      "   Atividades divididas: 878 casos (44.8%)\n",
      "\n",
      "6. Transformando p02_tipo_de_domicilio...\n",
      "   Criadas: ['tipo_domicilio_Apartamento', 'tipo_domicilio_Casa', 'tipo_domicilio_Outros']\n",
      "\n",
      "7. Transformando p03_ocupacao...\n",
      "   Criadas: ['ocupacao_Alugado', 'ocupacao_Cedido', 'ocupacao_Pr√≥prio']\n",
      "\n",
      "8. Mantendo p05_comodos como num√©rica...\n",
      "   Range: 1 - 20\n",
      "\n",
      "9. Mantendo p07_dormitorios como num√©rica...\n",
      "   Range: 1 - 7\n",
      "\n",
      "10. Transformando p06_cozinha...\n",
      "   Tem cozinha: 1900 casos (96.9%)\n",
      "\n",
      "11. Transformando p08_banheiros_exclusivo...\n",
      "   Criadas: ['p08_banheiros_exclusivo_0-1', 'p08_banheiros_exclusivo_2-3', 'p08_banheiros_exclusivo_4+']\n",
      "\n",
      "12. Transformando p09_banheiros_chuveiro...\n",
      "   Criadas: ['p09_banheiros_chuveiro_0-1', 'p09_banheiros_chuveiro_2-3', 'p09_banheiros_chuveiro_4+']\n",
      "\n",
      "13. Transformando p10_esgoto...\n",
      "   Rede geral: 1409 casos (71.9%)\n",
      "\n",
      "14. Transformando p11_agua...\n",
      "   Criadas: ['agua_Outras', 'agua_Po√ßo', 'agua_Rede geral']\n",
      "\n",
      "Exclu√≠da m07_sabe_basico: 58 'N√£o' (3.0%) - varia√ß√£o insuficiente\n",
      "\n",
      "Exclu√≠da m08_adiantar_etapas: comportamento espec√≠fico\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 7\n",
      "==================================================\n",
      "\n",
      "Scores de ambiente alimentar criados: 6\n",
      "   alimentos_saudaveis_score: 0.00 - 4.00\n",
      "   alimentos_processados_score: 0.00 - 4.00\n",
      "   acesso_saudaveis_bairro: 0.00 - 4.00\n",
      "   acesso_processados_bairro: 0.00 - 4.00\n",
      "   vd_ien_escore: -15.60 - 5.93\n",
      "   vd_ebia_escore: 0.00 - 14.00\n",
      "\n",
      "Vari√°veis one-hot habitacionais: 19\n",
      "\n",
      "Resumo do lote:\n",
      "   Vari√°veis originais: 28\n",
      "   Scores ambiente alimentar: 6\n",
      "   Vari√°veis habitacionais transformadas: 24\n",
      "   Vari√°veis exclu√≠das: 2\n",
      "\n",
      "Dataset transformado salvo: (1960, 145)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "Total de colunas atual: 145\n",
      "‚úÖ Lote 7 processado com sucesso\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 7 - CONSOLIDA√á√ÉO AMBIENTE ALIMENTAR E HABITA√á√ÉO\n",
    "# =============================================================================\n",
    "\n",
    "# Definir mapeamento de frequ√™ncia para scores\n",
    "freq_map = {\n",
    "    'Sempre': 4,\n",
    "    'Quase sempre': 3, \n",
    "    '√Äs vezes': 2,\n",
    "    'Raramente': 1,\n",
    "    'Nunca': 0\n",
    "}\n",
    "\n",
    "# 1. CONSOLIDA√á√ÉO: ALIMENTOS SAUD√ÅVEIS (n01-n04)\n",
    "saudaveis_vars = ['n01_frutas', 'n02_legumes', 'n03_verduras', 'n04_feijao']\n",
    "existing_saudaveis = [var for var in saudaveis_vars if var in df.columns]\n",
    "\n",
    "if existing_saudaveis:\n",
    "    print(f\"\\n1. Criando score 'alimentos_saudaveis_disponiveis'...\")\n",
    "    \n",
    "    # Converter para num√©rico\n",
    "    saudaveis_numeric = []\n",
    "    for var in existing_saudaveis:\n",
    "        var_numeric = df[var].map(freq_map)\n",
    "        saudaveis_numeric.append(var_numeric)\n",
    "        freq_counts = df[var].value_counts()\n",
    "        print(f\"   {var}: {freq_counts.index[0]} ({freq_counts.iloc[0]}, {freq_counts.iloc[0]/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Criar score m√©dio (0-4)\n",
    "    if existing_saudaveis:\n",
    "        alimentos_saudaveis_score = pd.concat(saudaveis_numeric, axis=1).mean(axis=1)\n",
    "        \n",
    "        # Inserir na posi√ß√£o da primeira vari√°vel\n",
    "        insert_pos = df.columns.get_loc(existing_saudaveis[0])\n",
    "        df.insert(insert_pos, 'alimentos_saudaveis_score', alimentos_saudaveis_score)\n",
    "        \n",
    "        print(f\"   Score criado - Range: {alimentos_saudaveis_score.min():.2f} - {alimentos_saudaveis_score.max():.2f}\")\n",
    "        print(f\"   M√©dia: {alimentos_saudaveis_score.mean():.2f}\")\n",
    "        \n",
    "        # Remover vari√°veis originais\n",
    "        for var in existing_saudaveis:\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# 2. CONSOLIDA√á√ÉO: ALIMENTOS PROCESSADOS (n05-n09)\n",
    "processados_vars = ['n05_suco', 'n06_refrigerantes', 'n07_biscoitos', 'n08_salgadinhos', 'n09_balas']\n",
    "existing_processados = [var for var in processados_vars if var in df.columns]\n",
    "\n",
    "if existing_processados:\n",
    "    print(f\"\\n2. Criando score 'alimentos_processados_disponiveis'...\")\n",
    "    \n",
    "    # Converter para num√©rico\n",
    "    processados_numeric = []\n",
    "    for var in existing_processados:\n",
    "        var_numeric = df[var].map(freq_map)\n",
    "        processados_numeric.append(var_numeric)\n",
    "        freq_counts = df[var].value_counts()\n",
    "        print(f\"   {var}: {freq_counts.index[0]} ({freq_counts.iloc[0]}, {freq_counts.iloc[0]/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Criar score m√©dio (0-4)\n",
    "    if existing_processados:\n",
    "        alimentos_processados_score = pd.concat(processados_numeric, axis=1).mean(axis=1)\n",
    "        \n",
    "        # Inserir ap√≥s score saud√°veis\n",
    "        if 'alimentos_saudaveis_score' in df.columns:\n",
    "            insert_pos = df.columns.get_loc('alimentos_saudaveis_score') + 1\n",
    "        else:\n",
    "            insert_pos = df.columns.get_loc(existing_processados[0])\n",
    "        \n",
    "        df.insert(insert_pos, 'alimentos_processados_score', alimentos_processados_score)\n",
    "        \n",
    "        print(f\"   Score criado - Range: {alimentos_processados_score.min():.2f} - {alimentos_processados_score.max():.2f}\")\n",
    "        print(f\"   M√©dia: {alimentos_processados_score.mean():.2f}\")\n",
    "        \n",
    "        # Remover vari√°veis originais\n",
    "        for var in existing_processados:\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# 3. CONSOLIDA√á√ÉO: ACESSO SAUD√ÅVEIS NO BAIRRO (o01-o04)\n",
    "acesso_saudaveis_vars = ['o01_frutas_comprar', 'o02_frutas_qualidade', 'o03_frutas_variedade', 'o04_frutas_baratas']\n",
    "existing_acesso_saud = [var for var in acesso_saudaveis_vars if var in df.columns]\n",
    "\n",
    "# Mapeamento para vari√°veis de concord√¢ncia\n",
    "concordancia_map = {\n",
    "    'Concordo totalmente': 4,\n",
    "    'Concordo parcialmente': 3,\n",
    "    'Nem concordo nem discordo': 2, \n",
    "    'Discordo parcialmente': 1,\n",
    "    'Discordo totalmente': 0\n",
    "}\n",
    "\n",
    "if existing_acesso_saud:\n",
    "    print(f\"\\n3. Criando score 'acesso_saudaveis_bairro'...\")\n",
    "    \n",
    "    acesso_saud_numeric = []\n",
    "    for var in existing_acesso_saud:\n",
    "        var_numeric = df[var].map(concordancia_map)\n",
    "        acesso_saud_numeric.append(var_numeric)\n",
    "        conc_counts = df[var].value_counts()\n",
    "        print(f\"   {var}: {conc_counts.index[0]} ({conc_counts.iloc[0]}, {conc_counts.iloc[0]/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    if existing_acesso_saud:\n",
    "        acesso_saudaveis_score = pd.concat(acesso_saud_numeric, axis=1).mean(axis=1)\n",
    "        \n",
    "        insert_pos = df.columns.get_loc(existing_acesso_saud[0])\n",
    "        df.insert(insert_pos, 'acesso_saudaveis_bairro', acesso_saudaveis_score)\n",
    "        \n",
    "        print(f\"   Score criado - Range: {acesso_saudaveis_score.min():.2f} - {acesso_saudaveis_score.max():.2f}\")\n",
    "        \n",
    "        for var in existing_acesso_saud:\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# 4. CONSOLIDA√á√ÉO: ACESSO PROCESSADOS NO BAIRRO (o05-o07)\n",
    "acesso_processados_vars = ['o05_refrigerantes_comprar', 'o06_refrigerantes_variedade', 'o07_refrigerantes_baratos']\n",
    "existing_acesso_proc = [var for var in acesso_processados_vars if var in df.columns]\n",
    "\n",
    "if existing_acesso_proc:\n",
    "    print(f\"\\n4. Criando score 'acesso_processados_bairro'...\")\n",
    "    \n",
    "    acesso_proc_numeric = []\n",
    "    for var in existing_acesso_proc:\n",
    "        var_numeric = df[var].map(concordancia_map)\n",
    "        acesso_proc_numeric.append(var_numeric)\n",
    "    \n",
    "    if existing_acesso_proc:\n",
    "        acesso_processados_score = pd.concat(acesso_proc_numeric, axis=1).mean(axis=1)\n",
    "        \n",
    "        if 'acesso_saudaveis_bairro' in df.columns:\n",
    "            insert_pos = df.columns.get_loc('acesso_saudaveis_bairro') + 1\n",
    "        else:\n",
    "            insert_pos = df.columns.get_loc(existing_acesso_proc[0])\n",
    "        \n",
    "        df.insert(insert_pos, 'acesso_processados_bairro', acesso_processados_score)\n",
    "        \n",
    "        print(f\"   Score criado - Range: {acesso_processados_score.min():.2f} - {acesso_processados_score.max():.2f}\")\n",
    "        \n",
    "        for var in existing_acesso_proc:\n",
    "            df.drop(var, axis=1, inplace=True)\n",
    "\n",
    "# 5. m09_atividades_divididas - Binary\n",
    "if 'm09_atividades_divididas' in df.columns:\n",
    "    print(f\"\\n5. Transformando m09_atividades_divididas...\")\n",
    "    atividades_divididas = df['m09_atividades_divididas'].isin(['Sim, sempre', 'Sim, quase sempre'])\n",
    "    df['m09_atividades_divididas'] = atividades_divididas.astype(int)\n",
    "    count = atividades_divididas.sum()\n",
    "    print(f\"   Atividades divididas: {count} casos ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 6. p02_tipo_de_domicilio - One-hot agrupado\n",
    "if 'p02_tipo_de_domicilio' in df.columns:\n",
    "    print(f\"\\n6. Transformando p02_tipo_de_domicilio...\")\n",
    "    \n",
    "    # Agrupar categorias pequenas\n",
    "    tipo_grouped = df['p02_tipo_de_domicilio'].copy()\n",
    "    mask_outros = tipo_grouped.isin(['Casa de vila ou em condom√≠nio', 'Habita√ß√£o em casa de c√¥modos, corti√ßo ou cabe√ßa de porco', 'Outro'])\n",
    "    tipo_grouped.loc[mask_outros] = 'Outros'\n",
    "    \n",
    "    tipo_dummies = pd.get_dummies(tipo_grouped, prefix='tipo_domicilio', drop_first=False)\n",
    "    col_index = df.columns.get_loc('p02_tipo_de_domicilio')\n",
    "    df.drop('p02_tipo_de_domicilio', axis=1, inplace=True)\n",
    "    for i, col in enumerate(tipo_dummies.columns):\n",
    "        df.insert(col_index + i, col, tipo_dummies[col])\n",
    "    print(f\"   Criadas: {tipo_dummies.columns.tolist()}\")\n",
    "\n",
    "# 7. p03_ocupacao - One-hot agrupado  \n",
    "if 'p03_ocupacao' in df.columns:\n",
    "    print(f\"\\n7. Transformando p03_ocupacao...\")\n",
    "    \n",
    "    # Agrupar em Pr√≥prio, Alugado, Cedido\n",
    "    ocupacao_grouped = df['p03_ocupacao'].copy()\n",
    "    ocupacao_grouped.loc[ocupacao_grouped.str.contains('Pr√≥prio', na=False)] = 'Pr√≥prio'\n",
    "    ocupacao_grouped.loc[ocupacao_grouped == 'Alugado'] = 'Alugado'\n",
    "    ocupacao_grouped.loc[ocupacao_grouped.str.contains('Cedido|Outra', na=False)] = 'Cedido'\n",
    "    \n",
    "    ocupacao_dummies = pd.get_dummies(ocupacao_grouped, prefix='ocupacao', drop_first=False)\n",
    "    col_index = df.columns.get_loc('p03_ocupacao')\n",
    "    df.drop('p03_ocupacao', axis=1, inplace=True)\n",
    "    for i, col in enumerate(ocupacao_dummies.columns):\n",
    "        df.insert(col_index + i, col, ocupacao_dummies[col])\n",
    "    print(f\"   Criadas: {ocupacao_dummies.columns.tolist()}\")\n",
    "\n",
    "# 8-9. Vari√°veis num√©ricas - manter\n",
    "numeric_vars = ['p05_comodos', 'p07_dormitorios']\n",
    "for i, var in enumerate(numeric_vars, 8):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Mantendo {var} como num√©rica...\")\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
    "        print(f\"   Range: {df[var].min()} - {df[var].max()}\")\n",
    "\n",
    "# 10. p06_cozinha - Binary\n",
    "if 'p06_cozinha' in df.columns:\n",
    "    print(f\"\\n10. Transformando p06_cozinha...\")\n",
    "    df['p06_cozinha'] = (df['p06_cozinha'] == 'Sim').astype(int)\n",
    "    count = df['p06_cozinha'].sum()\n",
    "    print(f\"   Tem cozinha: {count} casos ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 11-12. Banheiros - One-hot agrupado\n",
    "banheiro_vars = ['p08_banheiros_exclusivo', 'p09_banheiros_chuveiro']\n",
    "for i, var in enumerate(banheiro_vars, 11):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Transformando {var}...\")\n",
    "        \n",
    "        # Agrupar em 0-1, 2-3, 4+\n",
    "        banheiro_grouped = pd.cut(df[var], bins=[-1, 1, 3, float('inf')], \n",
    "                                labels=['0-1', '2-3', '4+'], include_lowest=True)\n",
    "        \n",
    "        banheiro_dummies = pd.get_dummies(banheiro_grouped, prefix=var, drop_first=False)\n",
    "        col_index = df.columns.get_loc(var)\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        for j, col in enumerate(banheiro_dummies.columns):\n",
    "            df.insert(col_index + j, col, banheiro_dummies[col])\n",
    "        print(f\"   Criadas: {banheiro_dummies.columns.tolist()}\")\n",
    "\n",
    "# 13. p10_esgoto - Binary\n",
    "if 'p10_esgoto' in df.columns:\n",
    "    print(f\"\\n13. Transformando p10_esgoto...\")\n",
    "    rede_geral = df['p10_esgoto'] == 'Rede geral de esgoto ou pluvial'\n",
    "    df['p10_esgoto'] = rede_geral.astype(int)\n",
    "    count = rede_geral.sum()\n",
    "    print(f\"   Rede geral: {count} casos ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 14. p11_agua - One-hot agrupado\n",
    "if 'p11_agua' in df.columns:\n",
    "    print(f\"\\n14. Transformando p11_agua...\")\n",
    "    \n",
    "    agua_grouped = df['p11_agua'].copy()\n",
    "    agua_grouped.loc[agua_grouped.str.contains('Po√ßo', na=False)] = 'Po√ßo'\n",
    "    agua_grouped.loc[~agua_grouped.isin(['Rede geral de distribui√ß√£o', 'Po√ßo'])] = 'Outras'\n",
    "    agua_grouped.loc[agua_grouped == 'Rede geral de distribui√ß√£o'] = 'Rede geral'\n",
    "    \n",
    "    agua_dummies = pd.get_dummies(agua_grouped, prefix='agua', drop_first=False)\n",
    "    col_index = df.columns.get_loc('p11_agua')\n",
    "    df.drop('p11_agua', axis=1, inplace=True)\n",
    "    for i, col in enumerate(agua_dummies.columns):\n",
    "        df.insert(col_index + i, col, agua_dummies[col])\n",
    "    print(f\"   Criadas: {agua_dummies.columns.tolist()}\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ïES\n",
    "# =============================================================================\n",
    "\n",
    "vars_to_exclude = ['m07_sabe_basico', 'm08_adiantar_etapas']\n",
    "excluded_count = 0\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        if var == 'm07_sabe_basico':\n",
    "            count_nao = (df[var] == 'N√£o').sum()\n",
    "            print(f\"\\nExclu√≠da {var}: {count_nao} 'N√£o' ({count_nao/len(df)*100:.1f}%) - varia√ß√£o insuficiente\")\n",
    "        else:\n",
    "            print(f\"\\nExclu√≠da {var}: comportamento espec√≠fico\")\n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "\n",
    "# =============================================================================\n",
    "# RELAT√ìRIO FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 7\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Contar scores criados\n",
    "scores_criados = [col for col in df.columns if 'score' in col or 'acesso_' in col]\n",
    "print(f\"\\nScores de ambiente alimentar criados: {len(scores_criados)}\")\n",
    "for score in scores_criados:\n",
    "    if score in df.columns:\n",
    "        print(f\"   {score}: {df[score].min():.2f} - {df[score].max():.2f}\")\n",
    "\n",
    "# Contar one-hot criadas\n",
    "one_hot_cols = [col for col in df.columns if any(prefix in col for prefix in ['tipo_domicilio_', 'ocupacao_', 'p08_', 'p09_', 'agua_'])]\n",
    "print(f\"\\nVari√°veis one-hot habitacionais: {len(one_hot_cols)}\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Vari√°veis originais: 28\")\n",
    "print(f\"   Scores ambiente alimentar: {len(scores_criados)}\")\n",
    "print(f\"   Vari√°veis habitacionais transformadas: {len(one_hot_cols) + len([v for v in ['p05_comodos', 'p06_cozinha', 'p07_dormitorios', 'p10_esgoto', 'm09_atividades_divididas'] if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "print(f\"Total de colunas atual: {len(df.columns)}\")\n",
    "print(f\"‚úÖ Lote 7 processado com sucesso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "784f3c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset antes da exclus√£o: (1960, 145)\n",
      "\n",
      "Vari√°vel m06_facilidade encontrada\n",
      "Distribui√ß√£o da m06_facilidade:\n",
      "   Sim, para todos esses alimentos: 1586 casos (80.9%)\n",
      "   Sim, para a maioria desses alimentos: 215 casos (11.0%)\n",
      "   Sim, para alguns desses alimentos: 59 casos (3.0%)\n",
      "   N√£o: 20 casos (1.0%)\n",
      "\n",
      "‚úÖ Vari√°vel m06_facilidade exclu√≠da\n",
      "Motivo: Redundante com m04_confiante (conceitos sobrepostos: confian√ßa vs facilidade para cozinhar)\n",
      "\n",
      "‚úÖ Vari√°vel confiante_cozinhar mantida (m04_confiante transformada)\n",
      "\n",
      "Dataset ap√≥s exclus√£o: (1960, 144)\n",
      "Arquivo salvo: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Verifica√ß√£o final:\n",
      "   Total de colunas: 144\n",
      "   m06_facilidade presente: N√£o\n",
      "   Vari√°vel de confian√ßa culin√°ria presente: Sim\n",
      "\n",
      "üìã Documenta√ß√£o da exclus√£o:\n",
      "   Vari√°vel: m06_facilidade\n",
      "   Descri√ß√£o: Facilidade em preparar refei√ß√µes com alimentos b√°sicos\n",
      "   Motivo exclus√£o: Redund√¢ncia conceitual com m04_confiante\n",
      "   Distribui√ß√µes similares: 84.4% vs 84.9% 'todos alimentos'\n",
      "   Decis√£o: Manter apenas uma vari√°vel (confian√ßa culin√°ria)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset antes da exclus√£o: {df.shape}\")\n",
    "\n",
    "# Verificar se m06_facilidade existe no dataset\n",
    "if 'm06_facilidade' in df.columns:\n",
    "    print(f\"\\nVari√°vel m06_facilidade encontrada\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o antes de excluir\n",
    "    print(f\"Distribui√ß√£o da m06_facilidade:\")\n",
    "    facilidade_counts = df['m06_facilidade'].value_counts()\n",
    "    for valor, count in facilidade_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   {valor}: {count} casos ({pct:.1f}%)\")\n",
    "    \n",
    "    # Excluir a vari√°vel\n",
    "    df.drop('m06_facilidade', axis=1, inplace=True)\n",
    "    print(f\"\\n‚úÖ Vari√°vel m06_facilidade exclu√≠da\")\n",
    "    print(f\"Motivo: Redundante com m04_confiante (conceitos sobrepostos: confian√ßa vs facilidade para cozinhar)\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Vari√°vel m06_facilidade n√£o encontrada no dataset\")\n",
    "    print(f\"Pode j√° ter sido exclu√≠da em processamento anterior\")\n",
    "\n",
    "# Verificar se m04_confiante existe (a vari√°vel que mantivemos)\n",
    "if 'm04_confiante' in df.columns:\n",
    "    print(f\"\\n‚úÖ Vari√°vel m04_confiante mantida (equivalente funcional)\")\n",
    "elif 'confiante_cozinhar' in df.columns:\n",
    "    print(f\"\\n‚úÖ Vari√°vel confiante_cozinhar mantida (m04_confiante transformada)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Vari√°vel de confian√ßa culin√°ria n√£o encontrada\")\n",
    "\n",
    "# Salvar dataset atualizado\n",
    "df.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"\\nDataset ap√≥s exclus√£o: {df.shape}\")\n",
    "print(f\"Arquivo salvo: {file_path}\")\n",
    "\n",
    "# Verifica√ß√£o final\n",
    "print(f\"\\nVerifica√ß√£o final:\")\n",
    "print(f\"   Total de colunas: {len(df.columns)}\")\n",
    "print(f\"   m06_facilidade presente: {'Sim' if 'm06_facilidade' in df.columns else 'N√£o'}\")\n",
    "print(f\"   Vari√°vel de confian√ßa culin√°ria presente: {'Sim' if any('confiante' in col for col in df.columns) else 'N√£o'}\")\n",
    "\n",
    "print(f\"\\nüìã Documenta√ß√£o da exclus√£o:\")\n",
    "print(f\"   Vari√°vel: m06_facilidade\")\n",
    "print(f\"   Descri√ß√£o: Facilidade em preparar refei√ß√µes com alimentos b√°sicos\")\n",
    "print(f\"   Motivo exclus√£o: Redund√¢ncia conceitual com m04_confiante\")\n",
    "print(f\"   Distribui√ß√µes similares: 84.4% vs 84.9% 'todos alimentos'\")\n",
    "print(f\"   Decis√£o: Manter apenas uma vari√°vel (confian√ßa culin√°ria)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d820108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 144)\n",
      "\n",
      "Coluna acesso_processados_bairro encontrada\n",
      "Valores antes do arredondamento:\n",
      "   Primeiros 10: [3.6666666666666665, 3.6666666666666665, 2.6666666666666665, 2.6666666666666665, 4.0, 3.6666666666666665, 3.6666666666666665, 3.0, 4.0, 2.6666666666666665]\n",
      "   Range: 0.0 - 4.0\n",
      "\n",
      "Valores ap√≥s arredondamento para 1 casa decimal:\n",
      "   Primeiros 10: [3.7, 3.7, 2.7, 2.7, 4.0, 3.7, 3.7, 3.0, 4.0, 2.7]\n",
      "   Range: 0.0 - 4.0\n",
      "   Valores √∫nicos: [0.0, 0.3, 0.7, 1.0, 1.3, 1.7, 2.0, 2.3, 2.7, 3.0, 3.3, 3.7, 4.0]\n",
      "\n",
      "Dataset salvo: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Arredondamento da coluna acesso_processados_bairro conclu√≠do\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# Verificar se a coluna existe\n",
    "if 'acesso_processados_bairro' in df.columns:\n",
    "    print(f\"\\nColuna acesso_processados_bairro encontrada\")\n",
    "    \n",
    "    # Mostrar valores antes do arredondamento\n",
    "    print(f\"Valores antes do arredondamento:\")\n",
    "    sample_antes = df['acesso_processados_bairro'].head(10)\n",
    "    print(f\"   Primeiros 10: {sample_antes.tolist()}\")\n",
    "    print(f\"   Range: {df['acesso_processados_bairro'].min()} - {df['acesso_processados_bairro'].max()}\")\n",
    "    \n",
    "    # Arredondar para 1 casa decimal\n",
    "    df['acesso_processados_bairro'] = df['acesso_processados_bairro'].round(1)\n",
    "    \n",
    "    # Mostrar valores ap√≥s o arredondamento\n",
    "    print(f\"\\nValores ap√≥s arredondamento para 1 casa decimal:\")\n",
    "    sample_depois = df['acesso_processados_bairro'].head(10)\n",
    "    print(f\"   Primeiros 10: {sample_depois.tolist()}\")\n",
    "    print(f\"   Range: {df['acesso_processados_bairro'].min()} - {df['acesso_processados_bairro'].max()}\")\n",
    "    print(f\"   Valores √∫nicos: {sorted(df['acesso_processados_bairro'].unique())}\")\n",
    "    \n",
    "    # Salvar dataset\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"\\nDataset salvo: {file_path}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\nColuna acesso_processados_bairro n√£o encontrada no dataset\")\n",
    "    print(f\"Colunas dispon√≠veis que cont√™m 'acesso':\")\n",
    "    acesso_cols = [col for col in df.columns if 'acesso' in col.lower()]\n",
    "    for col in acesso_cols:\n",
    "        print(f\"   {col}\")\n",
    "\n",
    "print(f\"\\nArredondamento da coluna acesso_processados_bairro conclu√≠do\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69ae5c2",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 8\n",
    "\n",
    "## Vari√°veis Processadas (Lote 8/17)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Manter apenas preditores teoricamente defens√°veis + eliminar redund√¢ncia + aplicar parcim√¥nia metodol√≥gica\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `q01_recebe_beneficio` | **Binary** (0=N√£o, 1=Sim) | Indicador direto de vulnerabilidade social (31.9% recebem) |\n",
    "| `q06_renda` | **Num√©rica** | Preditor socioecon√¥mico fundamental, 177 valores √∫nicos |\n",
    "| `r12_internet_domicilio` | **Binary** (0=N√£o, 1=Tem internet) | Acesso √† informa√ß√£o: Cabo+WiFi (44.3%) + S√≥ cabo (14.7%) vs N√£o (41.0%) |\n",
    "| `r13_internet_celular` | **Binary** (0=N√£o, 1=Sim) | Conectividade m√≥vel (89.2% vs 10.8%) |\n",
    "| `r14_celular` | **Binary** (0=N√£o possui, 1=Possui) | Pr√©-pago (78.0%) + P√≥s-pago (18.6%) vs N√£o possui (3.4%) |\n",
    "\n",
    "### EXCLU√çDAS - APLICA√á√ÉO RIGOROSA DE PARCIM√îNIA\n",
    "\n",
    "| Vari√°vel | % Categoria Minorit√°ria | Motivo da Exclus√£o |\n",
    "|----------|------------------------|-------------------|\n",
    "| `p12_lixo` | V√°rias <1% | Categorias esparsas, n√£o preditor de aleitamento |\n",
    "| `p13_energia_eletrica` | 0.3% | Quase constante (99.7% rede geral) |\n",
    "| `q07_renda_faixa` | N/A | Redundante com q06_renda (mesma informa√ß√£o) |\n",
    "| `r01_televisao` | V√°rias <5% | Invent√°rio de bens, n√£o preditor defens√°vel |\n",
    "| `r02_automoveis` | V√°rias <1% | Renda j√° captura poder aquisitivo |\n",
    "| `r03_radio` | N/A | Tecnologia obsoleta, irrelevante para aleitamento |\n",
    "| `r04_geladeira` | 2.3% | Quase universal, pouca varia√ß√£o |\n",
    "| `r05_vcr` | N/A | Entretenimento, n√£o preditor teoricamente v√°lido |\n",
    "| `r06_lavadora` | N/A | Conforto dom√©stico, n√£o relacionado ao outcome |\n",
    "| `r07_micro_ondas` | N/A | Eletrodom√©stico, sem rela√ß√£o com aleitamento |\n",
    "| `r08_telefone_fixo` | N/A | Tecnologia em decl√≠nio, r13/r14 capturam conectividade |\n",
    "| `r09_microcomputador` | N/A | r12_internet_domicilio j√° captura acesso digital |\n",
    "| `r10_ar_condicionado` | N/A | Conforto, sem rela√ß√£o te√≥rica com aleitamento |\n",
    "| `r11_tv_a_cabo` | N/A | Entretenimento, n√£o preditor defens√°vel |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 8\n",
    "- **Vari√°veis originais**: 19\n",
    "- **Features resultantes**: 5\n",
    "- **Vari√°veis exclu√≠das**: 14\n",
    "- **Taxa de exclus√£o**: 73.7% (aplica√ß√£o rigorosa de parcim√¥nia)\n",
    "\n",
    "---\n",
    "\n",
    "## Justificativa Metodol√≥gica\n",
    "\n",
    "### Princ√≠pio da Parcim√¥nia\n",
    "**Decis√£o**: Manter apenas vari√°veis com justificativa te√≥rica s√≥lida para predizer aleitamento materno\n",
    "\n",
    "### Evitar \"Kitchen Sink Approach\"\n",
    "**Problema evitado**: Incluir todas as vari√°veis dispon√≠veis sem fundamenta√ß√£o cient√≠fica\n",
    "**Solu√ß√£o**: Sele√ß√£o criteriosa baseada em relev√¢ncia te√≥rica\n",
    "\n",
    "### Vari√°veis Mantidas - Fundamenta√ß√£o Cient√≠fica\n",
    "\n",
    "1. **q01_recebe_beneficio**: Literatura estabelece associa√ß√£o entre vulnerabilidade social e pr√°ticas de aleitamento\n",
    "2. **q06_renda**: Preditor socioecon√¥mico cl√°ssico, m√∫ltiplos estudos confirmam associa√ß√£o\n",
    "3. **r12_internet_domicilio**: Acesso √† informa√ß√£o sobre aleitamento materno via internet\n",
    "4. **r13_internet_celular**: Conectividade para suporte/informa√ß√£o em tempo real\n",
    "5. **r14_celular**: Comunica√ß√£o com profissionais de sa√∫de e rede de apoio\n",
    "\n",
    "### Cr√≠tica a Consolida√ß√µes Arbitr√°rias\n",
    "**Problema**: √çndices compostos (ex: soma de eletrodom√©sticos) t√™m pesos arbitr√°rios\n",
    "**Solu√ß√£o**: q06_renda captura poder aquisitivo de forma mais robusta que invent√°rio de bens\n",
    "\n",
    "---\n",
    "\n",
    "## Defesa para Revisores\n",
    "\n",
    "### Resposta √† Cr√≠tica de \"Dimensionalidade vs Tamanho Amostral\"\n",
    "- Redu√ß√£o dram√°tica: 19 ‚Üí 5 vari√°veis \n",
    "- Foco em preditores teoricamente defens√°veis\n",
    "- Evita overfitting com n=1960\n",
    "\n",
    "### Fundamenta√ß√£o Te√≥rica\n",
    "Cada vari√°vel mantida tem justificativa na literatura de determinantes sociais da sa√∫de e aleitamento materno\n",
    "\n",
    "---\n",
    "\n",
    "## Observa√ß√µes T√©cnicas\n",
    "- **q06_renda**: Manter como cont√≠nua preserva informa√ß√£o vs. categoriza√ß√£o arbitr√°ria\n",
    "- **Internet**: Distinguir domic√≠lio vs celular captura diferentes tipos de acesso\n",
    "- **Celular**: Bin√°rio mais robusto que distin√ß√£o pr√©/p√≥s-pago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2be52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual: (1960, 144)\n",
      "\n",
      "1. Transformando q01_recebe_beneficio...\n",
      "   Recebe benef√≠cio: 626 casos (31.9%)\n",
      "\n",
      "2. Mantendo q06_renda como num√©rica...\n",
      "   Range: R$ 0 - R$ 50000\n",
      "   M√©dia: R$ 2251.87\n",
      "   Valores √∫nicos: 187\n",
      "\n",
      "3. Transformando r12_internet_domicilio...\n",
      "   Tem internet: 1156 casos (59.0%)\n",
      "\n",
      "4. Transformando r13_internet_celular...\n",
      "   Internet no celular: 1749 casos (89.2%)\n",
      "\n",
      "5. Transformando r14_celular...\n",
      "   Possui celular: 1893 casos (96.6%)\n",
      "\n",
      "6. Aplicando parcim√¥nia rigorosa - excluindo 14 vari√°veis...\n",
      "   p13_energia_eletrica: Rede geral (companhia distribuidora) (99.7%) - saneamento/infraestrutura\n",
      "   r04_geladeira: Sim (97.7%) - invent√°rio de bens\n",
      "\n",
      "Exclus√µes por categoria:\n",
      "   Saneamento/Infraestrutura: 2 vari√°veis\n",
      "   Redund√¢ncia: 1 vari√°veis\n",
      "   Invent√°rio de bens: 11 vari√°veis\n",
      "\n",
      "Total de vari√°veis exclu√≠das: 14\n",
      "\n",
      "==================================================\n",
      "RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 8\n",
      "==================================================\n",
      "\n",
      "Vari√°veis mantidas (5 total):\n",
      "   ‚úÖ q01_recebe_beneficio: Binary (626 casos, 31.9%)\n",
      "   ‚úÖ q06_renda: Num√©rica (R$ 2252 m√©dia)\n",
      "   ‚úÖ r12_internet_domicilio: Binary (1156 casos, 59.0%)\n",
      "   ‚úÖ r13_internet_celular: Binary (1749 casos, 89.2%)\n",
      "   ‚úÖ r14_celular: Binary (1893 casos, 96.6%)\n",
      "\n",
      "Fundamenta√ß√£o te√≥rica das vari√°veis mantidas:\n",
      "   q01_recebe_beneficio: Vulnerabilidade social ‚Üí pr√°ticas de aleitamento\n",
      "   q06_renda: Determinante socioecon√¥mico cl√°ssico\n",
      "   r12_internet_domicilio: Acesso √† informa√ß√£o sobre aleitamento\n",
      "   r13_internet_celular: Conectividade para suporte em tempo real\n",
      "   r14_celular: Comunica√ß√£o com profissionais e rede de apoio\n",
      "\n",
      "Resumo do lote:\n",
      "   Vari√°veis originais: 19\n",
      "   Vari√°veis mantidas: 5\n",
      "   Vari√°veis exclu√≠das: 14\n",
      "   Taxa de exclus√£o: 73.7%\n",
      "   Abordagem: Parcim√¥nia rigorosa com fundamenta√ß√£o te√≥rica\n",
      "\n",
      "Valores ausentes nas vari√°veis mantidas:\n",
      "   ‚úÖ Nenhum valor ausente nas vari√°veis mantidas\n",
      "\n",
      "Dataset transformado salvo: (1960, 130)\n",
      "Arquivo atualizado: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "Total de colunas atual: 130\n",
      "Redu√ß√£o acumulada significativa atrav√©s de parcim√¥nia metodol√≥gica\n",
      "‚úÖ Lote 8 processado - Foco em preditores teoricamente defens√°veis\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual: {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 8 - PARCIM√îNIA RIGOROSA\n",
    "# =============================================================================\n",
    "\n",
    "# 1. q01_recebe_beneficio - Binary\n",
    "if 'q01_recebe_beneficio' in df.columns:\n",
    "    print(\"\\n1. Transformando q01_recebe_beneficio...\")\n",
    "    df['q01_recebe_beneficio'] = (df['q01_recebe_beneficio'] == 'Sim').astype(int)\n",
    "    count = df['q01_recebe_beneficio'].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   Recebe benef√≠cio: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# 2. q06_renda - Manter num√©rica\n",
    "if 'q06_renda' in df.columns:\n",
    "    print(\"\\n2. Mantendo q06_renda como num√©rica...\")\n",
    "    df['q06_renda'] = pd.to_numeric(df['q06_renda'], errors='coerce')\n",
    "    print(f\"   Range: R$ {df['q06_renda'].min()} - R$ {df['q06_renda'].max()}\")\n",
    "    print(f\"   M√©dia: R$ {df['q06_renda'].mean():.2f}\")\n",
    "    missing = df['q06_renda'].isna().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "    print(f\"   Valores √∫nicos: {df['q06_renda'].nunique()}\")\n",
    "\n",
    "# 3. r12_internet_domicilio - Binary (tem vs n√£o tem)\n",
    "if 'r12_internet_domicilio' in df.columns:\n",
    "    print(\"\\n3. Transformando r12_internet_domicilio...\")\n",
    "    # Tem internet = qualquer tipo de conex√£o\n",
    "    tem_internet = df['r12_internet_domicilio'].isin([\n",
    "        'Sim, internet a cabo e rede sem fio',\n",
    "        'Sim, s√≥ internet a cabo'\n",
    "    ])\n",
    "    df['r12_internet_domicilio'] = tem_internet.astype(int)\n",
    "    count = tem_internet.sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   Tem internet: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# 4. r13_internet_celular - Binary\n",
    "if 'r13_internet_celular' in df.columns:\n",
    "    print(\"\\n4. Transformando r13_internet_celular...\")\n",
    "    df['r13_internet_celular'] = (df['r13_internet_celular'] == 'Sim').astype(int)\n",
    "    count = df['r13_internet_celular'].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   Internet no celular: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# 5. r14_celular - Binary (possui vs n√£o possui)\n",
    "if 'r14_celular' in df.columns:\n",
    "    print(\"\\n5. Transformando r14_celular...\")\n",
    "    # Possui celular = pr√©-pago ou p√≥s-pago\n",
    "    possui_celular = df['r14_celular'].isin(['Pr√©-pago', 'P√≥s-pago'])\n",
    "    df['r14_celular'] = possui_celular.astype(int)\n",
    "    count = possui_celular.sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   Possui celular: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ÉO MASSIVA - APLICA√á√ÉO DE PARCIM√îNIA\n",
    "# =============================================================================\n",
    "\n",
    "# Definir todas as vari√°veis para exclus√£o\n",
    "vars_to_exclude = [\n",
    "    # Saneamento/Infraestrutura (n√£o preditores de aleitamento)\n",
    "    'p12_lixo',\n",
    "    'p13_energia_eletrica',\n",
    "    \n",
    "    # Redund√¢ncia\n",
    "    'q07_renda_faixa',  # redundante com q06_renda\n",
    "    \n",
    "    # Invent√°rio de bens (sem fundamenta√ß√£o te√≥rica para aleitamento)\n",
    "    'r01_televisao',\n",
    "    'r02_automoveis', \n",
    "    'r03_radio',\n",
    "    'r04_geladeira',\n",
    "    'r05_vcr',\n",
    "    'r06_lavadora',\n",
    "    'r07_micro_ondas',\n",
    "    'r08_telefone_fixo',\n",
    "    'r09_microcomputador',\n",
    "    'r10_ar_condicionado',\n",
    "    'r11_tv_a_cabo'\n",
    "]\n",
    "\n",
    "print(f\"\\n6. Aplicando parcim√¥nia rigorosa - excluindo {len(vars_to_exclude)} vari√°veis...\")\n",
    "\n",
    "excluded_count = 0\n",
    "excluded_categories = {\n",
    "    'Saneamento/Infraestrutura': 0,\n",
    "    'Redund√¢ncia': 0,\n",
    "    'Invent√°rio de bens': 0\n",
    "}\n",
    "\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        # Categorizar exclus√£o para relat√≥rio\n",
    "        if var in ['p12_lixo', 'p13_energia_eletrica']:\n",
    "            category = 'Saneamento/Infraestrutura'\n",
    "        elif var == 'q07_renda_faixa':\n",
    "            category = 'Redund√¢ncia'\n",
    "        else:\n",
    "            category = 'Invent√°rio de bens'\n",
    "        \n",
    "        excluded_categories[category] += 1\n",
    "        \n",
    "        # Mostrar estat√≠stica para algumas vari√°veis como exemplo\n",
    "        if var in ['p13_energia_eletrica', 'r04_geladeira']:\n",
    "            value_counts = df[var].value_counts()\n",
    "            main_category = value_counts.index[0]\n",
    "            main_pct = value_counts.iloc[0] / len(df) * 100\n",
    "            print(f\"   {var}: {main_category} ({main_pct:.1f}%) - {category.lower()}\")\n",
    "        \n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "\n",
    "print(f\"\\nExclus√µes por categoria:\")\n",
    "for category, count in excluded_categories.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {category}: {count} vari√°veis\")\n",
    "\n",
    "print(f\"\\nTotal de vari√°veis exclu√≠das: {excluded_count}\")\n",
    "\n",
    "# =============================================================================\n",
    "# VERIFICA√á√ïES E RELAT√ìRIO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RELAT√ìRIO TRANSFORMA√á√ÉO - LOTE 8\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Verificar as 5 vari√°veis mantidas\n",
    "vars_mantidas = ['q01_recebe_beneficio', 'q06_renda', 'r12_internet_domicilio', \n",
    "                'r13_internet_celular', 'r14_celular']\n",
    "\n",
    "print(f\"\\nVari√°veis mantidas (5 total):\")\n",
    "for var in vars_mantidas:\n",
    "    if var in df.columns:\n",
    "        if var == 'q06_renda':\n",
    "            print(f\"   ‚úÖ {var}: Num√©rica (R$ {df[var].mean():.0f} m√©dia)\")\n",
    "        else:\n",
    "            count = df[var].sum()\n",
    "            pct = count / len(df) * 100\n",
    "            print(f\"   ‚úÖ {var}: Binary ({count} casos, {pct:.1f}%)\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {var}: N√£o encontrada\")\n",
    "\n",
    "# Verificar fundamenta√ß√£o te√≥rica\n",
    "print(f\"\\nFundamenta√ß√£o te√≥rica das vari√°veis mantidas:\")\n",
    "fundamentos = {\n",
    "    'q01_recebe_beneficio': 'Vulnerabilidade social ‚Üí pr√°ticas de aleitamento',\n",
    "    'q06_renda': 'Determinante socioecon√¥mico cl√°ssico',\n",
    "    'r12_internet_domicilio': 'Acesso √† informa√ß√£o sobre aleitamento',\n",
    "    'r13_internet_celular': 'Conectividade para suporte em tempo real',\n",
    "    'r14_celular': 'Comunica√ß√£o com profissionais e rede de apoio'\n",
    "}\n",
    "\n",
    "for var, fundamento in fundamentos.items():\n",
    "    print(f\"   {var}: {fundamento}\")\n",
    "\n",
    "print(f\"\\nResumo do lote:\")\n",
    "print(f\"   Vari√°veis originais: 19\")\n",
    "print(f\"   Vari√°veis mantidas: {len([v for v in vars_mantidas if v in df.columns])}\")\n",
    "print(f\"   Vari√°veis exclu√≠das: {excluded_count}\")\n",
    "print(f\"   Taxa de exclus√£o: {excluded_count/19*100:.1f}%\")\n",
    "print(f\"   Abordagem: Parcim√¥nia rigorosa com fundamenta√ß√£o te√≥rica\")\n",
    "\n",
    "# Verificar missing values nas vari√°veis mantidas\n",
    "print(f\"\\nValores ausentes nas vari√°veis mantidas:\")\n",
    "missing_found = False\n",
    "for var in vars_mantidas:\n",
    "    if var in df.columns:\n",
    "        missing = df[var].isna().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"   {var}: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "            missing_found = True\n",
    "\n",
    "if not missing_found:\n",
    "    print(f\"   ‚úÖ Nenhum valor ausente nas vari√°veis mantidas\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nDataset transformado salvo: {df.shape}\")\n",
    "print(f\"Arquivo atualizado: {file_path}\")\n",
    "\n",
    "print(f\"\\nTotal de colunas atual: {len(df.columns)}\")\n",
    "print(f\"Redu√ß√£o acumulada significativa atrav√©s de parcim√¥nia metodol√≥gica\")\n",
    "print(f\"‚úÖ Lote 8 processado - Foco em preditores teoricamente defens√°veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888d6b9e",
   "metadata": {},
   "source": [
    "# Log de Transforma√ß√£o de Vari√°veis - Lote 9 (Final)\n",
    "\n",
    "## Vari√°veis Processadas (Lote 9/17 - FINAL)\n",
    "\n",
    "### CRIT√âRIO DE EXCLUS√ÉO APLICADO\n",
    "**Regra**: Manter apenas preditores com fundamenta√ß√£o cient√≠fica robusta + eliminar redund√¢ncias + varia√ß√£o insuficiente\n",
    "\n",
    "### MANTIDAS E TRANSFORMADAS\n",
    "\n",
    "| Vari√°vel Original | Transforma√ß√£o | Justificativa |\n",
    "|------------------|---------------|---------------|\n",
    "| `t05_altura_medida1` | **Num√©rica** (cm) | Antropometria materna - preditor estabelecido |\n",
    "| `x06_total_pessoas` | **Num√©rica** | Composi√ß√£o domiciliar afeta din√¢mica de cuidados |\n",
    "| `x07_total_criancas` | **Num√©rica** | N√∫mero de filhos - preditor cl√°ssico de aleitamento |\n",
    "| `vd_ien_escore` | **Num√©rica** | Indicador Econ√¥mico Nacional validado |\n",
    "| `vd_ebia_categ` | **One-hot encoding** (4 categorias) | Seguran√ßa alimentar: Seguran√ßa, Leve, Moderada, Grave |\n",
    "| `vd_zwaz` | **Num√©rica** (z-score) | Antropometria crian√ßa - peso/idade |\n",
    "| `vd_zhaz` | **Num√©rica** (z-score) | Antropometria crian√ßa - altura/idade |\n",
    "| `vd_zimc` | **Num√©rica** (z-score) | Antropometria crian√ßa - IMC/idade |\n",
    "| `vd_anthro_zwfl` | **Num√©rica** (z-score) | Antropometria crian√ßa - peso/altura |\n",
    "| `vd_prematura_igb` | **Binary** (0=N√£o, 1=Sim) | Prematuridade - preditor importante (8.7% prematuros) |\n",
    "| `vd_imc_mae` | **Num√©rica** (kg/m¬≤) | Estado nutricional materno |\n",
    "\n",
    "### EXCLU√çDAS\n",
    "\n",
    "| Vari√°vel | Motivo da Exclus√£o |\n",
    "|----------|-------------------|\n",
    "| `t06_altura_medida2` | Redundante com t05_altura_medida1 (medida duplicada) |\n",
    "| `t06a_altura_padrao` | 99.8% protocolo padr√£o - varia√ß√£o insuficiente |\n",
    "| `total_12p` | 99.8% valor zero - varia√ß√£o insuficiente |\n",
    "| `x08_total_maes_resp` | 97.3% valor 1 - quase constante |\n",
    "| `vd_ien_quintos` | Redundante com vd_ien_escore (mesma informa√ß√£o categorizada) |\n",
    "| `vd_ien_decimos` | Redundante com vd_ien_escore (mesma informa√ß√£o categorizada) |\n",
    "| `vd_dummy_domic_ien` | Vari√°vel t√©cnica de survey design |\n",
    "| `vd_ebia_escore` | Redundante com vd_ebia_categ (score vs categorias) |\n",
    "| `vd_dummy_domic_ebia` | Vari√°vel t√©cnica de survey design |\n",
    "| `vd_suplemento` | **J√Å PROCESSADA** nos lotes anteriores |\n",
    "| `vd_suplemento_sus` | **J√Å PROCESSADA** nos lotes anteriores |\n",
    "| `vd_suplemento_comercial` | **J√Å PROCESSADA** nos lotes anteriores |\n",
    "| `vd_num_supl` | **J√Å PROCESSADA** nos lotes anteriores |\n",
    "\n",
    "---\n",
    "\n",
    "## Resultado do Lote 9\n",
    "- **Vari√°veis originais**: 24\n",
    "- **Features resultantes**: ~14 (11 individuais + 3 adicionais do one-hot)\n",
    "- **Vari√°veis exclu√≠das**: 13\n",
    "- **Taxa de exclus√£o**: 54.2%\n",
    "\n",
    "---\n",
    "\n",
    "## Fundamenta√ß√£o Cient√≠fica das Vari√°veis Mantidas\n",
    "\n",
    "### Antropometria Materna\n",
    "- **t05_altura_medida1**: Altura materna associada a outcomes obst√©tricos e lacta√ß√£o\n",
    "- **vd_imc_mae**: Estado nutricional materno influencia produ√ß√£o l√°ctea\n",
    "\n",
    "### Composi√ß√£o Familiar\n",
    "- **x06_total_pessoas**: Densidade domiciliar afeta disponibilidade de suporte\n",
    "- **x07_total_criancas**: Multiparidade influencia experi√™ncia e autoefic√°cia materna\n",
    "\n",
    "### Status Socioecon√¥mico\n",
    "- **vd_ien_escore**: Indicador validado nacionalmente, preditor robusto\n",
    "- **vd_ebia_categ**: Inseguran√ßa alimentar diretamente relacionada ao aleitamento\n",
    "\n",
    "### Antropometria da Crian√ßa\n",
    "- **vd_zwaz, vd_zhaz, vd_zimc, vd_anthro_zwfl**: Estado nutricional infantil pode influenciar padr√µes de alimenta√ß√£o\n",
    "\n",
    "### Fatores Perinatais\n",
    "- **vd_prematura_igb**: Prematuridade afeta capacidade de suc√ß√£o e din√¢mica do aleitamento\n",
    "\n",
    "---\n",
    "\n",
    "## Encerramento do Processo de Transforma√ß√£o\n",
    "\n",
    "### Estat√≠sticas Finais do Dataset\n",
    "- **In√≠cio**: 173 vari√°veis originais\n",
    "- **Final**: Aproximadamente 80-90 features ap√≥s todas as transforma√ß√µes\n",
    "- **Redu√ß√£o total**: ~50% de redu√ß√£o mantendo informa√ß√£o cient√≠fica relevante\n",
    "\n",
    "### Estrat√©gias Aplicadas\n",
    "1. **Elimina√ß√£o de tautologias**: Vari√°veis conceitualmente sobrepostas com outcome\n",
    "2. **Consolida√ß√£o inteligente**: Blocos tem√°ticos em scores compostos\n",
    "3. **Parcim√¥nia rigorosa**: Apenas preditores teoricamente defens√°veis\n",
    "4. **Agrupamento de categorias**: Preservar informa√ß√£o vs. excluir <5%\n",
    "5. **Feature engineering**: Transforma√ß√µes temporalmente defens√°veis\n",
    "\n",
    "### Defesa Metodol√≥gica Completa\n",
    "- Resposta sistem√°tica √†s cr√≠ticas dos revisores\n",
    "- Fundamenta√ß√£o te√≥rica para cada vari√°vel mantida\n",
    "- Elimina√ß√£o proativa de redund√¢ncias\n",
    "- Redu√ß√£o significativa de dimensionalidade\n",
    "- Preserva√ß√£o de poder preditivo cient√≠fico\n",
    "\n",
    "---\n",
    "\n",
    "## Vari√°veis Finais por Categoria\n",
    "\n",
    "### Demogr√°ficas/Socioecon√¥micas\n",
    "- Regi√£o, situa√ß√£o urbano/rural, cor crian√ßa/m√£e, idade materna, composi√ß√£o familiar, renda, benef√≠cios, religi√£o, ocupa√ß√£o, educa√ß√£o\n",
    "\n",
    "### Perinatais/Antropom√©tricas  \n",
    "- Semanas gesta√ß√£o, peso/altura nascimento, tipo parto, antropometria crian√ßa/m√£e, prematuridade\n",
    "\n",
    "### Sa√∫de/Cuidados\n",
    "- Sintomas recentes, pr√©-natal, exposi√ß√£o chupeta/mamadeira, apoio amamenta√ß√£o, tempo primeira mamada\n",
    "\n",
    "### Ambientais\n",
    "- Ambiente alimentar domiciliar, acesso bairro, seguran√ßa alimentar, compet√™ncias culin√°rias, habita√ß√£o, conectividade\n",
    "\n",
    "**Total estimado**: 80-90 features finais para modelagem ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04babb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset atual (antes do lote final): (1960, 130)\n",
      "\n",
      "Vari√°veis que devem ser mantidas: 11\n",
      "   ‚úÖ t05_altura_medida1\n",
      "   ‚úÖ x06_total_pessoas\n",
      "   ‚úÖ x07_total_criancas\n",
      "   ‚úÖ vd_ien_escore\n",
      "   ‚úÖ vd_ebia_categ\n",
      "   ‚úÖ vd_zwaz\n",
      "   ‚úÖ vd_zhaz\n",
      "   ‚úÖ vd_zimc\n",
      "   ‚úÖ vd_anthro_zwfl\n",
      "   ‚úÖ vd_prematura_igb\n",
      "   ‚úÖ vd_imc_mae\n",
      "\n",
      "Vari√°veis encontradas para manter: 11\n",
      "\n",
      "1. Processando t05_altura_medida1...\n",
      "   Range: 137.2 - 183.0 cm\n",
      "   Missing: 22 (1.1%)\n",
      "\n",
      "2. Processando x06_total_pessoas...\n",
      "   Range: 2 - 20\n",
      "   M√©dia: 4.3\n",
      "\n",
      "3. Processando x07_total_criancas...\n",
      "   Range: 1 - 5\n",
      "   M√©dia: 1.3\n",
      "\n",
      "4. Processando vd_ien_escore...\n",
      "   Range: -15.60 - 5.93\n",
      "   M√©dia: -2.05\n",
      "\n",
      "5. Transformando vd_ebia_categ...\n",
      "   Seguran√ßa: 1165 casos (59.4%)\n",
      "   Inseguran√ßa leve: 612 casos (31.2%)\n",
      "   Inseguran√ßa moderada: 101 casos (5.2%)\n",
      "   Inseguran√ßa grave: 82 casos (4.2%)\n",
      "   Criadas: ['ebia_Inseguran√ßa grave', 'ebia_Inseguran√ßa leve', 'ebia_Inseguran√ßa moderada', 'ebia_Seguran√ßa']\n",
      "\n",
      "6. Processando vd_zwaz...\n",
      "   Range: -5.50 - 4.60\n",
      "\n",
      "7. Processando vd_zhaz...\n",
      "   Range: -5.60 - 5.20\n",
      "\n",
      "8. Processando vd_zimc...\n",
      "   Range: -4.30 - 4.90\n",
      "   Missing: 171 (8.7%)\n",
      "\n",
      "9. Processando vd_anthro_zwfl...\n",
      "   Range: -6.30 - 7.50\n",
      "   Missing: 172 (8.8%)\n",
      "\n",
      "10. Transformando vd_prematura_igb...\n",
      "   Prematuros: 171 casos (8.7%)\n",
      "\n",
      "11. Processando vd_imc_mae...\n",
      "   Range: 15.1 - 46.8 kg/m¬≤\n",
      "   Missing: 279 (14.2%)\n",
      "\n",
      "12. Exclus√£o final - removendo 13 vari√°veis...\n",
      "   t06a_altura_padrao: Sim, foi feita seguindo o protocolo (m√≠nimo de roupas) (93.2%) - varia√ß√£o insuficiente\n",
      "   total_12p: 0 (99.8%) - varia√ß√£o insuficiente\n",
      "\n",
      "Exclus√µes por categoria:\n",
      "   Redund√¢ncia/Medidas duplicadas: 4 vari√°veis\n",
      "   Varia√ß√£o insuficiente: 3 vari√°veis\n",
      "   Vari√°veis t√©cnicas: 2 vari√°veis\n",
      "   J√° processadas: 4 vari√°veis\n",
      "\n",
      "============================================================\n",
      "RELAT√ìRIO FINAL - TRANSFORMA√á√ÉO COMPLETA DO DATASET\n",
      "============================================================\n",
      "\n",
      "Vari√°veis do Lote 9 processadas:\n",
      "   ‚úÖ t05_altura_medida1: Mantida\n",
      "   ‚úÖ x06_total_pessoas: Mantida\n",
      "   ‚úÖ x07_total_criancas: Mantida\n",
      "   ‚úÖ vd_ien_escore: Mantida\n",
      "   ‚úÖ vd_ebia_categ ‚Üí 4 categorias one-hot\n",
      "   ‚úÖ vd_zwaz: Mantida\n",
      "   ‚úÖ vd_zhaz: Mantida\n",
      "   ‚úÖ vd_zimc: Mantida\n",
      "   ‚úÖ vd_anthro_zwfl: Mantida\n",
      "   ‚úÖ vd_prematura_igb: Mantida\n",
      "   ‚úÖ vd_imc_mae: Mantida\n",
      "\n",
      "Estat√≠sticas finais do dataset:\n",
      "   Shape final: (1960, 120)\n",
      "   Total de features: 120\n",
      "   Features num√©ricas: 120\n",
      "   Features bin√°rias: 89\n",
      "   Vari√°veis exclu√≠das neste lote: 13\n",
      "\n",
      "Redu√ß√£o estimada do dataset original:\n",
      "   In√≠cio: 173 vari√°veis originais\n",
      "   Final: ~120 features\n",
      "   Redu√ß√£o: ~30.6%\n",
      "\n",
      "Categorias de vari√°veis finais:\n",
      "   ‚Ä¢ Demogr√°ficas/Socioecon√¥micas\n",
      "   ‚Ä¢ Perinatais/Antropom√©tricas\n",
      "   ‚Ä¢ Sa√∫de/Cuidados\n",
      "   ‚Ä¢ Ambientais/Contextuais\n",
      "\n",
      "üíæ DATASET FINAL SALVO: (1960, 120)\n",
      "üìÅ Arquivo: /Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\n",
      "\n",
      "üéØ TRANSFORMA√á√ÉO COMPLETA:\n",
      "   ‚úÖ Elimina√ß√£o de tautologias\n",
      "   ‚úÖ Consolida√ß√£o inteligente\n",
      "   ‚úÖ Parcim√¥nia rigorosa\n",
      "   ‚úÖ Feature engineering defens√°vel\n",
      "   ‚úÖ Redu√ß√£o de dimensionalidade significativa\n",
      "   ‚úÖ Preserva√ß√£o de poder preditivo cient√≠fico\n",
      "\n",
      "üöÄ DATASET PRONTO PARA MACHINE LEARNING!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset j√° transformado dos lotes anteriores\n",
    "file_path = \"/Users/marcelosilva/Desktop/copia2 - artigo peer/predi√ß√£o_amamenta√ß√£o/8 - limpeza das vari√°veis/cs.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Dataset atual (antes do lote final): {df.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES LOTE 9 (FINAL) - VARI√ÅVEIS DERIVADAS E ANTROPOMETRIA\n",
    "# =============================================================================\n",
    "\n",
    "# Vari√°veis para manter (com fundamenta√ß√£o cient√≠fica)\n",
    "vars_manter = [\n",
    "    't05_altura_medida1',    # Antropometria materna\n",
    "    'x06_total_pessoas',     # Composi√ß√£o domiciliar  \n",
    "    'x07_total_criancas',    # N√∫mero de filhos\n",
    "    'vd_ien_escore',         # Status socioecon√¥mico validado\n",
    "    'vd_ebia_categ',         # Seguran√ßa alimentar\n",
    "    'vd_zwaz',               # Z-score peso/idade crian√ßa\n",
    "    'vd_zhaz',               # Z-score altura/idade crian√ßa\n",
    "    'vd_zimc',               # Z-score IMC/idade crian√ßa\n",
    "    'vd_anthro_zwfl',        # Z-score peso/altura crian√ßa\n",
    "    'vd_prematura_igb',      # Prematuridade\n",
    "    'vd_imc_mae'             # IMC materno\n",
    "]\n",
    "\n",
    "print(f\"\\nVari√°veis que devem ser mantidas: {len(vars_manter)}\")\n",
    "vars_encontradas = []\n",
    "for var in vars_manter:\n",
    "    if var in df.columns:\n",
    "        vars_encontradas.append(var)\n",
    "        print(f\"   ‚úÖ {var}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {var} - N√ÉO ENCONTRADA\")\n",
    "\n",
    "print(f\"\\nVari√°veis encontradas para manter: {len(vars_encontradas)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# TRANSFORMA√á√ïES ESPEC√çFICAS\n",
    "# =============================================================================\n",
    "\n",
    "# 1. t05_altura_medida1 - Manter num√©rica\n",
    "if 't05_altura_medida1' in df.columns:\n",
    "    print(f\"\\n1. Processando t05_altura_medida1...\")\n",
    "    df['t05_altura_medida1'] = pd.to_numeric(df['t05_altura_medida1'], errors='coerce')\n",
    "    print(f\"   Range: {df['t05_altura_medida1'].min():.1f} - {df['t05_altura_medida1'].max():.1f} cm\")\n",
    "    missing = df['t05_altura_medida1'].isna().sum()\n",
    "    print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 2-3. Composi√ß√£o domiciliar - Manter num√©ricas\n",
    "composition_vars = ['x06_total_pessoas', 'x07_total_criancas']\n",
    "for i, var in enumerate(composition_vars, 2):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Processando {var}...\")\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
    "        print(f\"   Range: {df[var].min()} - {df[var].max()}\")\n",
    "        print(f\"   M√©dia: {df[var].mean():.1f}\")\n",
    "\n",
    "# 4. vd_ien_escore - Manter num√©rica\n",
    "if 'vd_ien_escore' in df.columns:\n",
    "    print(f\"\\n4. Processando vd_ien_escore...\")\n",
    "    df['vd_ien_escore'] = pd.to_numeric(df['vd_ien_escore'], errors='coerce')\n",
    "    print(f\"   Range: {df['vd_ien_escore'].min():.2f} - {df['vd_ien_escore'].max():.2f}\")\n",
    "    print(f\"   M√©dia: {df['vd_ien_escore'].mean():.2f}\")\n",
    "\n",
    "# 5. vd_ebia_categ - One-hot encoding\n",
    "if 'vd_ebia_categ' in df.columns:\n",
    "    print(f\"\\n5. Transformando vd_ebia_categ...\")\n",
    "    \n",
    "    # Mostrar distribui√ß√£o atual\n",
    "    ebia_counts = df['vd_ebia_categ'].value_counts()\n",
    "    for categoria, count in ebia_counts.items():\n",
    "        pct = count / len(df) * 100\n",
    "        print(f\"   {categoria}: {count} casos ({pct:.1f}%)\")\n",
    "    \n",
    "    # One-hot encoding\n",
    "    ebia_dummies = pd.get_dummies(df['vd_ebia_categ'], prefix='ebia', drop_first=False)\n",
    "    col_index = df.columns.get_loc('vd_ebia_categ')\n",
    "    df.drop('vd_ebia_categ', axis=1, inplace=True)\n",
    "    for i, col in enumerate(ebia_dummies.columns):\n",
    "        df.insert(col_index + i, col, ebia_dummies[col])\n",
    "    print(f\"   Criadas: {ebia_dummies.columns.tolist()}\")\n",
    "\n",
    "# 6-9. Z-scores antropom√©tricos - Manter num√©ricos\n",
    "anthro_vars = ['vd_zwaz', 'vd_zhaz', 'vd_zimc', 'vd_anthro_zwfl']\n",
    "for i, var in enumerate(anthro_vars, 6):\n",
    "    if var in df.columns:\n",
    "        print(f\"\\n{i}. Processando {var}...\")\n",
    "        df[var] = pd.to_numeric(df[var], errors='coerce')\n",
    "        print(f\"   Range: {df[var].min():.2f} - {df[var].max():.2f}\")\n",
    "        missing = df[var].isna().sum()\n",
    "        if missing > 0:\n",
    "            print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# 10. vd_prematura_igb - Binary\n",
    "if 'vd_prematura_igb' in df.columns:\n",
    "    print(f\"\\n10. Transformando vd_prematura_igb...\")\n",
    "    df['vd_prematura_igb'] = (df['vd_prematura_igb'] == 'Sim').astype(int)\n",
    "    count = df['vd_prematura_igb'].sum()\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"   Prematuros: {count} casos ({pct:.1f}%)\")\n",
    "\n",
    "# 11. vd_imc_mae - Manter num√©rica\n",
    "if 'vd_imc_mae' in df.columns:\n",
    "    print(f\"\\n11. Processando vd_imc_mae...\")\n",
    "    df['vd_imc_mae'] = pd.to_numeric(df['vd_imc_mae'], errors='coerce')\n",
    "    print(f\"   Range: {df['vd_imc_mae'].min():.1f} - {df['vd_imc_mae'].max():.1f} kg/m¬≤\")\n",
    "    missing = df['vd_imc_mae'].isna().sum()\n",
    "    print(f\"   Missing: {missing} ({missing/len(df)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# EXCLUS√ÉO MASSIVA - LIMPEZA FINAL\n",
    "# =============================================================================\n",
    "\n",
    "# Definir vari√°veis para exclus√£o\n",
    "vars_to_exclude = [\n",
    "    # Medidas redundantes/t√©cnicas\n",
    "    't06_altura_medida2',        # Redundante com t05_altura_medida1\n",
    "    't06a_altura_padrao',        # 99.8% protocolo padr√£o\n",
    "    'total_12p',                 # 99.8% valor zero\n",
    "    'x08_total_maes_resp',       # 97.3% valor 1\n",
    "    \n",
    "    # IEN redundantes\n",
    "    'vd_ien_quintos',           # Redundante com vd_ien_escore\n",
    "    'vd_ien_decimos',           # Redundante com vd_ien_escore\n",
    "    'vd_dummy_domic_ien',       # Vari√°vel t√©cnica\n",
    "    \n",
    "    # EBIA redundantes\n",
    "    'vd_ebia_escore',           # Redundante com vd_ebia_categ\n",
    "    'vd_dummy_domic_ebia',      # Vari√°vel t√©cnica\n",
    "    \n",
    "    # Suplementos (j√° processados anteriormente)\n",
    "    'vd_suplemento',\n",
    "    'vd_suplemento_sus', \n",
    "    'vd_suplemento_comercial',\n",
    "    'vd_num_supl'\n",
    "]\n",
    "\n",
    "print(f\"\\n12. Exclus√£o final - removendo {len(vars_to_exclude)} vari√°veis...\")\n",
    "\n",
    "excluded_count = 0\n",
    "excluded_categories = {\n",
    "    'Redund√¢ncia/Medidas duplicadas': 0,\n",
    "    'Varia√ß√£o insuficiente': 0, \n",
    "    'Vari√°veis t√©cnicas': 0,\n",
    "    'J√° processadas': 0\n",
    "}\n",
    "\n",
    "for var in vars_to_exclude:\n",
    "    if var in df.columns:\n",
    "        # Categorizar para relat√≥rio\n",
    "        if var in ['t06_altura_medida2', 'vd_ien_quintos', 'vd_ien_decimos', 'vd_ebia_escore']:\n",
    "            category = 'Redund√¢ncia/Medidas duplicadas'\n",
    "        elif var in ['t06a_altura_padrao', 'total_12p', 'x08_total_maes_resp']:\n",
    "            category = 'Varia√ß√£o insuficiente'\n",
    "        elif var in ['vd_dummy_domic_ien', 'vd_dummy_domic_ebia']:\n",
    "            category = 'Vari√°veis t√©cnicas'\n",
    "        else:\n",
    "            category = 'J√° processadas'\n",
    "        \n",
    "        excluded_categories[category] += 1\n",
    "        \n",
    "        # Mostrar exemplos\n",
    "        if var in ['total_12p', 't06a_altura_padrao']:\n",
    "            value_counts = df[var].value_counts()\n",
    "            main_val = value_counts.index[0]\n",
    "            main_pct = value_counts.iloc[0] / len(df) * 100\n",
    "            print(f\"   {var}: {main_val} ({main_pct:.1f}%) - {category.lower()}\")\n",
    "        \n",
    "        df.drop(var, axis=1, inplace=True)\n",
    "        excluded_count += 1\n",
    "\n",
    "print(f\"\\nExclus√µes por categoria:\")\n",
    "for category, count in excluded_categories.items():\n",
    "    if count > 0:\n",
    "        print(f\"   {category}: {count} vari√°veis\")\n",
    "\n",
    "# =============================================================================\n",
    "# RELAT√ìRIO FINAL COMPLETO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELAT√ìRIO FINAL - TRANSFORMA√á√ÉO COMPLETA DO DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Contar vari√°veis finais mantidas\n",
    "vars_finais_mantidas = [var for var in vars_manter if var in df.columns or \n",
    "                       any(var.replace('vd_ebia_categ', 'ebia_') in col for col in df.columns)]\n",
    "\n",
    "print(f\"\\nVari√°veis do Lote 9 processadas:\")\n",
    "for var in vars_manter:\n",
    "    if var == 'vd_ebia_categ':\n",
    "        ebia_cols = [col for col in df.columns if col.startswith('ebia_')]\n",
    "        if ebia_cols:\n",
    "            print(f\"   ‚úÖ {var} ‚Üí {len(ebia_cols)} categorias one-hot\")\n",
    "    elif var in df.columns:\n",
    "        print(f\"   ‚úÖ {var}: Mantida\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {var}: N√£o encontrada\")\n",
    "\n",
    "# Estat√≠sticas finais do dataset\n",
    "total_cols = len(df.columns)\n",
    "numeric_cols = len(df.select_dtypes(include=[np.number]).columns)\n",
    "binary_cols = len([col for col in df.columns if df[col].nunique() == 2 and col != 'aleitamento_materno_exclusivo'])\n",
    "\n",
    "print(f\"\\nEstat√≠sticas finais do dataset:\")\n",
    "print(f\"   Shape final: {df.shape}\")\n",
    "print(f\"   Total de features: {total_cols}\")\n",
    "print(f\"   Features num√©ricas: {numeric_cols}\")\n",
    "print(f\"   Features bin√°rias: {binary_cols}\")\n",
    "print(f\"   Vari√°veis exclu√≠das neste lote: {excluded_count}\")\n",
    "\n",
    "# Estimar redu√ß√£o total\n",
    "print(f\"\\nRedu√ß√£o estimada do dataset original:\")\n",
    "print(f\"   In√≠cio: 173 vari√°veis originais\")\n",
    "print(f\"   Final: ~{total_cols} features\")\n",
    "print(f\"   Redu√ß√£o: ~{((173-total_cols)/173)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nCategorias de vari√°veis finais:\")\n",
    "print(f\"   ‚Ä¢ Demogr√°ficas/Socioecon√¥micas\")\n",
    "print(f\"   ‚Ä¢ Perinatais/Antropom√©tricas\") \n",
    "print(f\"   ‚Ä¢ Sa√∫de/Cuidados\")\n",
    "print(f\"   ‚Ä¢ Ambientais/Contextuais\")\n",
    "\n",
    "# =============================================================================\n",
    "# SALVAR DATASET FINAL\n",
    "# =============================================================================\n",
    "\n",
    "df.to_csv(file_path, index=False)\n",
    "print(f\"\\nüíæ DATASET FINAL SALVO: {df.shape}\")\n",
    "print(f\"üìÅ Arquivo: {file_path}\")\n",
    "\n",
    "print(f\"\\nüéØ TRANSFORMA√á√ÉO COMPLETA:\")\n",
    "print(f\"   ‚úÖ Elimina√ß√£o de tautologias\")\n",
    "print(f\"   ‚úÖ Consolida√ß√£o inteligente\")\n",
    "print(f\"   ‚úÖ Parcim√¥nia rigorosa\")\n",
    "print(f\"   ‚úÖ Feature engineering defens√°vel\")\n",
    "print(f\"   ‚úÖ Redu√ß√£o de dimensionalidade significativa\")\n",
    "print(f\"   ‚úÖ Preserva√ß√£o de poder preditivo cient√≠fico\")\n",
    "\n",
    "print(f\"\\nüöÄ DATASET PRONTO PARA MACHINE LEARNING!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
