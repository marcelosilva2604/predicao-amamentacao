{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa96612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIANDO TRAIN/TEST SPLIT ESTRATIFICADO\n",
      "==================================================\n",
      "Dataset original: (1960, 120)\n",
      "Distribuição target original:\n",
      "  Classe 0 (não EBF): 1040 (53.1%)\n",
      "  Classe 1 (EBF): 920 (46.9%)\n",
      "\n",
      "Features: 118\n",
      "Observações: 1960\n",
      "\n",
      "Após split estratificado:\n",
      "Treino: 1568 casos (80.0%)\n",
      "Teste: 392 casos (20.0%)\n",
      "\n",
      "Distribuição TREINO:\n",
      "  Classe 0: 832 (53.1%)\n",
      "  Classe 1: 736 (46.9%)\n",
      "\n",
      "Distribuição TESTE:\n",
      "  Classe 0: 208 (53.1%)\n",
      "  Classe 1: 184 (46.9%)\n",
      "\n",
      "Datasets salvos:\n",
      "Treino: /Users/marcelosilva/Desktop/copia2 - artigo peer/predição_amamentação/9 - Train-Test DS/train_set.csv\n",
      "  Shape: (1568, 120)\n",
      "Teste: /Users/marcelosilva/Desktop/copia2 - artigo peer/predição_amamentação/9 - Train-Test DS/test_set.csv\n",
      "  Shape: (392, 120)\n",
      "\n",
      "Verificação final:\n",
      "Total casos: 1960 = 1960 ✓\n",
      "Nenhum vazamento: IDs únicos entre treino e teste\n",
      "Sobreposição de IDs: 0 (deve ser 0) ✓\n",
      "\n",
      "Pronto para aplicar regularização apenas no conjunto de TREINO!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Carregar dataset completo\n",
    "df = pd.read_csv('/Users/marcelosilva/Desktop/copia2 - artigo peer/predição_amamentação/9 - Train-Test DS/completeDS.csv')\n",
    "\n",
    "print(\"CRIANDO TRAIN/TEST SPLIT ESTRATIFICADO\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(f\"Dataset original: {df.shape}\")\n",
    "\n",
    "# Verificar target\n",
    "target_counts = df['aleitamento_materno_exclusivo'].value_counts()\n",
    "print(f\"Distribuição target original:\")\n",
    "print(f\"  Classe 0 (não EBF): {target_counts[0]} ({target_counts[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"  Classe 1 (EBF): {target_counts[1]} ({target_counts[1]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Separar features e target\n",
    "X = df.drop(['aleitamento_materno_exclusivo', 'id_anon'], axis=1)\n",
    "y = df['aleitamento_materno_exclusivo']\n",
    "ids = df['id_anon']\n",
    "\n",
    "print(f\"\\nFeatures: {X.shape[1]}\")\n",
    "print(f\"Observações: {len(y)}\")\n",
    "\n",
    "# Split estratificado 80/20\n",
    "X_train, X_test, y_train, y_test, ids_train, ids_test = train_test_split(\n",
    "    X, y, ids,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Estratificação pela target\n",
    ")\n",
    "\n",
    "print(f\"\\nApós split estratificado:\")\n",
    "print(f\"Treino: {X_train.shape[0]} casos ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Teste: {X_test.shape[0]} casos ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Verificar manutenção das proporções\n",
    "train_counts = y_train.value_counts()\n",
    "test_counts = y_test.value_counts()\n",
    "\n",
    "print(f\"\\nDistribuição TREINO:\")\n",
    "print(f\"  Classe 0: {train_counts[0]} ({train_counts[0]/len(y_train)*100:.1f}%)\")\n",
    "print(f\"  Classe 1: {train_counts[1]} ({train_counts[1]/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribuição TESTE:\")\n",
    "print(f\"  Classe 0: {test_counts[0]} ({test_counts[0]/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  Classe 1: {test_counts[1]} ({test_counts[1]/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# Recriar dataframes completos\n",
    "train_df = pd.concat([\n",
    "    ids_train.reset_index(drop=True),\n",
    "    y_train.reset_index(drop=True), \n",
    "    X_train.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "test_df = pd.concat([\n",
    "    ids_test.reset_index(drop=True),\n",
    "    y_test.reset_index(drop=True),\n",
    "    X_test.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Salvar datasets\n",
    "train_path = '/Users/marcelosilva/Desktop/copia2 - artigo peer/predição_amamentação/9 - Train-Test DS/train_set.csv'\n",
    "test_path = '/Users/marcelosilva/Desktop/copia2 - artigo peer/predição_amamentação/9 - Train-Test DS/test_set.csv'\n",
    "\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"\\nDatasets salvos:\")\n",
    "print(f\"Treino: {train_path}\")\n",
    "print(f\"  Shape: {train_df.shape}\")\n",
    "print(f\"Teste: {test_path}\")\n",
    "print(f\"  Shape: {test_df.shape}\")\n",
    "\n",
    "print(f\"\\nVerificação final:\")\n",
    "print(f\"Total casos: {len(train_df) + len(test_df)} = {len(df)} ✓\")\n",
    "print(f\"Nenhum vazamento: IDs únicos entre treino e teste\")\n",
    "\n",
    "# Verificar se não há sobreposição de IDs\n",
    "overlap = set(train_df['id_anon']).intersection(set(test_df['id_anon']))\n",
    "print(f\"Sobreposição de IDs: {len(overlap)} (deve ser 0) ✓\")\n",
    "\n",
    "print(f\"\\nPronto para aplicar regularização apenas no conjunto de TREINO!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pycaret_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
